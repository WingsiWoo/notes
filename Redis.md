#  Redis

## 数据结构与对象

### SDS

Redis没有直接使用C传统的字符串表示（以空字符结尾的字符数组），而是自己构建了一种名为简单动态字符串（SDS）的抽象类型，并将SDS用作Redis的默认字符串表示。

> 在Redis里，C字符串只会作为字符串字面量用在一些无须对字符串值进行修改的地方，比如打印日志

除了用来保存数据库中的字符串值外，SDS还被用作缓冲区：AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区，都是由SDS实现的。



#### 定义

```c
struct sdshdr {
  // 记录buf数组中已使用字节的数量
	int len;
	// 记录buf数组中未使用字节的数量
	int free;
	// 字节数组，用于保存字符串
	char buf[];
}
```

SDS遵循C字符串以空字符结尾的惯例，会默认在字符串末尾添加一个空字符作为结尾。保存空字符的1字节空间不计算在SDS的`len`属性，并且为空字符分配1字节空间、添加空字符到字符串末尾等操作是由SDS函数自动完成的，也就是说这个空字符对于SDS使用者来说是完全透明的。

这样做的好处是SDS字符可以直接重用一部分C字符串函数库里面的函数。



#### Redis选用SDS的优点

1. ==获取字符串长度==

   - C字符串本身并没有记录字符串的长度，要想获取字符串长度就需要从头遍历并计数，时间复杂度为O(n)
   - SDS中的`len`属性记录了字符串长度，获取SDS长度的时间复杂度为O(1)。并且这个长度值的维护是由SDS的相关API执行时自动完成的，用户无需费心维护

2. ==杜绝缓冲区溢出==

   - C字符串可通过`strcat(dest, src)`函数把src字符串拼接到dest字符串后面，假设内存中有两个紧邻的字符串s1和s2（s1在前），如果对s1执行strcat函数的话，s1的数据就会溢出到s2所在的空间中，导致s2本身保存的内容被s1新增的内容覆盖，这就是所谓的缓冲区溢出
   - 与C字符串不同，当SDS API需要对SDS进行修改时，API会先检查内存空间是否满足修改所需的要求，如果不满足的话，API会先根据空间分配策略自动扩展SDS空间，然后才执行实际的修改操作。这个扩展的操作是由SDS API自动完成的，无需用户关心

3. ==减少修改字符串时带来的内存重分配次数==

   - C字符串的底层是实现N+1个字符长的数组来存储字符（额外的一个字符空间用于存储空字符），所以每次增长或者缩短一个C字符串，就需要对这个字符数组进行一次内存重分配操作
     - 如果程序执行的是增长字符串操作，则需要先通过内存重分配来扩展底层数组的大小，否则可能会产生缓冲区溢出
     - 如果程序执行的是截取字符串操作，则需要通过内存重分配来释放不再需要的那部分空间，否则会产生内存泄漏

   > 内存重分配可能需要执行系统调用，通常是一个比较耗时的操作。而Redis作为一个数据库，并且常用作缓存，要求速度快、数据频繁修改，如果每次修改字符串长度都需要执行一次内存重分配的话，就会耗费大量的性能，因此Redis要尽可能的避免内存重分配的发生

   - SDS通过未使用空间解除了字符串长度与底层数组长度之间的关联，即`buf`数组的长度不一定是字符长度+1，数组内可以包含未使用的字节，这些字节的数量由SDS的`free`属性记录。通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略

     - **空间预分配**

       空间预分配策略用于优化SDS的字符串增长操作：当SDS API对一个SDS进行增长，并且需要对SDS进行空间扩展的时候，程序会额外分配未使用空间，从而减少连续执行字符串增长操作的内存重分配次数

       - 修改后 `len < 1MB` ，分配和`len`同样大小的未使用空间，即SDS的`len`将等于`free`
       - 修改后 `len >= 1MB` ，分配1MB未使用空间

     - **惰性空间释放**

       惰性空间释放用于优化SDS的字符串缩短操作：SDS API缩短一个SDS时，不会立即使用内存重分配来回收内存空间，而是使用`free`属性记录。当然，SDS也提供了相应的API来真正释放内存，所以无需担心惰性空间释放策略会造成内存浪费

4. ==二进制安全==

   - C字符串中的字符必须符合某种编码，并且中间不能包含空字符（否则程序读入时可能会把这个空字符误认为字符串结尾），因此限制了**C字符串只能保存文本数据**，而不能保存像图片、音频、视频、压缩文件的二进制数据
   - SDS使用`len`的值来判断字符串是否结束，所以就没有上面说的问题，使得**Redis可以保存任意格式的二进制数据**



### 链表

1. 链表被广泛用于实现Redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等
2. ==双向链表==：每个链表节点有`prev`和`next`指针，获取前后节点的时间复杂度都是O(1)
3. ==无环==：表头节点的`prev`指针和表尾节点的`next`节点都指向NULL，对链表的访问以NULL结束
4. ==带表头指针和表尾指针==：`list`结构中存储着链表的头节点和尾节点，访问的时间复杂度都是O(1)
5. ==带链表长度计数器==：`list`结构中用`len`属性存储链表长度，获取长度时无需遍历，时间复杂度为O(1)
6. ==多态==：链表节点使用`void*`指针来保存节点值，并且可以通过`list`结构的`dup`、`free`、`match`三个函数为节点值设置类型特定函数，所以**链表可以用于保存各种不同类型的值**



### 字典

用途：

- Redis数据库本身就是使用字典作为底层实现
- Hash散列的底层实现之一



#### 哈希表定义

```c
typedef struct dictht {
	// 哈希表数组
	dictEntry **table;
	// 哈希表大小
	unsigned long size;
	// 哈希表大小掩码，用于计算索引值，总是为size-1
	unsigned long sizemask;
	// 哈希表已有节点数量
	unsigned long used;
}
```

```c
typedef struct dictEntry {
  // 键
	void *key;
  // 值，可以是指针、uint64_t整数、int64_t整数
	union {
		void *val;
		uint64_tu64;
		int64_ts64;
	} v;
  // 指向下个哈希表节点，形成链表
	struct dictEntry *next;
} dictEntry;
```

> Redis中的哈希表采用链地址法解决哈希冲突（把同义词用链表串联起来），别的解决方法还有开放地址法（以原来的哈希值再求一次哈希，探测新的地址直到没有碰撞）、再哈希法（构造多个哈希函数）、建立公共溢出区（与基本表碰撞的元素一律填入溢出表）
>
> 另外，由于`dictEntry`节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点插入到链表的头部



#### 字典定义

```c
typedef struct dict {
  // 类型特定函数
	dicType *type;
  // 私有数据
	void *privdata;
  // 哈希表，一般情况下只使用ht[0]，ht[1]只有在rehash时才使用
	dictht ht[2];
  // rehash索引，当rehash不在进行时，值为-1
	int rehashidx;
} dict
```

`type`属性和`privdata`属性是针对不同类型的键值对，为创建多态字典而设置的：

- `type`属性是一个指向`dictType`结构的指针，每个`dictType`结构保存了一簇用于操作特定类型键值对的函数，`Redis`会为用途不同的字典设置不同的类型特定函数
- `privdata`属性保存了需要传给那些类型特定函数的可选参数



#### rehash

为了让哈希表的负载因子维持在一个合理的范围内，需要对哈希表的大小进行相应的扩展和收缩，也就是`rehash`（重新散列）：

1. 为字典`dict`中的`ht[1]`哈希表分配空间，这个哈希表的空间大小取决于要执行的操作（扩展还是收缩），以及`ht[0]`当前包含的键值对数量（即`ht[0].used`）
   - 扩展操作：`ht[1]`的大小为第一个大于等于`ht[0].used*2`的2次幂
   - 收缩操作：`ht[1]`的大小为第一个大于等于`ht[0].used`的2次幂
2. 将保存在ht[0]中的所有键值对rehash到ht[1]上
3. 所有键值对都迁移完成后，释放`ht[0]`，把现在的`ht[1]`设置为`ht[0]`，并在`ht[1]`新创建一个空白哈希表，为下一次`rehash`作准备

哈希表的负载因子 = 哈希表已保存节点数 / 哈希表大小

- 当哈希表负载因子 < 0.1，程序自动开始对哈希表执行收缩操作
- 服务器目前没有在执行`BGSAVE`或者`BGREWRITEAOF`命令，且哈希表负载因子 >= 1，程序执行扩展操作
- 服务器目前正在执行`BGSAVE`或者`BGREWRITEAOF`命令，且哈希表负载因子 >= 5，程序执行扩展操作

> 根据`BGSAVE`或者`BGREWRITEAOF`命令是否在执行，服务器执行扩展操作所需的负载因子不同的原因是：在执行这两个命令的过程中，Redis需要创建当前服务器进程的子进程。而大多数操作系统都采用写时复制（`Copy-On-Write`）来优化子进程的使用效率，所以在子进程存在期间，服务器会提高扩展操作所需的负载因子，从而尽可能避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度节约内存



**什么是写时复制**

在了解Linux的`copy-on-write`机制之前，首先要了解两个函数：`fork()`和`exec()`。

- `fork()`函数是类Unix操作系统上创建进程的主要方法，用于创建子进程（相当于当前进程的副本）
  - 新的进程要通过老的进程复制自身得到
  - Linux的所有进程都是通过`init`进程或`init`的子进程`fork`出来的
- `exec()`是一组函数的统称， 它包括了`execl()`、`execlp()`、`execv()`、`execle()`、`execve()`、`execvp()`。
  - `exec()`函数的作用是装载一个新的程序（可执行映像）覆盖当前进程内存空间中的映像，从而执行不同的任务
  - `exec`系列函数在执行时会直接替换掉当前进程的地址空间

按照传统的做法，先通过`fork()`创建子进程，并把父进程的数据拷贝到子进程中，拷贝完后，父子进程之间的数据段和堆栈是相互独立的。之后如果子进程第一时间执行`exec()`来做自己想要实现的功能（此时父子进程之间的数据完全一致），`exec()`函数会把那一块内存空间中原有的数据清空，然后把子进程的数据写入内存。

但是这样的话，这个拷贝的数据很多时候就是无效的，因为父子进程的数据是一样的（清空又写入）。于是就诞生了写时复制的技术：

- `fork`创建出的子进程，与父进程共享内存空间。也就是说，如果子进程不对内存空间进行写入操作的话，内存空间中的数据并不会复制给子进程，这样创建子进程的速度就很快了(不用复制，直接引用父进程的物理空间)。

- 这样子如果在`fork`函数返回之后，子进程**第一时间**`exec`一个新的可执行映像，那么也不会浪费时间和内存空间了。

- 当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间。

- 如果是因为`exec`，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。

- `fork`出的子进程共享父进程的物理空间，当父子进程有内存写入操作时，`read-only`内存页发生中断，将触发的异常的内存页复制一份(其余的页还是共享父进程的)。

  > 这里强调第一时间是指父子进程之间的数据完全一致，这样父子进程才能引用同一个物理空间
  >
  > 在fork后exec之前父子进程拥有不同的虚拟空间，但是都指向同一个物理空间

优点：

- COW技术可减少分配和复制大量资源时带来的瞬间延时
- COW技术可减少不必要的资源分配。比如`fork`进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。

缺点：

- 如果在`fork()`之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断`page-fault`)，这样就得不偿失。

对于Redis中的COW：

- Redis在持久化时，如果是采用`BGSAVE`命令或者`BGREWRITEAOF`的方式，那Redis会`fork`出一个子进程来读取数据，从而写到磁盘中。
- 总体来看，Redis还是读操作比较多。如果子进程存在期间，发生了大量的写操作，那可能就会出现很多的分页错误(页异常中断`page-fault`)，这样就得耗费不少性能在复制上。
- 而**在`rehash`阶段上，写操作是无法避免的**。所以Redis在`fork`出子进程之后，将负载因子阈值提高，尽量减少写操作，避免不必要的内存写入操作，最大限度地节约内存。



#### 渐进式rehash

1. 为`ht[1]`分配空间，让字典同时持有`ht[0]`和`ht[1]`两个哈希表
2. 在字典中维持一个索引计数器变量`rehashidx`，值设为0表示`rehash`开始（为-1表示没有在`rehash`）
3. 在`rehash`进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作意外，还会顺带将`ht[0]`哈希表在`rehashidx`索引上的所有键值对都`rehash`到`ht[1]`，完成后`rehashidx++`
4. 随着字典操作不断执行，最终`ht[0]`上所有的键值对都会`rehash`完成，最后将`rehashidx`设为-1，表示`rehash`工作结束

> 渐进式`rehash`的好处是避免了集中式`rehash`带来的庞大计算量
>
> 渐进式`rehash`的过程中字典会同时使用`ht[0]`和`ht[1]`两个哈希表，因此要查找一个键的时候，程序会先到`ht[0]`中查找，找不到的话再到`ht[1]`中查找；新增键值对只会插入到`ht[1]`，保证`ht[0]`中的键值对在`rehash`过程中只减不增



### 跳跃表

跳跃表是一种有序数据集合，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的，支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。

Redis只在两个地方用到了跳跃表：有序集合键、在集群节点中用作内部数据结构

用途：

- Zset有序集合的底层实现之一

- 集群节点中用作内部数据结构

  

#### 定义

```c
typedef struct zskiplist {
  // 表头、表尾节点，从两个方向都可以开始遍历
	struct zskiplistNode *header, *tail;
  // 表中节点数量
	unsigned long length;
  // 表中层数最大的节点的层数
	int level;
} zskiplist;
```

```c
typedef struct zskiplistNode {
  // 层
	struct zskiplistLevel {
	  // 前进指针
		struct zskiplistNode *forward;
		// 跨度，记录了前进指针所指向节点和当前节点的距离
		unsigned int span;
	} level[];
	// 后退指针
	struct zskiplistNode *backward;
	// 分值，跳跃表中节点按照分值从小到大排序
	double score;
	// 成员对象，指向一个字符串对象（保存着一个SDS值）
	robj *obj;
} zskiplistNode;
```

1. 层

   跳跃表节点的level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度，一般来说层的数量越多，访问其他节点的速度就越快。

   > 每次新建一个跳跃表节点时，程序都根据幂次定律（越大的数出现的概率越小）随机生成一个介于1-32之间的值作为level数组的大小，这个大小就是层的高度

2. 跨度

   两个节点之间的跨度越大，它们相距越远；指向NULL的所有前进指针的跨度都为0

   > 跨度是用来计算排位的，在查找某个节点的过程中，将沿途访问过的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位

3. 分值和成员对象

   跳跃表中所有节点按照分值从小到大排序。分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象较小的节点会排在前面

   > 跳跃表中分值可以存在一样的，但是成员对象必须是唯一的，即不可能存在分值和成员对象都一样的节点




#### 查询、插入、删除

![img](https://img-blog.csdn.net/20161110132445855?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

注意：在不同层同一列的节点实际上是同一个，所以跳表不存在重复存储的问题

1. 插入：

   1. 随机生成层数

   2. 找到所在层插入位置的上一个节点

   3. 插入上一个节点和下一个节点之间

   4. 更新上一个节点的span和自己的span（本节点到下一节点的跨度）

      > 最底层每个节点的span一定是1，因为就相当于是个单链表

2. 查询：跳表的查询其实有点类似于二分查找，首先从最高层开始遍历查找，找到第一个大于目标值的节点，然后以该节点作为下一层查找的终点，到下一层继续寻找。查询时间复杂度为O(logn)



### 整数集合

整数集合是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。

- 只包含整数值元素的集合

- 底层实现为数组，以**有序、无重复**的方式保存元素，在有需要时，程序会根据新添加元素的类型，改变这个数组的类型

- 只支持升级操作，不支持降级操作

  即当添加一个新元素到整数集合里，并且新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要先进行升级，才能将新元素添加到整数集合中

  过程：

  1. 根据新元素的类型扩展整数集合底层数组大小，并为新元素分配空间
  2. 将底层数据内所有的元素都转换成与新元素相同的类型，并放置到正确位置上
  3. 将新元素添加到底层数组

  > 好处是提高整数集合的灵活性（可以随意将int16_t、int32_t、int64_t加入整数集合而无需担心出现类型错误）、尽可能的节约内存（在添加更长的整数元素进去之前，都会使用最短的int16_t来存储，从而节省内存）

- 用途 

- - Set 集合的底层实现之一



### 压缩列表

- 压缩列表是**为了节约内存**而开发的，由一系列特殊编码的连续内存块组成的**顺序型数据结构**

- 压缩列表增删节点，可能会引发连锁更新操作，但这种操作出现的几率并不高

  ![image-20220218114030937](https://tva1.sinaimg.cn/large/e6c9d24egy1gzhijnn4vrj20cl0263yh.jpg)

  previous_entry_length记录了前一个节点的长度：

  - 如果前一节点的长度小于254字节，则需要用1字节长度来保存
  - 如果前一节点的长度大于等于254字节，则需要用5字节长度来保存

  ![image-20220218114154974](https://tva1.sinaimg.cn/large/e6c9d24egy1gzhil2acymj20jo02ymx9.jpg)

  假设e1-eN都是长度介于250字节到253字节之间的节点，此时需要在e1前插入一个长度大于254字节的节点new，由于new节点长度大于254字节，所以e1需要把其previous_entry_length的长度扩展为5字节，但是这样一扩展e1本身的长度也超过了254字节，因此e2也需要扩展。以此类推，插入一个new引起了后续多个节点的更新，这就是连锁更新

  > 因为连锁更新在最坏情况下需要对压缩列表执行N次空间重分配操作，而每次空间重分配的最坏复杂度为O(N)，因此连锁更新的最坏复杂度为O(N^2^)

- 用途 

- - List 列表的底层实现之一

- - Hash 散列的底层实现之一
  - Zset 有序集合的底层实现之一



### 对象

Redis并没有直接使用前面提到的数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，每种对象都用到了至少一种数据结构

#### 定义

```c
typedef struct redisObject {
  // 类型
	unsigned type:4;
  // 编码
	unsigned encoding:4;
  // 指向底层数据结构的指针
	void *ptr;
	// 引用计数
  int refcount;
  // 最后一次被程序访问的时间
  unsigned lru:22;
} robj
```



#### 对象类型

|   对象名称   |   类型常量   | TYPE命令输出 |
| :----------: | :----------: | :----------: |
|  字符串对象  | REDIS_STRING |    string    |
|   列表对象   |  REDIS_LIST  |     list     |
|   哈希对象   |  REDIS_HASH  |     hash     |
|   集合对象   |  REDIS_SET   |     set      |
| 有序集合对象 |  REDIS_ZSET  |     zset     |



#### 编码和底层实现

`encoding`即说明这个对象使用了什么数据结构作为底层实现

|         编码常量          |      对应底层数据结构      |
| :-----------------------: | :------------------------: |
|    REDIS_ENCODING_INT     |       long类型的整数       |
|   REDIS_ENCODING_EMBSTR   | embstr编码的简单动态字符串 |
|    REDIS_ENCODING_RAW     |   简单动态字符串（SDS）    |
|     REDIS_ENCODING_HT     |            字典            |
| REDIS_ENCODING_LINKEDLIST |          双端链表          |
|  REDIS_ENCODING_ZIPLIST   |          压缩列表          |
|   REDIS_ENCODING_INTSET   |          整数集合          |
|  REDIS_ENCODING_SKIPLIST  |        跳跃表和字典        |

![image-20220218115804391](https://tva1.sinaimg.cn/large/e6c9d24egy1gzhj1wzz35j20nf09zjtq.jpg)

Redis可以根据不同的使用场景来为对象设置不同的编码，从而优化对象在某一场景下的效率：

- 列表元素较少时，使用压缩列表作为底层实现，更节约内存，能更快载入到缓存中
- 列表元素很多，转换成双端链表，功能更强，更适合保存大量元素

1. 字符串对象

   - `raw`：保存的是一个字符串值，并且这个字符串值的长度大于32字节，那么字符串对象将使用一个SDS来保存，并且编码设置为`raw`
   - `embstr`：保存的是一个字符串值，并且这个字符串值的长度小于等于32字节
     - `embstr`编码将创建字符串对象所需的内存分配次数从`raw`编码的两次降低为一次
     - 释放`embstr`编码的字符串对象只需要调用一次内存释放函数，`raw`编码的需要两次
     - `embstr`编码的字符串对象的所有数据都保存在一块连续的内存中，能更好的利用缓存带来的优势
     - `embstr`编码的字符串对象是只读的（Redis没有为其提供任何相应的修改程序），因此对`embstr`编码的字符串对象执行任何修改命令时都会转换成`raw`后再执行修改命令

   > 可以用long double类型表示的浮点数在Redis中也是作为字符串值来保存的，如果要对浮点数进行计算时会把保存的字符串转换回浮点数，计算后再转换为字符串存储到字符串对象中

   - `int`
     - 保存的是整数值，并且这个整数值可以用`long`类型来表示
     - 如果保存的不再是整数值而是字符串值，编码就会转变为`raw`（比如执行`APPEND`操作，因为`APPEND`操作只能对字符串值执行，所以程序会自动转换编码再进行追加）

2. 列表对象

   - `ziplist`

     - 列表对象保存的所有字符串元素的长度都小于64字节
     - 列表对象保存的元素数量小于512个

     > 以上任一条件不满足时则使用`linkedlist`编码

   - `linkedlist`：每个双端链表的节点都保存了一个字符串对象，每个字符串对象保存了一个列表元素

   > 字符串对象是Redis中唯一会被其他四种类型对象嵌套的对象

3. 哈希对象

   - `ziplist`：每当有新的键值对要加入到哈希对象时，程序会先将把保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾
     - 保存了同一键值对的两个节点总是紧挨在一起，键在前值在后
     - 靠近表头方向的是先添加的键值对
     - 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
     - 哈希对象保存的键值对数量小于512个
   - `hashtable`：字典中的键和值都是字符串对象

4. 集合对象

   - `intset`
     - 集合对象保存的所有元素都是整数值
     - 集合对象保存的元素数量不超过512个
   - `hashtable`：字典的每个键都是一个字符串对象，字符串对象内包含了一个集合元素，值全部设置为NULL

5. 有序集合对象

   - `ziplist`

     - 每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值
     - 压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向
     - 有序集合保存的元素数量小于128个
     - 有序集合保存的所有元素成员的长度都小于64字节

   - `skiplist`

     - 使用`zset`结构作为底层实现，一个`zset`结构同时包含一个字典和一个跳跃表
     - 跳跃表按分值从小到大保存了所有集合元素，通过这个跳跃表，程序可以对有序集合进行范围型操作，比如`ZRANK`、`ZRANGE`等命令就是基于跳跃表API实现的
     - `zset`中的字典存储着成员到分值的映射，通过字典可以用O(1)时间复杂度获取到给定成员的分值，`ZSCORE`命令就是根据这一特性实现的

     > `zset`结构中的跳跃表和字典通过指针来共享相同元素的成员和分值，所以同时使用这两种数据结构来保存数据结构都不会产生任何重复成员或分值，也不会因此而浪费额外的内存
     >
     > - 如果不使用跳跃表，由于字典以无序方式来保存集合元素，因此每次执行范围型操作的时候都需要先进行排序，至少需要`O(NlogN)`的时间复杂度，以及额外`O(N)`内存空间（因为要创建一个数组来保存排序后的元素）
     > - 如果不使用字典，那么获取成员对应的分值所需的时间复杂度就上升到`O(logN)`



#### 类型检查

- SET、GET、APPEND、STRLEN等只能对字符串键执行
- HDEL、HSET、HGET、HLEN等只能对哈希键执行
- RPUSH、LOPO、LINSERT、LLEN等只能对列表键执行
- SADD、SPOP、SINTER、SCARD等只能对集合键执行
- ZADD、ZCARD、ZRANK、ZSCORE等只能对有序集合键执行

如果尝试执行其他类型的命令，Redis将会返回一个类型错误：

![image-20220219150124726](https://tva1.sinaimg.cn/large/e6c9d24egy1gzityzbskqj20kq00kjra.jpg)

所以为了确保只有指定类型的键可以执行某些特定的命令，在执行一个类型特定的命令之前，Redis会先检查输入键的类型（使用`redisObject`结构中的`type`属性）是否正确，然后再决定是否执行给定的命令



#### 多态命令

Redis除了会根据值对象的类型来判断键是否能够执行指定命令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令。（即一个对象可能会有不同的编码方式，Redis会自动根据其编码方式选择对应数据结构的API进行操作）

像DEL、EXPIRE、TYPE这种命令就称为多态命令，因为无论输入的键是什么类型，这些命令都可以正确执行



#### 内存回收

Redis通过**引用计数**来实现内存回收机制。每个对象的引用计数信息由`redisObject`结构的`refcount`属性记录

![image-20220219151505353](https://tva1.sinaimg.cn/large/e6c9d24egy1gziud6kvfsj20gx047aar.jpg)



#### 对象共享

对象共享即让多个键共享同一个值对象：

1. 将数据库键的值指针指向一个现有的值对象
2. 将被共享的值对象的引用计数加一

> Redis在初始化服务器时，会创建0-9999这一万个整数值的字符串对象，当需要使用的时候服务器会使用这些共享对象而不是新创建对象
>
> Redis只会对包含整数值的字符串对象进行共享

##### 为什么Redis不共享包含字符串的对象？

当服务器考虑将一个共享对象设置为键的值对象时，会先检查给定的共享对象和键想创建的目标对象是否完全相同，只有完全相同才会进行设置。而一个共享对象保存的值越复杂，验证是否相同所需的复杂度就会越高，消耗CPU时间也会越多：

- 验证保存整数值的字符串对象为`O(1)`
- 验证保存字符串值的字符串对象为`O(N)`
- 验证包含了多个值对象的对象（比如列表对象或者哈希对象）为`O(N^2^)`

因此，尽管共享更复杂的对象可以节约更多内存，但考虑到CPU时间，Redis只对包含整数值的字符串对象进行共享



#### 对象的空转时长

`redisObject`结构中的`lru`属性记录了对象最后一次被命令程序访问的时间，当前时间 - lru时间即该对象的空转时长。如果服务器大考了`maxmemory`选项，并且服务器用于回收内存的算法为`volatile-lru`或者`allkeys-lru`，那么当服务器占用的内存数超过了`maxmemory`，那么空转时长较大的那部分键会优先被服务器释放，从而回收内存



## 数据库

- Redis服务器将所有数据库都保存在`redisServer`的`db`数组中，`db`数组的每个项都是一个`redisDb`结构，每个结构代表一个数据库。
- 初始化服务器时，程序根据`redisServer`中的`dbnum`属性来决定创建多少个数据库，默认为`16`
- 服务器内部，客户端状态`redisClient`结构的`db`属性记录了客户端当前的目标数据库，这个属性是一个指向`redisDb`结构的指针
- `redisDb`结构的`dict`字典保存了数据库中所有的键值对，称为键空间
  - 键空间的键是字符串对象
  - 键空间的值可以是任意一种Redis对象
- 键空间的维护操作：
  - 读取键后，服务器会根据键是否存在来更新服务器的键空间命中或键空间不命中次数
  - 更新键的LRU时间
  - 如果读取时发现该键已过期，则删除过期键
  - 如果有客户端使用`WATCH`命令监视这个键，那么服务器在对被监视的键进行修改之后会将这个键标记为脏
  - 修改键后脏键计数器的值加一，这个计数器会触发服务器的持久化以及复制操作
  - 数据库通知



### 过期键删除策略

数据库键的过期时间都保存在过期字典中。

1. 定时删除：在设置键的过期时间的同时，创建一个定时器，在键过期时立即删除
   - 对内存最友好，保证过期键尽可能快地被删除，并释放过期键所占用的内存
   - 对CPU时间最不友好，在内存并不紧张而CPU时间非常紧张的情况下，把CPU时间浪费在删除过期键上，无疑会对服务器的响应时间和吞吐量造成影响
2. 惰性删除：放任键过期不管，但每次从键空间获取该键时要先检查其是否过期，如果过期了要先删除该键
   - 是唯一一种被动删除策略
   - 对CPU时间来说最友好，保证删除过期键的操作只会在非做不可的情况下进行
   - 对内存最不友好，如果一个键已经过期，并且可能之后不再被访问，那么这个过期键占用的内存就不会被释放
3. 定期删除：每隔一段时间程序就对数据库进行一次检查，删除里面的过期键



### Redis的过期键删除策略

Redis服务器实际使用的是惰性删除和定期删除两种策略，在合理使用CPU时间和避免浪费内存空间之间取得平衡

- 惰性删除：所有读写数据库的Redis命令在执行之前都会调用`expireIfNeeded`函数对输入键进行检查
- 定期删除：Redis服务器周期执行`activeExpireCycle`函数，在规定时间内分多次遍历服务器中的各个数据库。全局变量`current_db`会记录当前`activeExpireCycle`函数检查的进度，下一次`activeExpireCycle`函数调用时会接着上一次的进度进行处理，检查完毕后`current_db`重置为0
- 生成RDB文件：过期键不会被保存到新创建的RDB文件中
- 载入RDB文件
  - 主服务器模式，不会载入过期键
  - 从服务器模式，无论是否过期，载入文件中保存的所有键。不过主从服务器在进行数据同步的时候，从服务器的数据库会被清空，所以载入的过期键也不会产生什么影响
- AOF文件写入：过期键被删除后，程序会向AOF文件追加一条DEL命令，来显式记录该键已经删除
- AOF重写：过期键不会被保存到重写后的AOF文件中
- 复制模式：当服务器运行在复制模式下，从服务器的过期键删除动作由主服务器控制
  - 主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键
  - 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键
  - 从服务器只有在接到主服务器发来的DEL命令之后，才会删除过期键



### 数据库通知

数据库通知时2.8新增的功能，可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变化，以及数据库中命令的执行情况。



### 缓存淘汰策略

- `noeviction`:如果缓存数据超过了`maxmemory`限定值，并且客户端正在执行的命令(大部分的写入指令，但DEL和几个指令例外)会导致内存分配，则向客户端返回错误响应
- `allkeys-lru`: 对所有的键都采取`LRU`淘汰
- `volatile-lru`: 仅对设置了过期时间的键采取`LRU`淘汰
- `allkeys-random`: 随机回收所有的键
- `volatile-random`: 随机回收设置过期时间的键
- `volatile-ttl`: 仅淘汰设置了过期时间的键---淘汰生存时间`TTL(Time To Live)`更小的键

#### Redis中的近似LRU算法

普通的LRU算法是使用双向链表+哈希表（`LinkedHashMap`）实现的，但是出于节省内存的考虑，Redis底层并没有完整的实现LRU算法。`Redis`并不会选择最久未被访问的键进行回收，相反它会尝试运行一个近似`LRU`的算法，通过**对少量键进行取样，然后回收其中的最久未被访问的键**。通过调整每次回收时的采样数量`maxmemory-samples`（默认为5），可以实现调整算法的精度。

根据`Redis`作者的说法，每个`Redis Object`可以挤出24 bits的空间，但24 bits是不够存储两个指针的，而存储一个**低位时间戳**是足够的，`Redis Object`以秒为单位存储了对象新建或者更新时的`unix time`，也就是`LRU clock`，24 bits数据要溢出的话需要194天，而缓存的数据更新非常频繁，已经足够了。

`Redis`的键空间是放在一个哈希表中的，要从所有的键中选出一个最久未被访问的键，需要另外一个数据结构存储这些源信息，这显然不划算。最初，`Redis`只是随机的选3个key，然后从中淘汰，后来算法改进到了`N个key`的策略，默认是5个。

`Redis`3.0之后又改善了算法的性能，会提供一个**待淘汰候选key的`pool`**，里面默认有16个key，按照空闲时间排好序。更新时从`Redis`键空间随机选择N个key，分别计算它们的空闲时间`idle`，key只会在`pool`不满或者空闲时间大于`pool`里最小的时，才会进入`pool`，然后从`pool`中选择空闲时间最大的key淘汰掉。



## RDB持久化

RDB持久化即把数据库状态保存到RDB文件中，由于RDB文件是保存在磁盘里的，所以即使服务器进程意外退出，只要RDB文件仍然存在，也可以把数据库状态恢复到生成RDB文件时候的状态，避免了数据意外丢失。

- RDB文件通过保存数据库汇总的键值对来记录数据库状态
- RDB文件是一个经过压缩的二进制文件，由多个部分组成
- 对于不同类型的键值对，RDB文件会使用不同的方式来保护它们



### RDB文件的创建与载入

- `SAVE`：会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求

- `BGSAVE`：会创建一个子进程负责创建RDB文件，不会阻塞服务器进程。

  - 在`BGSAVE`命令执行期间，拒绝执行客户端发送的`SAVE`命令，这是为了避免父进程（服务器进程）和子进程同时执行两个`rdbSave`调用，防止产生竞争条件

  - 拒绝执行客户端发送的`BGSAVE`命令，因为同样会产生竞争条件

  - `BGREWRITEAOF`和`BGSAVE`不能同时执行：

    - 如果`BGSAVE`命令正在执行，则`BGREWRITEAOF`会被延迟到`BGSAVE`执行完毕后执行
    - 如果`BGREWRITEAOF`命令正在执行，则`BGSAVE`会被拒绝

    > 这个不能同时执行并不是因为它们会产生冲突（都由子进程执行），只是出于性能方面的考虑，一并发出两个子进程，并且这两个子进程都同时执行大量的磁盘写入操作，不是一个好主意

  - 可以通过`save`选项来设置多个保存条件，但只要其中任意一个条件满足，服务器就会执行`BGSAVE`命令

    ```c
    save 900 1	// 服务器在900s内对数据库进行了至少1次修改 
    save 300 10 // 服务器在300s内对数据库进行了至少10次修改 
    save 60 10000	// 服务器在60s内对数据库进行了至少10000次修改 
    ```

    > 这些设置的参数保存在`redisServer`中的`saveparam`数组中。同时，`redisServer`中还维护着一个`dirty`计数器用于记录上次执行`SAVE`或`BGSAVE`之后数据库修改的次数，和`lastsave`属性，这是一个UNIX时间戳，记录着服务器上次成功执行`SAVE`或`BGSAVE`的时间
    >
    > Redis的服务器周期性操作函数`serverCron`默认每`100ms`就会执行一次，它的其中一项工作就是检查`save`中是否有条件满足

- 载入：Redis没有专门载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，就会自动进行载入，并且**载入期间服务器进程一直阻塞**

- 由于AOF文件的更新频率通常比RDB高，因此如果服务器开启了AOF持久化功能，服务器会优先使用AOF文件来还原数据库状态。只有当AOF功能关闭时，服务器才会使用RDB文件来还原数据库状态



## AOF持久化

AOF持久化通过保存Redis服务器所执行的写命令来记录数据库状态



### 命令追加

当AOF持久化功能打开时，服务器在执行完一个写命令之后，会以**协议格式**将被执行的写命令追加到`redisServer`的`aof_buf`缓冲区的末尾。

### 文件写入与同步

Redis的服务器进程就是一个事件循环，这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复，而时间事件则负责像`serverCron`函数这样需要定时运行的函数。

因为服务器在处理文件事件的时候可能会执行写命令，使得有一些内容会被追加到`aof_buf`缓冲区的末尾，所以在服务器每次结束一个事件循环之前，它都会调用`flushAppendOnlyFile`函数，考虑是否需要把`aof_buf`缓冲区中的内容写入到AOF文件中。

`flushAppendOnlyFile`函数的行为由服务器配置的`appendfsync`选项的值来决定：

- `always`：将`aof_buf`缓冲区中所有内容写入并同步到AOF文件中
  - 由于每个事件循环都需要写入并同步，因此是最慢的
  - 最安全的，即使出现故障停机，也只会丢失一个事件循环中所产生的命令数据
- `everysec`：为默认值，将`aof_buf`缓冲区中所有内容写入并同步到AOF文件中，如果上次同步距今超过1s，则再次对AOF文件进行同步，并且这个同步操作是由一个线程专门负责执行的
  - 从效率上来说，足够快；并且即使发生故障停机，只会丢失1s的命令数据
- `no`：将`aof_buf`缓冲区中所有内容写入到AOF文件中，但不同步，何时同步由操作系统决定
  - 无需同步，因此写入速度是最快的，但是由于可能会积累一段时间的命令数据，因此单次同步时长是最长的
  - 当出现故障停机时，会丢失上次同步AOF文件后的所有命令数据



### 文件载入与数据还原

服务器只需要读入并重新执行一次AOF中的命令就可以还原服务器的数据库状态

1. 创建一个**不带网络连接的伪客户端**（因为Redis命令只能在客户端上下文中执行），而载入AOF文件所使用的命令直接来源于AOF文件而不是网络连接，所以使用的是不带网络连接的伪客户端，执行效果是一样的
2. 从AOF文件中分析并读取出一条命令
3. 使用伪客户端执行命令



### AOF文件重写aof_rewrite

随着服务器运行时间增加，AOF文件的体积会越来越大，体积越大，数据还原所需的时间就越多，并且体积过大的AOF文件可能对Redis服务器、甚至整个宿主计算机造成影响。

为了解决AOF文件体积膨胀问题，Redis提供了AOF文件重写功能。通过该功能，Redis可以创建一个新的AOF文件来体替代原有的AOF文件，新旧文件保存的数据库状态相同，但是新文件不会包含任何浪费空间的冗余命令，体积要小得多。

> 虽然名为重写，但是实际上完全不需要对现有的AOF文件进行任何读取、分析或者写入操作，而是基于服务器当前的数据库状态实现的

如图，为了保存当前list的状态，旧的AOF文件需要写入六条命令

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gzmb7zdhu2j20mm0d20tg.jpg" alt="image-20220222151437989" style="zoom:50%;" />

重写的AOF文件可以用`RPUSH list “A” “B” “C” “D” “E” “F” “G”`一条命令来代替

> 在实际中，为了避免在执行命令时造成客户端输入缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素个数是否超过了`redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD`常量，如果超过了就使用多条命令来记录，该常量的值默认为`64`



### AOF后台重写BGREWRITEAOF

如果由服务器直接调用`aof_erewrite`函数的话，那么在重写AOF文件期间，服务器将无法处理客户端发来的命令请求（因为Redis服务器使用单线程来处理命令请求）。所以提出了后台重写，即把AOF重写程序放到子进程里执行：

- 子进程执行AOF重写期间，服务器进程不会阻塞，可以继续处理命令请求
- 子进程带有服务器进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性

但是这样就会产生一个新的问题：子进程执行AOF重写期间，服务器进程可能会需要处理新的命令请求，这些新的命令可能会对数据库状态进行修改，从而使得服务器当前的数据库状态与重写后AOF文件保存的数据库状态不一致。

为了解决这个问题，Redis服务器创建了一个AOF重写缓冲区：

1. 服务器进程执行客户端发来的命令
2. 服务器进程将执行后的写命令追加到AOF缓冲区
3. 服务器进程将执行后的写命令追加到AOF重写缓冲区

子进程完成AOF重写工作后，它会向父进程发送一个信号，父进程在接收到该信号之后会调用一个信号处理函数，并执行以下工作：

1. 将AOF重写缓冲区中所有内容写入到新的AOF文件中，至此新AOF文件中保存的数据库状态和服务器当前的数据库状态一致
2. 对新的AOF文件改名，**原子的**覆盖原有的AOF文件

> 在AOF后台重写整个过程中，只有在这个调用信号处理函数的过程会阻塞服务器进程，使得AOF重写工作对服务器性能的影响降到了最低



## 缓存异常

### 缓存和数据库的数据不一致

> 1. 先更新数据库，后更新缓存：在并发更新数据库的场景下，会将脏数据插入到缓存中
> 2. 先更新缓存，后更新数据库：如果更新缓存成功而更新数据库失败，一定会造成数据不一致问题
>
> 因此上面两种方案基本不会使用

#### 先删除缓存，后更新数据库

存在的问题：假设来了请求A（更新操作）和请求B（读取操作）

1. 请求A进行写操作，先删除缓存
2. 请求B查询缓存发现数据不存在
3. 请求B到数据库中查询，得到旧值
4. 请求B将旧值写入缓存
5. 请求A更新数据库

这样子就相当于删了白删。



##### 延时双删

延时双删即写操作进行第一次淘汰缓存，并更新数据库，等待一段时间（这个时间要大于平均读取操作的时间，即保证请求B一定已经完成）后再次淘汰缓存。这样就可以再次把请求B写入缓存的旧值再次淘汰

但是如果使用的是MySQL的读写分离的架构的话，主从同步之间也会有时间差的：

1. 请求A进行写操作，先删除缓存
2. 请求B查询缓存发现数据不存在
3. 请求B到从数据库中查询，得到旧值
4. 请求B将旧值写入缓存
5. 请求A更新数据库，并进行主从同步

这个情况的解决办法就是如果缓存不命中，就强制性到主库中查询（主库中为最新数据）

##### 更新与读取操作进行异步串行化

在系统内部维护多个内存队列，把对同一个数据的请求放到同一个队列中。如果读取数据时发现缓存不命中，并且该数据对应的队列中有更新操作，那么把该读取操作放入队列中，等待前面的更新操作完成后再读取。

> 多个读库更新缓存的请求是没有意义的，因此放入队列中可以先做个过滤，如果队列中已经有了该数据的更新缓存的请求了，就没必要再放进去了。



### 先更新数据库，后删除缓存

存在问题：更新数据库成功而删除缓存失败，那么之后读取的都是错误的数据



##### 消息队列进行删除补偿

如果删除缓存失败则把Redis的key作为消息发送到消息队列中，系统接收到消息队列发送的消息后对缓存进行再次删除。

但是这样会对业务代码造成大量侵入，提高耦合度。

优化方案：MySQL的binlog日志中会记录对应更新操作，因此可以通过订阅binlog来对缓存进行删除补偿

> binlog是mysql用来记录数据库表结构变更以及表数据修改的的二进制日志，它只会记录表的变更操作，但不会记录select和show这种查询操作。
>
> 通常用于数据恢复、主从复制、审计（检查是否存在数据注入的问题）



### 缓存雪崩

同一时间大规模的key失效，导致大量请求打到数据库上，从而导致数据库压力剧增，甚至可能会宕机。

解决方案：

1. 均匀过期：设置不同的过期时间，使得过期时间均匀分布，从而避免同一时间有大量key失效
2. 分级缓存：设置多级缓存，当一级缓存不命中时访问二级缓存，每层缓存过期时间不一致
3. 永不过期：
   - 物理不过期：不设置过期时间
   - 逻辑不过期：如果发现某个key快要过期了，就通过一个后台的异步线程进行缓存的构建
4. 主从+哨兵，Redis集群：这是针对Redis服务器宕机导致缓存雪崩的情况



### 缓存击穿

指某个热点的key失效时，大并发集中对其进行请求，造成大量请求缓存不命中，转而请求访问数据库，导致数据库压力剧增，这就是缓存击穿。

解决方法：

1. 在缓存失效后，使用互斥锁或者队列来控制并发读写数据的线程数量，这种方式会阻塞部分线程，降低系统并发度
2. 缓存永不失效：
   - 物理不过期：不设置过期时间
   - 逻辑不过期：如果发现某个key快要过期了，就通过一个后台的异步线程进行缓存的构建



### 缓存穿透

查询的目标数据在缓存和数据库中都不存在，这就导致用户每次请求这个数据的时候都会去数据库查找一次，这就是缓存穿透。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间内大量请求落在数据库上，导致数据库压力过大，甚至承受不住而宕机。

解决方法：

1. 无效的key放到缓存中，并设置过期时间极短，这样之后再次请求这个数据的时候直接返回NULL，无需到数据库查询。但是如果传进来的无效key是随机的，那这个方法也没有意义

2. 使用布隆过滤器：在缓存前增加一个布隆过滤器，把数据库中所有的key都存储在布隆过滤器中，如果布隆过滤器判定key不存在，那么就直接返回，不让其访问数据库。适用于请求的无效key很多并且重复率低

   > 布隆过滤器是由一个固定大小的二进制向量或者位图和一系列映射函数组成的。当有变量被加入集合时，布隆过滤器会通过K个映射函数把这个变量映射成位图中的K个点，并把它们置为1。查询变量是否存在的时候就只需要查看这个变量对应的映射点是否为1就可以了：
   >
   > - 如果有任意一个点为0，则一定不存在
   > - 如果都是1，则**很有可能**存在（注意不是百分百确定存在，因为散列函数是会存在碰撞的，而且在多个输入的情况下可能会有相同的bit位被多次映射且置1）
   >   - 所以布隆过滤器存在删除问题，因为一个bit位并不是独占的，可能存在多个元素共享同一位，如果删除了就会导致误判率大幅上升



## Redis高可用

### 持久化

持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份）



### 主从复制/读写分离

在Redis中，用户可以通过执行SLAVEOF命令来让一个服务器去复制另一个服务器，被复制的称为主服务器，复制的称为从服务器

```sql
// 在A服务器上执行该命令，则A服务器为主服务器，B服务器为从服务器
SLAVEOF B-ip B-port
```

> **引入主从复制机制的目的有两个**
>
> - 一个是读写分离，分担 "master" 的读写压力
> - 一个是方便做容灾恢复



优点：

- 读写分离，写操作必须由主服务器负责，读操作的压力可以分散到从服务器上
- Slave 同样可以接受其它 Slaves 的连接和同步请求，这样可以有效的分载 Master 的同步压力；
- Master Server 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求；
- Slave Server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；



缺点：

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（**也就是要人工介入**）；
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；
- 如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。
- Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；



Redis的复制功能分为同步和命令传播两个操作：

1. 同步操作用于将从服务器的数据库状态更新到主服务器所处的数据库状态
2. 命令传播操作用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器的数据库重新回到一致状态

#### 2.8以前的旧版复制

同步：

1. 从服务器向主服务器发送SYNC命令
2. 收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录执行接下来执行的所有写命令
3. 主服务器执行完BGSAVE命令后，就把生成的RDB文件发送给从服务器，从服务器接受收并载入这个RDB文件，就可以把自己的数据库状态更新到与主服务器刚开始执行BGSAVE命令时候的数据库状态
4. 主服务器将记录在缓冲区的写命令全部发送给从服务器，从服务器执行这些命令就可以把自己的状态更新到主服务器当前的最新状态

缺点：

- 旧版复制的是主数据库中所有数据，如果是从服务器第一次复制，那没什么问题；但是如果是从服务器断开连接后想要通过复制来进行同步，实际上RDB文件中包含的断开连接前的数据是完全没有必要的，因为那段时间主从是同步的
- 假设断开期间执行的写命令很少，为了同步这几个写命令产生的不一致数据，却要让主从服务器重新执行一次SYNC命令，这种方法是十分低效的
- SYNC命令是一个十分耗费资源的操作：
  - 主服务器需要执行BGSAVE命令生成RDB文件，这个操作会耗费主服务器大量的CPU、内存和磁盘IO资源
  - 主服务器需要把RDB文件发送给从服务器，会耗费大量的网络资源
  - 接受RDB的从服务器需要载入文件，并且载入期间，从服务器会因为阻塞而无法处理命令请求

#### 2.8及之后的新版复制

Redis从2.8版本开始，使用PSYNC命令代替SYNC命令来执行同步操作，分为完整重同步和部分重同步：

- 完整重同步：用于处理初次复制的情况，执行步骤和SYNC命令基本一致

- 部分重同步：用于处理断线后重复制的情况，当从服务器断线重连后，如果条件允许，主服务器可以将断线期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令就可以恢复到一致状态

  - 主服务器和从服务器的复制偏移量

    主从服务器会分别维护一个复制偏移量，主服务器每次向从服务器传播N个字节的数据的时候，就将自己的复制偏移量加上N，从服务器收到后也加上N。因此，当双方的复制偏移量一致的时候，就能确定处于一致状态

  - 主服务器的复制积压缓冲区

    复制积压缓冲区是由主服务器维护的一个固定长度先进先出队列，默认大小为1MB。当主服务器进行命令传播的时候，它不仅会将写命令发送给从服务器，还会将写命令入队到复制积压缓冲区里，并且为队列中的每个字节记录对应的复制偏移量。这样的话当从服务器断线重连的时候，从服务器通过PSYNC命令把自己的复制偏移量发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行哪种同步操作：

    - 如果复制偏移量之后的数据仍在缓冲区中，则执行部分重同步
    - 否则执行完整重同步

  - 服务器的运行ID

    当从服务器对主服务器进行初次复制的时候，主服务器会将自己的运行ID发送给从服务器，从服务器会保存起来。当断线重连后，从服务器会向主服务器发送自己保存的运行ID：

    - 运行ID相同，说明之前连接的就是这个主服务器，可以尝试执行部分重同步
    - 运行ID不同，说明之前连接的不是这个主服务器，需要执行完整重同步操作



### 哨兵模式

> 主从复制模式中，当主服务器宕机之后，需要手动把一台从服务器切换为主服务器，而哨兵模式可以自动切换

Redis哨兵模式即设置一个独立运行的进程（哨兵），定期给主从服务器发送命令并等待其响应，从而监控运行的多个Redis实例。当发现主服务器下线的时候，会选择某个从服务器升级为主服务器，然后由新升级的主服务器代替原来的主服务器继续处理命令请求，同时继续监控原来的主服务器，当其重新上线的时候，把其作为从服务器加入到新的主服务器下

- 每10秒向主服务器发送INFO命令，可以根据其回复了解主服务器的状态

- 当Sentinel发现有从服务器加入的时候，会先为这个从服务器创建命令连接和订阅链接，并同样每10s发送INFO命令

  > 命令连接：用于Sentinel每秒发送PING检测服务器是否在线
  >
  > 订阅连接：接收服务器发来的频道信息从而发现未知的新Sentinel
  >
  > Sentinel之间只会建立命令连接



优点：

- 基于主从模式，支持读写分离，同时支持主服务器宕机自动切换

缺点：

- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。



#### 主观下线与客观下线

==主观下线==，**适用于主服务器和从服务器**。如果在规定的时间内(配置参数：down-after-milliseconds)，Sentinel 节点没有收到目标服务器的有效回复，则判定该服务器为“主观下线”。比如 Sentinel1 向主服务发送了`PING`命令，在规定时间内没收到主服务器`PONG`回复，则 Sentinel1 判定主服务器为“主观下线”。

==客观下线==，**只适用于主服务器**。 Sentinel1 发现主服务器出现了故障，它会通过相应的命令，询问其它 Sentinel 节点对主服务器的状态判断。如果超过半数以上的 Sentinel 节点认为主服务器 down 掉，则 Sentinel1 节点判定主服务为“客观下线”。



#### 投票选举

投票选举，所有 Sentinel 节点会通过投票机制，按照谁发现谁去处理的原则，选举 Sentinel1 为领头节点去做 Failover（故障转移）操作。Sentinel1 节点则按照一定的规则在所有从节点中选择一个最优的作为主服务器，然后通过发布订阅功能通知其余的从节点（slave）更改配置文件，跟随新上任的主服务器（master）。至此就完成了主从切换（故障转移）的操作。

Sentinel 负责监控主从节点的“健康”状态。当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接 Redis 集群时，会首先连接 Sentinel，通过 Sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 Sentinel 要地址，Sentinel 会将最新的主节点地址告诉客户端。因此应用程序无需重启即可自动完成主从节点切换。



### Cluster模式

> 哨兵模式下每台服务器都存储相同的数据，很浪费内存，并且需要Sentinel来专门监控服务器状态。因此Redis3.0引入了Cluster集群模式，实现了Redis的分布式存储，即每个Redis节点上都存储不同的内容

特点：

1. 多主多从、去中心化：多个主节点存储不同的数据，从节点作为备用，复制主节点（主从复制），不做读写操作，不提供服务
2. 不支持处理多个key：数据分散在多个节点，在数据量高并发的情况下会影响性能
3. 支持动态扩容节点：数据存储在哈希槽中，把哈希槽在节点间移动并不会停止服务，所以无论删除或者改变某个节点都不会造成集群不可用的状态
4. 自我检测故障、故障转移：节点之间相互通信，相互选举，不再依赖Sentinal



#### 数据分片

Redis集群没有使用一致性hash，而是引入了哈希槽（hash slot）的概念。Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置到哪个槽，集群的每个节点负责一部分hash槽。

这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D ， 我需要从节点 A， B， C 中得部分槽到 D 上。如果我想移除节点 A ，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。**由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态**。

在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是 cluster，可以理解为是一个集群管理的插件。当我们的存取的 Key到达的时候，Redis 会根据 CRC16 的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。



#### 故障检测

集群中每个节点会定期向集群中的其他节点发送PING消息，以检测对方是否在线；如果接受PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将对方标记为疑似下线。

如果集群中超过半数以上负责处理哈希槽的主节点都将某个节点标记为疑似下线，那么某个主节点就会将这个节点标记为已下线，并且广播这条消息，其他节点就会立即将该节点标记为已下线



#### 故障转移

当一个从节点发现自己正在复制的主节点下线时，从节点将开始对下线主节点进行故障转移：

1. 在该下线主节点的所有从节点中，选择一个做主节点
2. 被选中的从节点会执行SLAVEOF no one命令，成为新的主节点
3. 新的主节点会撤销对所有已下线主节点的槽指派，并将这些槽全部派给自己
4. 新的主节点向集群广播一条PONG消息，让其他节点得知主节点的变化
5. 新主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成



#### Raft算法

