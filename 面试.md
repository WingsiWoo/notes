# 面试

## JUC并发

### synchronized与volatile的区别

1. ==本质区别==
   - volatile本质是告诉JVM当前在寄存器的量不可信，必须到主存中读取；
   - synchronized是锁定该资源，只允许当前线程访问，其他线程一直阻塞等待，需要拿到锁才能访问
2. ==作用范围==
   - volatile只能作用在变量
   - synchronized可以作用在类、方法、变量
3. ==保证的性质==
   - volatile只能保证可见性，不能保证原子性
   - synchronized可以保证原子性和可见性
4. ==线程阻塞==
   - volatile不会引起线程阻塞
   - synchronized会使拿不到锁的线程阻塞
5. ==编译器优化==
   - volatile标记的变量创建过程不会被编译器优化（禁止指令重排）
   - synchronized标记的变量可能会被编译器优化



### synchronized与lock的区别

1. ==作用范围==
   - synchronized可作用于变量、方法、类
   - Lock只能作用于代码块
2. ==获取和释放==
   - synchronized会自动获取和释放，无法得知自己是否获取到锁
   - Lock需要手动获取和释放，可以知道自己是否成功获取锁
3. ==中断==
   - synchronized是不可中断的，即阻塞等待的线程会一直阻塞等待直到获取到锁
   - 如果调用`lockInterruptibly()`方法获取锁，那么处于等待过程中的线程可以被中断
4. ==Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问==



### synchronized与ReentrantLock的联系与区别

1. ==都是可重入锁==

   可重入锁即递归锁，当一个线程获取到锁后其执行到的代码需要再次获取这个锁，那么该线程的锁计数器会加1，然后可以直接执行，而无需重新获取锁。（释放锁时要锁计数器为0，即持有的所有锁都释放了才可以释放）

2. ==实现==

   - sycnhronized是Java的一个关键字，在JVM层面实现
   - ReentrantLock是Lock的一个实现类，在API层面实现

3. ==ReentrantLock增加的高级功能==

   - 等待可中断-lockInterruptibly()
   - 可以指定为公平锁/非公平锁，synchronized只能是非公平锁
   - ReentrantLock类线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的

4. ==死锁问题==

   - synchronized是有JVM自动获取和释放锁的
   - ReentrantLock需要手动获取和释放锁，使用不当可能会造成死锁问题



### synchronized锁膨胀的过程

在锁对象的对象头里有一个threadId的字段，第一次访问时该字段为空，并且使该线程持有**偏向锁**，然后把该字段设为该线程的ID。

再次进入时会先判断threadId与当前线程ID是否一致，如果一致则直接使用即可，不一致的话说明该锁正在被其他线程持有，该锁升级为**自旋锁（轻量级锁）**，当前线程通过自旋尝试获取锁

如果自旋一定次数后还不能获取到锁的话，就升级为**重量级锁**

==锁升级是为了减少锁带来的性能消耗==



## 计网

### HTTP1.0与HTTP1.1的对比

1. ==长连接（连接复用）==

   - HTTP1.0不支持长连接，每个HTTP请求都会创建一个新的TCP连接
   - HTTP1.1默认开启`Connection:Keep-Alive`开启长连接，并且HTTP1.1新增了请求的管道化处理，在一个TCP连接上可以传送多个HTTP请求和响应，在一定程度上减少了连接的创建的消耗和延迟，不过由于服务端仍然需要根据请求顺序响应，因此仍然没有解决HOLB队头阻塞问题

2. ==缓存处理==

   - HTTP1.0采用`Pragma+Expires`的方式进行缓存处理，`Expires`即把设定的过期时间和本地时间进行比较来确定缓存是否有效，如果本地时间不正确则可能达不到预期的效果
   - HTTP1.1采用`Cache-Control`来进行缓存控制

3. ==新增响应码==

   在HTTP1.1中新增了24个错误状态响应码，如`409(Conflict)`表示请求的资源 与资源的当前状态发生冲突;`410(Gone)`表示服务器上的某个资源被永久性的删除。

4. ==断点续传（分块传输）==

   - HTTP1.0不支持断点续传，传输的对象必须是完整的，如果传输中断了，下一次重新开始传输时就要从头开始传输
   - HTTP1.1支持断点续传，传输的对象可以不是完整的

5. ==请求部分对象==

   - HTTP1.0必须请求完整的对象，如果客户端只需要一部分数据，但服务端却只能传输完整的数据过来，就会造成带宽浪费
   - HTTP1.1可以通过设置range头域来请求一部分对象，返回码是`206(Partial Content)`，这样就方便了开发者自由的选择以便于充分利用带宽和连接。

6. ==Host头处理==

   - HTTP1.0认为每个IP地址只会有一个主机，因此请求URL中不传递host
   - 随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误(`400 Bad Request`)



### HTTP1.1与HTTP2.0的对比

1. ==二进制分帧==
   - HTTP1.1基于文本格式解析，但是由于文本格式的表现十分多样，因此要做到健壮性比较困难
   - HTTP2.0采用二进制分帧的方法，基于二进制解析，由于二进制只有0和1，因此要做到健壮性容易得多。并且在二进制分帧层上，HTTP2.0会把传输信息分为多个二进制帧
2. ==头部压缩==
   - HTTP1.x中，HTTP请求和响应都是由状态行、头部、消息主体三部分组成的。一般而言，消息主体都会经过压缩，或者本身传输的就是压缩过后的二进制文件。但状态行和头部却没有经过任何压缩，直接以纯文本传输。
   - 在HTTP2.0中，使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。
3. ==多路复用（连接共享）==
   - 在HTTP1.1中，浏览器和客户端在同一时间、针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞，这也是为何一些站点会有多个静态资源CDN域名的原因之一。
   - HTTP2.0中，采用多路复用，多个HTTP Request可以共用一个TCP连接。归功于二进制分帧机制，HTTP2.0不再依赖多个TCP连接去实现多流并行，每个数据流都可以被拆分成很多个互不依赖的帧，可以乱序发送，然后在另一端重新组合。不仅可以减少消息交互往返的时间，还可以避免创建新连接造成的延迟，使得 TCP 的效率更高。
4. ==服务器推送==
   - HTTP1.x中，服务器发送数据都需要先收到客户端的请求
   - HTTP2.0中，添加了服务器推送的功能，服务器可以主动的向客户端推送数据而无需等待客户端的请求，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。服务器推送还有一个很大的优势：**可以缓存**。也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。



### HTTP与HTTPS

|              |        HTTP        |              HTTPS              |
| :----------: | :----------------: | :-----------------------------: |
|     端口     |         80         |               443               |
|    安全性    | 无加密，安全性较差 |     有加密机制，安全性较高      |
|   资源消耗   |        较少        |        加密消耗较多资源         |
| 是否需要证书 |         否         |               是                |
|     协议     |   运行在TCP之上    | 运行在SSL之上，SSL运行在TCP之上 |



## JVM

### 什么是JVM内存结构？

1. ==程序计数器==

   线程私有的一块很小的内存空间，作为当前线程的行号指示器，记录当前正在执行的线程的指令地址

2. ==虚拟机栈==

   线程私有，每个方法执行时都会创建一个栈帧，用于存储局部变量表、操作数、动态链接和方法返回值等信息，如果线程请求的栈深度超过了虚拟机允许的最大深度时，就会抛`StackOverFlowError`

3. ==本地方法栈==

   线程私有，用于保存native方法的信息，JVM不会在虚拟机栈中为本地方法创建栈帧，而是简单的动态链接并直接调用该方法

4. ==Java堆==

   所有线程共享，几乎所有的对象实例和数组都要在堆上分配内存，垃圾回收的主要对象

5. ==方法区==

   存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码数据，也就是永久代。JDK8中不再存在方法区，取而代之的是元数据区，原来的方法区被分为两部分：

   - 加载的类信息（在元数据区中）
   - 运行时常量池（在堆中）



### 类加载

1. 加载

   1. 通过类的全限定类名获取该类的二进制流
   2. 将该二进制流的静态存储结构转为方法区的运行时数据结构
   3. 在堆中为该类生成一个class对象

2. 连接

   1. 验证：验证该class文件中的字节流信息是否符合JVM要求，不会威胁到JVM的安全

   2. 准备：为该class对象的静态变量分配内存，初始化其初始值（零值）

      > 这些内存都在方法区中进行分配，具体的赋值在初始化阶段完成
      >
      > 这里不包含用`final`修饰的`static`变量，因为==`final`在编译时就会分配内存了，准备阶段会显式初始化==

   3. 解析：该阶段主要完成符号引用转化为直接引用

3. 初始化：调用类构造器（此处才开始执行类中定义的java代码）

4. 使用

5. 卸载

   条件：

   1. 该类的所有实例对象都已经被回收（即Java堆中不存在任何该类的实例）

   2. 加载该类的ClassLoader已经被回收（因为JVM始终保持对类加载器的引用，而类加载器保持着对其加载的类的class对象的引用，所以如果类加载器没有被回收，那么该类的class对象始终是可达的）

      > 这也是自定义ClassLoader存在的意义，因为系统的ClassLoader永远是可达的，那么由它们加载的类永远不会被卸载

   3. 该类的class对象在任何地方都没有被引用，无法通过反射访问该类

   > 总结来说就是三个不可达：实例对象不可达、类加载器不可达、class不可达

   类的卸载其实就是在方法区中清空该类的信息



### 双亲委派机制

#### 什么是双亲委派机制？

双亲委派机制即当一个类加载器收到加载请求时，不会先自己去尝试类加载，而是先委托父类进行加载，当父类无法进行加载时才交还给子类进行加载。因此所有的类加载请求都会被传递到`Bootstrap ClassLoader`



#### 为什么要使用双亲委派机制？

1. ==避免类的重复加载==

   对于某一个类，无论是哪个类加载器要加载类，最终都会通过双亲委派机制由某一个固定的类加载器进行加载。当这个负责加载该类的类加载器发现自己已经加载过这个类了，就不会再次加载了，从而避免了类的重复加载

2. ==保护核心类库的加载==

   Java主要支持4种类加载器：

   - `Bootstrap ClassLoader` 启动类加载器：主要负责加载Java核心类库
   - `Extention ClassLoader` 标准扩展类加载器：主要负责加载扩展类
   - `Application ClassLoader` 应用类加载器：主要负责加载当前应用classpath下的所有类
   - `User ClassLoader` 用户自定义类加载器：用户自定义的类加载器，可以加载指定路径下的class文件

   ![preview](https://pic4.zhimg.com/v2-eb6ffa2110335ebb79b864e14a23c48b_r.jpg)

   > 注意它们之间不是继承关系，而是组合关系（即子类中定义一个父类加载器的属性）

   双亲委派机制使得核心类永远都是由Bootstrap ClassLoader负责加载的，避免了核心API被恶意篡改引起严重问题



#### 破坏双亲委派机制

自定义类加载器，继承ClassLoader类，重写loadClass方法和findClass方法（先尝试自己加载，如果不行再委托父加载器加载）

Tomcat，应用的类加载器优先自行加载应用目录下的class，加载不了才委派给父加载器，3个目的：

1.  对于各个webapp中的class和lib，需要相互隔离，不能出现一个应用中加载的类库会影响另一个应用的情况，并且lib要可共享，避免浪费资源
2. 使用单独的ClassLoader加载tomcat自身的类库，避免破坏
3. 热部署（修改项目代码后无需重启tomcat就能让修改生效）