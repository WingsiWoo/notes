# 面试2

## 职业规划

1. 因为自己本身的技术栈是java，所以有一个转语言的过程，目标是实习期间尽快掌握目标技术栈，努力完成实习期间的任务，拿到转正的机会
2. 初入职场的头一两年是能力上涨最快的时期，因为接触到了许多新的技术和大牛，也有了更大的平台去进行实践，所以刚开始的时候跟着公司的前辈学习，努力提升自己，保质保量的完成自己的任务。并尝试着自己去提出方案和实现方案，向成为一个能独当一面的工程师而努力
3. 除了完成自己的工作任务，还要培养自己发现问题、解决问题的能力，主动提出新的思考和需求，不断提升自己，希望自己有一天也能像之前前辈们培养我一样，我也去为公司培养优秀的人才



## 别人的评价

1. 工作认真负责：这是辅导员老师和工作室指导老师对我的评价，他们交给我的任务我都会尽可能迅速、高质量的完成
2. 活泼开朗：跟工作室的小伙伴相处和谐
3. 努力上进：工作室的师兄师姐的评价，其实在考核答辩的时候，师兄师姐有私下跟我说过我的水平目前可能跟其他同学有一定的差距，希望进入工作室之后能加把劲。我非常感谢师兄师姐能给我一个进入工作室磨练自己的机会，我也没有辜负他们的期望，不能说超过了其他的同学，因为大家都很厉害，但我可以说我赶上了他们



## 想问的问题

部门技术栈、实习生培训、是否能转正、转正流程



## HR面

1. 优点和缺点：

   - 优点：沉着冷静、自学能力强、刻苦努力、有责任感、有良好的团队协作能力和领导能力
   - 缺点：不主动去询问别人问题而多数选择自己解决，但是上大学后的这几年改变了很多，平时遇到什么问题都会提醒自己要主动跟其他同学多多交流；还年轻，缺乏磨练，但是相信自己之后会不断成长

2. 企业文化

   - 字节：追求极致、务实敢为、开放谦逊、坦诚清晰、始终创业、多元兼容
   - 抖音：就像它的广告语一样，记录美好的生活，让每一个人都有机会拿起手机发挥自己的创造能力、记录自己的美好生活
   - 部门业务：![image-20220331142437025](https://tva1.sinaimg.cn/large/e6c9d24egy1h0t1p11jgdj20m506jjs1.jpg)

3. 职业规划：

   - 实习期间内，尽快掌握部门用到的技术栈，熟悉部门的业务，高质高量的完成交给自己的任务，争取转正的机会
   - 初入职场的头两年，我认为是一个程序员成长最快速的一段时间，因为第一次参与到那么大项目的开发、同时身边有很多大牛对我进行引导，在这个期间，除了要高质高量的完成自己的任务以外，我还要尝试去提出问题、发现问题、解决问题，而不是只是听别人说然后自己埋头苦干
   - 工作了一段时间，我也成长了许多，希望我在完成工作之余，能像当初前辈们培养我一样，我也能尽自己的绵薄之力为公司培养优秀的人才

4. 最大的挫折/压力

   在基于海量数据的气象分析系统这个项目上线前一周，发现一些站点计算出来的数据有一定的偏差，而这时候气象局又要求我们尽快找出产生偏差的原因以及计算出准确的数据，在排查了程序代码问题以及手工计算和核对数据之后，发现是数据的计算方式出现了问题，而气象数据不是简单的加减乘除就得出的，我们需要在短时间内了解每一个气象指标不同时间范围的计算方式并且将这部分代码重新实现，所以当时那一段时间我们都是忙的焦头烂额的。这也给了我们团队一个警示，很多事情不能想当然地去做，不清晰的地方一定要沟通和讨论清楚，要想好了再去实施

5. 后台组组长的职责：

   第一个职责就是监督小组成员的学习进度，督促大家沟通。平时我会负责召开小组的每周技术分享会，在分享会上每个人都需要讲一下自己最近学习到的东西，既可以锻炼我们的口头表达能力，也能加深我们对自己所学知识的理解，同时也可以从其他同学的分享中发现自己遗漏的知识点和新的知识。同时，我们还在语雀上开了一个公用的笔记空间，平时我们都会把自己的学习笔记上传到语雀里。

   第二个职责就是作为指导老师和工作室同学之间沟通的桥梁，以及负责工作室的招新和培训工作。作为后台组的组长，我的缺点改善了许多（之前的我不善于询问别人问题，但是成为后台组组长后，我一直在有意识的提醒自己要以身作则，维护好工作室的学习氛围，所以会开始主动的去询问别人问题）。

6. 对自己之前面试的评价：

   总的来说有以下几点：

   1. 基础知识整体来说掌握的还是可以的，但是面试的时候我想表达的太多，导致表达出来的逻辑思维有点混乱，所以我的口头表达能力还需要锻炼
   2. 多线程方面的知识是我的一个薄弱点，还需要加深学习
   3. 算法方面，二面时候我在算法环节表现的不是很好，虽然整体的逻辑很快就写出来了，但是因为一些小细节磕磕绊绊了很久，所以我还是需要多多锻炼自己的算法思维、写代码的时候要更细心，不要粗心大意
   4. 每次面试结束之后我都会进行复盘，去寻找自己不懂的知识，然后去进行查漏补缺

7. 为什么选客户端？

   本来简历投递的是后端开发，不过被转推荐到了客户端这边。但是我对于客户端开发还是十分感兴趣的，也很乐意去学习，虽然我没有客户端开发的基础，但是我有后端开发的基础，转方向还是比较容易的，而且我也相信自己的学习能力，并且努力学习。

8. 当初为什么选择后台？

   当初有一位认识的师兄，他是后台方向的，从他那里了解到了比较多的后台方面的信息，加上自己对后台也蛮感兴趣的，而且当时在自学java，也是工作室后台方向使用的语言，所以选择了后台。

9. 接到项目后，组内怎么分工？

   首先我们会先讨论并总结这个项目的技术点和业务需求，并划分为几块，然后再各自认领各自想做的部分。平时开发的时候，我们为每个issue都设置了ddl，规定这个需求或者这个bug要在什么时候之前解决，做到任务分布准确到人，并且有明确的截止时间。这样能有效保障开发效率

10. 项目开发过程中遇到难题？

    首先就是自己多多利用搜索引擎去尝试解决问题，然后跟工作室的同学进行交流，如果还是想不到解决的问题，我们也会主动去向师兄师姐寻找帮助。但是我们工作室都鼓励大家要不断提升自己的自学能力和独立解决问题的能力，所以我们很多问题基本都是在小组内自己讨论解决的。

11. 课余时间怎么安排？

    除了平时学习课内的知识，我还会主动去学习方向的知识，在学习之余也喜欢在校园内散散步，放松一下自己

12. 学习成绩

    绩点是3.85，排在班级前列，大一大二学年也获得了奖学金

13. 了解到的前沿技术

    nginx，它是一个高性能的HTTP和反向代理WEB服务器，占有内存少，并发能力强

    - 支持高并发：能支持几万并发连接（特别是静态小文件业务环境）。
    - 资源消耗少：在3万并发连接下，开启10个 Nginx 线程消耗的内存不到200MB。
    - 可以做 HTTP 反向代理及加速缓存，即负载均衡功能，内置对 RS 节点服务器健康检查功能，这相当于专业的 Haproxy 软件或 LVS 的功能。
    - 具备 Squid 等专业缓存软件等的缓存功能。
    - 支持异步网络 I/O 事件模型 epoll（ Linux 2.6 内核 以上）。

14. 怎么了解到的？

    在学习负载均衡相关知识的时候有了解到这个开源项目，所以自己也主动去学习一下nginx

15. 面试前的准备

    - 巩固基础
    - 锻炼口头表达能力，工作室内有做模拟面试

16. 和其他工作室的区别

    我们工作室主要着重于项目的开发，所以工作室的成员都有一定实际的项目开发经验

17. 开发过程中与其他人遇到分歧怎么办？

    首先要整理一下双方的意见，讨论两种方案的优缺点，权衡一下两种方案哪种更优。我认为遇到分歧最重要的就是沟通，而且也不能一味的坚持自己的想法，也要听听其他人的想法并且反思一下自己的想法是否有缺点和不足。如果还是没有得出统一的结论的话，可以寻求其他人的帮助，我们工作室平时开发如果遇到这种情况也会经常主动去询问师兄师姐和指导老师的意见



## 算法相关

### 找出数组中出现次数超过数组长度一半的数字

1. 排序求中间值：因为出现次数超过数组长度一半，所以排序后一定处在中间的位置

2. 对数字进行计数，然后把次数与数组长度进行比较

3. 抵消法（摩尔投票法）：需要保存两个值target（表示目标元素，初始为0号元素）和times（表示目标元素的出现次数，初始为1）。然后开始遍历数组，如果遍历到的元素与target一样，则times+1；如果不一样，则times-1，如果times为0，则把target更新为当前元素，并把times置为1。由于目标元素出现的次数比其它所有元素出现的次数之和还要多，所以目标元素肯定是最后一次把次数设为1时对应的元素。

   > 本质是摩尔投票法，如果题目没有说明一定存在符合要求的数字，那么仍然要分抵消阶段和计数阶段，最后判断target的出现次数是否真的超过数组长度一半



### 229.求众数2

```java
public List<Integer> majorityElement(int[] nums) {
        int length = nums.length;
        // 出现次数超过n/k的元素最多有k-1个
        int target1 = Integer.MIN_VALUE;
        int target2 = Integer.MIN_VALUE;
        int times1 = 0;
        int times2 = 0;
        // 抵消阶段吗，如果出现次数为0则把候选人更新为当前的元素
        for(int i = 0; i < length; i++) {
            if(target1 == nums[i]) {
                times1++;
            } else if(target2 == nums[i]) {
                times2++;
            } else if(times1 == 0) {
                target1 = nums[i];
                times1 = 1;
            } else if(times2 == 0) {
                target2 = nums[i];
                times2 = 1;
            } else {
                times1--;
                times2--;
            }
        }
        // 得到候选人后计算票数是否符合要求
        times1 = 0;
        times2 = 0;
        for(int i = 0; i < nums.length; i++) {
            if(target1 == nums[i]) {
                times1++;
            } else if(target2 == nums[i]) {
                times2++;
            }
        }
        List<Integer> res = new ArrayList<>();
        if(times1 > length / 3) {
            res.add(target1);
        }
        if(times2 > length / 3) {
            res.add(target2);
        }
        return res;
    }
```



### 找出数组中重复出现的数字（数组长度为n，里面的数字为0～n-1）

1. 排序+双指针：排序后重复数字一定相邻

2. 原地交换：把数字i交换到下标为i的位置上，如果当前数字不在正确的位置，并且要交换到的位置上已经有正确的数字在了，那么就说明当前数字是重复的

   ```java
   public int findRepeatNumber(int[] nums) {
     // nums[i]应该放在下标nums[i]上
     for(int i = 0; i < nums.length; ) {
       if(i == nums[i]) {
         i++;
         continue;
       }
       // 需要交换，并且交换的目标位置上已经有正确数字了
       if(nums[i] == nums[nums[i]]) {
       	return nums[i];
       }
       // 把当前位置上的数字nums[i]交换到正确的位置上，指针不继续向前移动，是因为之后要继续交换保证当前位置有正确的数字
       int temp = nums[nums[i]];
       nums[nums[i]] = nums[i];
       nums[i] = temp;
     }
     return -1;
   }
   ```



### 最大子数组和（具有最大和的连续子数组）

动态规划，因为只使用到dp[i - 1]和dp[i]，所以直接建立两个变量记录就行

```java
public int maxSubArray(int[] nums) {
  // dp[i]表示以nums[i]为结尾的连续子数组的最大和
  int[] dp = new int[nums.length];
  int max = nums[0];
  dp[0] = nums[0];
  for(int i = 1; i < nums.length; i++) {
    // 前者表示当前元素加上前面的连续子数组，后者表示从当前元素开始重新计算连续子数组
    dp[i] = Math.max(dp[i - 1] + nums[i], nums[i]);
    max = Math.max(dp[i], max);
  }
  return max;
}
```



### 491.递增子序列

给你一个整数数组 nums ，找出并返回所有该数组中不同的递增子序列，递增子序列中 至少有两个元素 。你可以按 任意顺序 返回答案。

数组中可能含有重复元素，如出现两个整数相等，也可以视作递增序列的一种特殊情况。

```java
List<List<Integer>> res;
List<Integer> ans;
public List<List<Integer>> findSubsequences(int[] nums) {
  res = new LinkedList<>();
  ans = new LinkedList<>();
  dfs(0, Integer.MIN_VALUE, nums);
  return res;
}

private void dfs(int cur, int last, int[] nums) {
  // cur为当前选择的指针，last为上一个选择的元素
  if(cur == nums.length) {
    if(ans.size() >= 2) {
    	res.add(new ArrayList<>(ans));
    }
    return;
  }
  // 如果有相同元素，需要考虑：前后都选/前后都不选/选前不选后
  // 选择当前元素
  if(nums[cur] >= last) {
    // choose
    ans.add(nums[cur]);
    dfs(cur + 1, nums[cur], nums);
    ans.remove(ans.size() - 1);
  }
  // 只有当当前的元素不等于上一个选择的元素的时候，才考虑不选择当前元素，直接递归后面的元素
  if(nums[cur] != last) {
  	dfs(cur + 1, last, nums);
	}

}
```



### 最长递增子序列的长度

1. 动态规划O(N^2^)

   ```java
   public int lengthOfLIS(int[] nums) {
     if(nums.length <= 1) {
       return nums.length;
     }
     // dp[i]表示0-i的最长递增子序列的长度
     int[] dp = new int[nums.length];
     // 全部初始化为1，一个数字本身是一个长度为1的递增子序列
     for (int i = 0; i < nums.length; i++) {
       dp[i] = 1;
     }
     int res = 0;
     for (int i = 1; i < nums.length; i++) {
       // j指向在i之前的一个递增子序列
       for (int j = 0; j < i; j++) {
         if(nums[i] > nums[j]) {
           // 选取最长的一个递增子序列，这里的dp[i]实际上是以前初始化过的dp[j]+1
           dp[i] = Math.max(dp[j] + 1, dp[i]);
         }
       }
       if(dp[i] > res) {
         res = dp[i];
       }
     }
     return res;
   }
   ```

2. 耐心排序/二分法O(nlogn)

   ```java
   public int lengthOfLIS(int[] nums) {
     if(nums.length <= 1) {
     	return nums.length;
     }
     // 实际上可以看作是一个小顶堆，只能把比top小的元素压入top
     int[] top = new int[nums.length];
     int count = 0;
     for(int i = 0; i < nums.length; i++) {
       int l = 0;
       int r = count;
       // 二分查找可以放入的堆
       while(l < r) {
         int mid = (l + r) / 2;
         if(top[mid] < nums[i]) {
         	l = mid + 1;
         } else {
         	r = mid;
         }
       }
       // 新建一个堆放元素
       if(l == count) {
         top[l] = nums[i];
         count++;
       } else {
         // 当有多个可选的时候，要放到最左边的堆，这样子就可以保证多个堆堆顶元素有序
       	top[l] = nums[i];
       }
     }
     // 牌的堆数就是最长递增子序列的长度
     return count;
   }
   ```



### 交换数字，不能用辅助空间

1. 加减法

   ```java
   [a,b]
   [a,a+b]
   [(a+b)-a, a+b]
   [b,(a+b)-b]
   [b,a]
   
   // a+b
   nums[1] = nums[0] + nums[1];
   // a+b-a=b
   nums[0] = nums[1] - nums[0];
   // a+b-b=a
   nums[1] = nums[1] - nums[0];
   ```

2. 位运算

   ```java
   // 异或运算
   nums[0]=nums[0]^nums[1];
   nums[1]=nums[0]^nums[1];
   nums[0]=nums[0]^nums[1];
   ```



### 交换某个整数的奇数位和偶数位

```java
// 奇数为全1为0x55555555，偶数位全1为0xaaaaaaaa
// 提取奇偶数位按位与即可
return ((num & 0x55555555) << 1) + ((num & 0xaaaaaaaa) >> 1);
```



### 子数组交换-arr[0:k-1]与arr[k:n-1]两个子数组交换位置

1. 开辟O(N)的辅助空间，先把arr[k:n-1]放进去，然后放arr[0:k-1]

2. 分治算法：只需要交换一个元素时的辅助变量的O(1)空间，甚至这个辅助空间可以继续优化，不使用

   - 当左右两个子数组长度相等时，直接讲对应元素进行互换

   - 左边长度<右边长度，把左边子数组与右边子数组后面长度大小相同的部分进行交换

     > 此时arr[n-k:n-1]（原来的左边子数组）已交换到位，剩下递归交换arr[0-k-1]与arr[k:n-k-1]

   - 左边长度>右边长度，把右边子数组与左边子数组前面长度大小相同的部分进行交换

     > 此时arr[0:n-1-k]（原来的右边子数组）已交换到位，剩下递归交换arr[n-k:k-1]与arr[k:n-1]

   ```java
   public void swap(int[] arr, int k) {
           realSwap(arr, 0, k - 1, k, arr.length - 1, k);
       }
   
   private void realSwap(int[] arr, int ll, int lr, int rl, int rr, int k) {
     if(ll > lr || rl > rr) {
     	return;
     }
     // same length,just swap
     if(lr - ll == rr - rl) {
       for(int i = 0; i <= lr - ll; i++) {
         int temp = arr[ll + i];
         arr[ll + i] = arr[rl + i];
         arr[rl + i] = temp;
     	}
     	return;
     }
     // left > right,replace right to high left
     if(lr - ll > rr - rl) {
       // after swap,[ll,ll+rr-rl] is already in right place
       for(int i = 0; i <= rr - rl; i++) {
         int temp = arr[ll + i];
         arr[ll + i] = arr[rl + i];
         arr[rl + i] = temp;
       }
       // continue swap [ll+rr-rl+1,k-1] and [k, rr]
       realSwap(arr, ll + rr - rl + 1, k - 1, k, rr, k);
       return;
     }
     // left < right,replace left to low right
     if(lr - ll < rr - rl) {
       // after swap,[rr-(lr-ll),rr] is already in right place
       for(int i = lr - ll; i >= 0; i--) {
         int temp = arr[lr - i];
         arr[lr - i] = arr[rr - i];
         arr[rr - i] = temp;
       }
       // continue swap [0,k-1] and [k,rr-(lr-ll)-1]
       realSwap(arr, ll, k - 1, k, rr - (lr - ll) - 1, k);
       return;
     }
   }
   ```



### 数组中的第k个最大元素

1. 维护一个大小为k的小顶堆，如果堆的大小超过k则移除堆顶元素（保证堆中存储的是k个最大元素），最后堆顶的就是第k个最大元素

   ```java
   public int findKthLargest(int[] nums, int k) {
     PriorityQueue<Integer> queue = new PriorityQueue<>();
     for(int i = 0; i < nums.length; i++) {
       queue.offer(nums[i]);
       if(queue.size() > k) {
       	queue.poll();
       }
     }
     return queue.poll();
   }
   ```

2. 快排简化版，（降序排序）如果分界点为k-1（即第k个）则返回分界点；如果分界点大于k-1则只需要对左区间继续快排；反之只需要对右区间继续快排

   ```java
   public int findKthLargest(int[] nums, int k) {
     int p = partition(nums, 0, nums.length - 1);
     while(p != k - 1) {
       if(p > k - 1) {
       	p = partition(nums, 0, p - 1);
       } else {
       	p = partition(nums, p + 1, nums.length - 1);
       }
     }
     return nums[p];
   }
   
   // 降序排序
   private int partition(int[] nums, int l, int r) {
     int temp = nums[l];
     while(l < r) {
       while(l < r && nums[r] <= temp) {
       	r--;
       }
       if(l < r) {
       	nums[l++] = nums[r];
       }
       while(l < r && nums[l] > temp) {
       	l++;
       }
       if(l < r) {
       	nums[r--] = nums[l];
       }
     }
     nums[l] = temp;
     return l;
   }
   ```



### 128.最长连续序列

给定一个未排序的整数数组 `nums` ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。

1. 哈希表记录右边界

   ```java
   public int longestConsecutive(int[] nums) {
     // value表示key可以到达的最大右边界
     Map<Integer, Integer> map = new HashMap<>();
     int max = 0;
     for(int i = 0; i < nums.length; i++) {
       // 默认的右边界为自己
       map.put(nums[i], nums[i]);
     }
     for(int num : nums) {
       if(!map.containsKey(num - 1)) {
         int right = map.get(num);
         // 去最远边界
         while(map.containsKey(right + 1)) {
         	right = map.get(right + 1);
         }
         // 更新最远边界
         map.put(num, right);
         max = Math.max(max, right - num + 1);
       }
     }
     return max;
   }
   ```

2. 哈希表存储连续区间长度

   当num是第一次出现：

   1. 分别获取左相邻数字num-1的连续区间长度（左区间）和右相邻数字num+1的连续区间长度（右区间）

      > 哈希表中存储的是连续区间的长度，可以表示三种区间：
      >
      > - 以key为右边界的区间
      > - 以key为左边界的区间
      > - key在中间的区间
      >
      > 因为num没有出现过，所以左相邻数字肯定就只能表示第二种区间了，因为1、3都会包含num；右相邻数字同理

   2. 更新当前的区间长度为left+right+1

      > 通过num把左右区间联通

   3. 更新最长区间长度ans

   4. 更新左右边界的区间长度

      > 左右两个区间联通了，所以需要更新边界点对应的长度

   ```java
   public int longestConsecutive(int[] nums) {
     // value表示包含key的连续区间的最大长度
     Map<Integer, Integer> map = new HashMap<>();
     int max = 0;
     for(int num : nums) {
       if(!map.containsKey(num)) {
         int left = map.getOrDefault(num - 1, 0);
         int right = map.getOrDefault(num + 1, 0);
         map.put(num, left + right + 1);
         map.put(num - left, left + right + 1);
         map.put(num + right, left + right + 1);
         max = Math.max(max, left + right + 1);
       }
     }
     return max;
   }
   ```



### 41.缺失的第一个正数

给你一个未排序的整数数组 `nums` ，请你找出其中没有出现的最小的正整数。

1. 置换：把数字i（正数）放到下标i-1上，置换完成后遍历一次数组，位置上没有正确数字的就是缺失的第一个正数

   ```java
   public int firstMissingPositive(int[] nums) {
     // number i to index i-1
     for(int i = 0; i < nums.length; i++) {
       // 数组中可能有重复元素，最后一个条件是为了避免死循环
       while(nums[i] != i + 1 && nums[i] - 1 < nums.length && nums[i] - 1 >= 0 && nums[nums[i] - 1] != nums[i]) {
         // 当前数字放到其正确位置上
         int temp = nums[nums[i] - 1];
         nums[nums[i] - 1] = nums[i];
         nums[i] = temp;
       }
     }
     int i = 0;
     for(; i < nums.length; i++) {
       if(nums[i] != i + 1) {
       	return i + 1;
       }
     }
     return i + 1;
   }
   ```

2. 哈希表：把数组元素都放入哈希表中，然后从1开始枚举判断是否存在

   ```java
   public int firstMissingPositive(int[] nums) {
   Map<Integer, Integer> map = new HashMap<>();
   for(int i = 0; i < nums.length; i++) {
     if(!map.containsKey(nums[i])) {
     	map.put(nums[i], 1);
     }
   }
   int i = 1;
   while(map.containsKey(i)) {
   	i++;
   }
   return i;
   }
   ```



### 25.K个一组翻转链表

```java
public ListNode reverseKGroup(ListNode head, int k) {
  ListNode tailNext = head;
  int i = 0;
  while(i < k) {
    if(tailNext == null) {
      // 不足k个，无需反转
      return head;
    }
    tailNext = tailNext.next;
    i++;
  }
  // tailNext为下一组第一个节点
  ListNode newHead = reverse(head, tailNext);
  head.next = reverseKGroup(tailNext, k);
  return newHead;
}

public ListNode reverse(ListNode head, ListNode tail) {
  ListNode pre = null;
  ListNode cur = head;
  ListNode next = head;
  while(cur != tail) {
    next = cur.next;
    cur.next = pre;
    pre = cur;
    cur = next;
  }
  // 返回反转后的链表头节点
  return pre;
}
```



### 33.搜索旋转排序数组

![image-20220323131352928](https://tva1.sinaimg.cn/large/e6c9d24egy1h0jqozk8xrj20e905ugm1.jpg)

二分数组，一定有其中一部分是有序的

```java
public int search(int[] nums, int target) {
  // 旋转指k-n-1与0-k-1交换
  int low = 0;
  int high = nums.length - 1;
  while(low <= high) {
    int mid = (low + high) / 2;
    if(nums[mid] == target) {
    	return mid;
    }
    // 0-mid有序
    if(nums[0] <= nums[mid]) {
      // target在0-mid区间
      if(nums[0] <= target && nums[mid] > target) {
      	high = mid - 1;
      } else {
        // 不在0-mid区间
        low = mid + 1;
      }
    } else {
      // 0-mid无序
      if(nums[mid] < target && nums[nums.length - 1] >= target) {
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
  }
  return -1;
}
```



### 92.反转链表2

![image-20220324110710896](https://tva1.sinaimg.cn/large/e6c9d24egy1h0ksngm1sej20en0ahwf2.jpg)

递归法：把问题转化为反转链表的前n个节点

```java
public ListNode reverseBetween(ListNode head, int left, int right) {
        if(head == null || head.next == null) {
            return head;
        }
        if(left == 1) {
            // 相当于反转前right个元素
            return reverse(head, right);
        }
        head.next = reverseBetween(head.next, left - 1, right - 1);
        return head;
    }

    // 反转链表前n个节点
    private ListNode reverse(ListNode head, int n) {
        ListNode pre = null;
        ListNode cur = head;
        ListNode next = head;
        int count = 0;
        while(cur != null && count++ < n) {
            next = cur.next;
            cur.next = pre;
            pre = cur;
            cur = next;
        }
        head.next = cur;
        return pre;
    }public ListNode reverseBetween(ListNode head, int left, int right) {
        if(head == null || head.next == null) {
            return head;
        }
        if(left == 1) {
            // 相当于反转前right个元素
            return reverse(head, right);
        }
        head.next = reverseBetween(head.next, left - 1, right - 1);
        return head;
    }

    // 反转链表前n个节点
    private ListNode reverse(ListNode head, int n) {
        ListNode pre = null;
        ListNode cur = head;
        ListNode next = head;
        int count = 0;
        while(cur != null && count++ < n) {
            next = cur.next;
            cur.next = pre;
            pre = cur;
            cur = next;
        }
        head.next = cur;
        return pre;
    }
```





## 聪明题

### 四辆小车,每辆车加满油可以走一公里,问怎么能让一辆小车走最远

中心思想：

1. 先一起走一段路程s
2. 走完s后，任选一辆车，把其剩余的油平分给剩余的车，使得剩余的车加满
3. 重复2直到最后一辆车没有

> s选择的标准：一辆车的总油量/行驶车辆总数 所能行走的路程，这样就能保证走完s后一辆车剩下的油刚好能把其他车加满

1. 出发：假设初始容量为12L

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   | 12L  | 12L  | 12L  | 12L  |

   12/4=3，所以接下来行走的路程s定义为3L油能走的路程

2. 行走3L油路程后，汽车情况如下

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  9L  |  9L  |  9L  |  9L  |

   任选一辆车，把其剩下的油平分到剩余车上，给剩余车加满油，此处选择1

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  0L  | 12L  | 12L  | 12L  |

   剩余车辆继续行驶，新的s为12/3=4，即4L油能走的路程

3. 行走4L油路程后，汽车情况如下

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  0L  |  8L  |  8L  |  8L  |

   继续，选择2号车给剩余车加油

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  0L  |  0L  | 12L  | 12L  |

   剩余车辆继续行驶12/2=6，6L油能走的路程

4. 走6L油的路程后

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  0L  |  0L  |  6L  |  6L  |

   选择3给其他车加油

   |  1   |  2   |  3   |  4   |
   | :--: | :--: | :--: | :--: |
   |  0L  |  0L  |  0L  | 12L  |

5. 最后剩下4号车行驶12L的路程，所有油耗完

6. 所以可以行驶的最远距离为(3L+4L+6L+12L)/12L=25/12公里



### 10个箱子，每个箱子里面都有n个石头，这些石头长的一模一样。正常的石头重a克，有一个箱子里的石头轻一些，每个石头是a-1克。怎么只称一次，找出这个不一样的箱子

把箱子按照1-10进行编号，1号箱子取一个石头、2号箱子取两个……以此类推。如果所有石头都是正常的，那么总重量应该是55a，假设当前总重量为x，那么55a-x就是不一样的箱子的编号



## 腾讯TEG面经

### count(*)操作

首先要讲一下MySQL中的存储引擎对于数据行数的存储：

1. MyISAM存储了数据的精确行数，如果是不带条件的count(\*)操作，在MyISAM存储引擎中是很快的，直接去取就行了；但是如果是带条件的，就要一个个去统计了*

2. InnoDB中只存储了一个大概行数，没有存储具体行数，主要原因是事务。当执行count(\*)操作的时候，==查询优化器倾向于使用索引长度短、字段重复值多（索引基数小）的索引来进行统计== ➡️ 应该也是什么时候给性别建立索引的答案，因为性别是一个标识字段，给其加上索引之后可以大大加快count(\*)操作

   > InnoDB没有存储具体行数的原因：不同事务执行count(\*)操作看到的结果可能是不一样的，主要是由于事务的隔离性。比如一张表本来有100条数据，事务AB并发执行，其中事务A插入一条数据后count(\*)，事务B删除一条数据后count(\*)。那么由于两个事务的增删操作执行后事务都还没有提交，所以其修改对于其他操作是不可见的。所以事务A的结果为101，而事务B的结果是99

优化：

1. 如果不需要十分精确的数据，那么可以不执行count(\*)，而是使用show table status命令来查询模糊行数
2. 建立辅助索引，可以给表中的一些标识字段（比如tinyint类型，标识通常长度小并且基数小）加索引，执行count(\*)的时候查询优化器就可以使用这个索引来进行统计，有效加速查询操作

count操作的效率排序：count(字段) < count(主键id) < count(1) ≈ count(*)

1. count(字段)，会进行全表扫描逐行判断（如果定义为非空那就无需判断是否为NULL），按行累加
2. count(主键)，会进行全表扫描，取出主键然后按行累加
3. count(1)和count(*)的优化逻辑一样，不会把字段取出来，而是通过索引进行计算



### #{}为什么可以防止SQL注入

SQL注入是指通过把SQL命令作为参数插入到SQL命令中，最终达到欺骗服务器执行非本意的SQL命令的情况，注入攻击的本质是把用户输入的数据当作代码执行

例：

```sql
# 因为 # 在sql语句中是注释，将后面密码的验证去掉了，而前面的条件中1 = 1始终成立，所以不管密码正确与否，都能登录成功。
SELECT * FROM XXX WHERE userName = admin or 1 = 1 # and password = 111
```

#{}在MySQL底层是运用了PreparedStatement预编译，传入的参数会以？形式显示，而不是简单的字符串拼接。因为sql的输入只有在sql编译的时候起作用，当sql预编译完后，传入的参数就仅仅是参数，不会参与sql语句的生成。

> 同时，预编译可以提高执行效率，因为数据库处理一条SQL语句的时候，需要完成对SQL语句的解析、检查语法以及生成代码，一般来说，处理时间比时间执行要长，而预编译语句字啊创建的时候就已经将SQL语句发送给了DBMS，完成了解析、检查语法以及生成代码的过程，因此，当一个SQL语句多次执行的时候，使用预编译可以减少处理时间

${}没有使用预编译，传入的参数直接和sql进行拼接，因此会产生SQL注入的漏洞



### Mybatis与Mybatis-Plus

JDBC过程：

1. 加载Driver，注册数据库驱动
2. 通过DriverManager，使用url、用户名和密码与数据库建立连接Connection
3. 通过Connection，创建执行对象SqlStatement/PreparedStatement
4. 调用Statemnt.excute()/excuteUpdate()方法执行sql语句，结果返回到ResultSet
5. 对结果集进行处理
6. 按顺序释放资源：ResultSet结果集、Statemnt执行对象、Connection连接

Mybatis：

根据XML配置文件创建SqlSessionFactory，SqlSessionFactory再根据配置（来源于配置文件或者代码中的注解）来获取一个SqlSession，SqlSession包含了执行Sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后需要关闭SqlSession。

- 优点：

  - 基于sql编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响。sql写在XML或者Java注解里，一定程度上解除了sql语句与程序代码的耦合，便于统一管理
  - 提供XML标签，支持编写动态sql语句，并可重用
  - 封装了JDBC，消除了JDBC大量的冗余代码，无需手动开关连接
  - 可以很好的与各种数据库兼容（JDBC支持的都支持）
  - 提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护

- 缺点：

  - 需要程序员手动编写sql语句

  - sql语句依赖于数据库，导致数据库可移植性差，不能随意更换数据库

  - 二级缓存机制不佳

    > mybatis中的缓存是指mybatis在执行一次sql语句之后，这条sql语句会被缓存起来，当再次执行相同语句的时候，就会直接从缓存中提取，而不是再次执行sql命令。
    >
    > - 一级缓存：SqlSession级别，相同的sql语句，会优先命中一级缓存，避免直接对数据库进行查询，以提高性能。
    >   - 如果在两次查询之间执行更新操作，会对一级缓存进行刷新，导致一级缓存失效
    >   - 每个SqlSession内有一个一级缓存，所以两个SqlSession执行同一个sql语句，还是会对数据库进行两次查询
    > - 二级缓存：如果想要多个SqlSession共享缓存，就需要开启二级缓存。
    >   - 需要手动开启，在mybatis配置文件中设置`<setting name = “cacheEnabled" value = “true">`
    >   - 开启二级缓存后，数据的查询执行的流程就是 二级缓存 -> 一级缓存 -> 数据库。
    >   - 多表操作中存在的脏数据问题：假设有两张表user和dept，其中对user和dept的联表查询操作写在了UserMapper.xml中，当第一次查询并缓存后，对dept的表进行了修改，此时二级缓存仍然有效，之后进行查询就会看到脏数据

Mybatis-Plus：

- 无侵入：只做增强不做改变，引入它不会对现有工程产生影响
- 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求
- 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错
- 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎（反向生成Mapper）
- 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询



### 如何保证一个变量在共享内存的并发安全

#### ThreadLocal（无锁）

当创建一个ThreadLocal变量时，访问这个变量的每个线程都有这个变量的一个本地副本，当多个线程操作这个变量的鹅时候，实际上是操作自己本地内存的变量，而不是共享内存中的变量，从而避免了线程安全的问题。

每个Thread类有一个ThreadLocalMap成员变量，key为ThreadLocal对象（弱引用），value为线程局部变量（强引用）。

对应关系：ThreadLocal对应一个共享变量，每个线程调用ThreadLocal.set()方法把ThreadLocal-本地变量保存到自己的ThreadLocalMap中，之后就可以通过ThreadLocal.get()方法到ThreadLocalMap中获取本地变量

特殊事项：

1. ThreadLocalMap中的key为弱引用：如果使用强引用，则ThreadLocalMap一直持有对ThreadLocal的强引用，因此在线程消亡/手动移除key之前，ThreadLocal都无法被回收，会引起内存泄漏问题

2. ThreadLocal使用完后需要执行remove()方法：如果ThreadLocal使用完成后没有执行remove就被回收了，那么ThreadLocalMap是无法通过key访问到本地变量的，也就是本地变量实际上不会再被使用到了，应该被回收。但是ThreadLocalMap一直持有对其的强引用，所以value不会被回收

   > ThreadLocalMap本身并没有为外界提供取出和存放数据的API，我们所能获得数据的方式只有通过ThreadLocal类提供的API来间接的从ThreadLocalMap取出数据，所以，当我们用不了key（ThreadLocal对象）的API也就无法从ThreadLocalMap里取出指定的数据。
   >
   > value不设置为弱引用，主要是因为不清楚这个value除了map的引用是否还存在其他的引用，如果不存在其他引用，那么GC的时候就会把value给回收了，如果此时ThreadLocal还在使用，就会产生value为null的错误

3. ThreadLocalMap是ThreadLocal的一个内部类，其类似一个哈希表，使用开放定址法解决哈希冲突

   > 1. 开放定址法/再散列法：当p=hash(key)产生哈希冲突时，以p为基础再次产生新的哈希地址，直到不冲突
   >    - 线性探测：冲突发生时顺序查看下一单元
   >    - 二次探测：左右横跳进行跳跃式探测
   >    - 伪随机探测：根据伪随机数列查看下一单元
   > 2. 再哈希法：构造多个不同的哈希函数，当发生冲突时使用另一个哈希函数
   > 3. 链地址法：数组中元素为链表，当发生冲突时插入到链表中，一个链表中存储的都是同义词

4. 最经常的使用场景：数据库Connection，以不加锁的方式解决了线程安全问题

延伸 ➡️ ：

1. 四种引用

   强引用：直接`new`

   软引用：通过`SoftReference`创建，在**内存空间不足**的时候直接销毁，即它可能最后的销毁地点是在老年区

   弱引用：通过`WeakReference`创建，在**GC**的时候直接销毁。即其销毁地点必定为伊甸区

   虚引用：通过`PhantomReference`创建，它和不存在一样，**「非常虚，只能通过引用队列在进行一些操作，主要用于堆外内存回收」**



#### 互斥同步（悲观锁）

synchronized、ReentrantLock

#### 非阻塞同步（乐观锁）

CAS（AtomicStampedReference、AtomicMarkableReference解决ABA问题，其中前者维护一个版本号，后者维护boolean类型的标记来标记值是否修改）



### volatile

#### 实现原理

1. 保证可见性：volatile修饰的变量强制要求到主存中读取最新数据，修改后要立刻写回主存以保证主存中的数据是最新的

2. 禁止指令重排序：底层原理是内存屏障，经典应用就是懒汉式单例模式中的双重检查锁+volatile

   - 写操作前LoadStore，后LoadLoad

     > LoadStore：禁止前面的写与后面的写重排
     >
     > LoadLoad：禁止前面的写和后面的读/写重排

   - 读操作前LoadLoad，后LoadStore

   > 实例化一个对象其实可以分为三个步骤：
   >
   > 1. 分配内存空间
   > 2. 初始化对象
   > 3. 将内存空间的地址赋值给对应的引用
   >
   > 但是上面的三个步骤不一定按照这个顺序执行。在多线程环境下，如果步骤3在步骤2之前执行，可能会提前把一个未初始化的对象引用暴露出来，从而导致不可预料的结果。



#### 一定安全吗

volatile不保证原子性，比如i++的场景/没有使用volatile的懒汉式单例模式：

1. 线程1读取i=1后阻塞
2. 线程2一气呵成完成i++，此时i=2
3. 线程1苏醒，因为之前已经读取过i=1，所以继续执行i++
4. 结果就是明明执行了两次i++，但是最终i的结果仍然为2

> 可以模仿懒汉式单例模式，加上双重检查锁



#### 使用场景

1. 对变量的写操作不依赖于当前值
2. 该变量没有包含在具有其他变量的不变式中

- 状态标志：变量用于指示某个一次性事件是否发生
- 一次性安全发布：懒汉式单例模式，避免因为指令重拍而把未初始化的对象引用提前暴露的情况
- 独立观察：比如某个变量可能随时会发生变化，需要定期观察其最新值，所以需要volatile保证该变量的可见性
- 读写锁：如果读多写少，可以使用synchronized保证写操作的并发安全，使用volatile保证数据的可见性，这样的话读操作就不需要加锁，而且由于读多写少，所以加锁性能影响不会太大。**比如ConcurrentHashMap就是synchronized+volatile的形式来保证并发安全**



### equals与hashCode

1. 重写前的equals和==一样，都是对地址进行比较；一般的类都会对equals方法重写，通过值来比较是否相等
2. hashCode方法主要是针对散列表结构的使用，比如HashMap、HashSet等，散列表进行判断元素的时候，先比较hashCode，只有hashCode相同的时候才会通过equals进行比较，从而大大减少了equals比较的次数，极大的提高了数据的存储性能
3. equals结果为true，hashCode一定相同
4. hashCode相同，equals不一定为true（哈希冲突）；同理，equals为false，hashCode不一定不同
5. 如果类不会在本质是散列表的数据结构中使用的话，不重写hashCode方法不会有什么影响，但是如果有使用的话，就必须重写，否则达不到预期的使用效果



### RESTful

RESTful，即表象层状态转换：

1. RE-Representational：每一个URI代表一种资源
2. S-State：客户端通过四个HTTP动词（GET、POST、PUT、DELETE），对服务端资源进行操作，实现表现层状态转换
3. T-Transfer：客户端和服务器之间，传递这种资源的某种表现层



#### 六大原则

1. C/S架构：客户端与服务端分离，数据存储在服务端。两端彻底分离的好处就是两端可以单独开发，互不干扰、服务端的扩展性变强、客户端代码的可移植性变强

2. 无状态：HTTP请求本身就是无状态的，大大提高了服务端的健壮性和可扩展性。不过无状态需要客户端每次请求都带上重复的信息来证明自己的身份

3. 统一的接口：这个是REST架构的核心，客户端只需要关注实现接口即可，接口可读性增强，使用人员方便调用

4. 一致的数据格式：比如通过HTTP返回的数据内有MIME type信息，可以从中得知返回数据的具体格式，这种技术称为超媒体（超文本链接）

   > ```javascript
   > // 状态行：版本+状态码+状态码描述文字
   > HTTP/1.1 200 OK
   > // 响应头
   > Date: Mon, 27 Jul 2009 12:28:53 GMT
   > Server: Apache/2.2.14 (Win32)
   > Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
   > Content-Length: 88
   > Content-Type: text/html
   > Connection: Closed
   > // 空行
   > 
   > // 消息主体
   > <html>
   >    <body>
   > 
   >    <h1>Hello, World!</h1>
   > 
   >    </body>
   > </html>
   > ```

5. 系统分层：客户端通常无法表明自己是直接还是间接与端服务器进行连接，分层时同样要考虑安全策略。
6. 可缓存：在万维网上，客户端可以缓存页面的响应内容。因此响应都应隐式或显式的定义为可缓存的，若不可缓存则要避免客户端在多次请求后用旧数据或脏数据来响应。管理得当的缓存会部分地或完全地除去客户端和服务端之间的交互，进一步改善性能和延展性。



### 负载均衡

随着业务流量越来越大，单台服务器无法满足业务需求的时候，就需要把多台服务器组成集群系统来提高整体的处理性能。使用统一的流量入口来对外提供服务，也就是一个流量调度器，通过某些算法，讲用户大量的请求流量均衡的分发到集群中不同的服务器上，就是所谓的负载均衡

好处：

1. 提高了系统的整体性能
2. 提高了系统的扩展性
3. 提高了系统的可用性



#### 正向代理与反向代理

- 正向代理：客户端非常明确要访问的服务器地址，正向代理代理客户端，替客户端向服务器发出请求（比如科学上网就是正向代理）
- 反向代理：反向代理隐藏了服务器的信息，它代理的事服务器端，代替其接收请求，然后把客户端的请求分发到不同服务器上，至于怎么合理分发客户端的请求，就是负载均衡要做的事了。反向代理中客户端并不知道具体是哪台服务器处理了自己的请求。



#### 负载均衡常用算法

1. 轮询：遍历服务器节点列表，并按照节点次序每轮选择一台服务器处理请求，当所有节点都被调用过一次之后，就从第一个节点重新开始一轮遍历
   - 该算法中每个请求按照时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群
   - 对于性能不同的服务器集群，该算法容易引发资源分配不合理等问题
2. 加权轮询：解决了普通轮询的弊端，通过加权的方式让性能较好的服务器被选择的优先级较高，负责处理更多的请求

> 以上两种算法，都存在Session不共享的问题。一个客户端多次请求可能会由不同的服务器处理，可能会需要客户端多次认证（因为新请求的服务器上面并没有存储客户端的Session信息）

3. ip_hash：根据客户端ip的hash值来分配服务器，可以保证同IP发出的多次请求会映射到同一个服务器上，一定程度上解决了集群部署环境下Session不共享的问题

   > 分布式Session的实现：
   >
   > 1. 把Session存储在客户端，客户端每次请求的时候把Session放在Cookie中，携带Cookie请求
   >
   > 2. Session复制：每个服务器上都存储一份Session，当一个服务器上的Session发生变化的时候，要广播通知其他服务器也进行相应修改，维护成本高、耗费空间大
   >
   > 3. 共享Session：服务端无状态化，把Session存储在缓存中间件（如Redis）中统一管理，保障分发到每一个服务器的响应结果都一致
   >
   > 4. Ngin ip_hash：通过对ip进行哈希映射，保证同个IP多次请求映射到同一个服务器上
   >
   >    ➡️ 如果服务器宕机了怎么办？
   >
   >    **一致性哈希算法**：普通的哈希算法是hash值对服务器总数取余，当集群中一个服务器宕机了，就会导致服务器总数发生变化，从而引起大量的哈希结果发生改变，也就是只有一台服务器宕机了，但是由于映射结果的改变，引起大量的Session需要重新存储（请求映射到新的服务器上）。
   >
   >    为了解决这个问题，引入了一致性哈希算法，即不再对服务器总数这个会变化的数取余，而是对一个固定的数2^32^取余。把0 ~ (2^32)-1的数字看作是一个闭合的环形，客户端ip hash和服务器都是这个哈希环上的节点，ip hash的映射结果就是其在环上顺时针遇到的第一个服务器节点。引入一致性哈希算法后，当某个服务器宕机了，则原本映射到该服务器的请求会移动到顺时针的下一个服务器节点，而不会影响其他的请求。
   >
   >    ➡️ 一致性哈希算法的优化
   >
   >    一致性哈希算法还存在一个问题，假设服务器1和服务器2是顺时针相邻的两个服务器，当服务器1宕机的时候，原本请求到服务器1的请求就会全部迁移到服务器2中，导致服务器2的压力急速上升，甚至可能会引起连锁反应，服务器2崩溃，服务器12的请求迁移到服务器3……
   >
   >    解决方法就是在哈希环中插入若干个虚拟节点，这些虚拟节点也是到服务器的映射，当一个服务器宕机后，其对应的虚拟节点也会从哈希环中移除，服务器和虚拟节点的下一个节点映射到的不可能是同一个服务器，所以原本请求到这个服务器的请求就可以分发到不同服务器上，避免了连锁崩溃



### SpringSecurity

Spring Security是spring采用AOP思想，基于servlet过滤器实现的安全框架。它提供了完善的认证机制和方法级的授权功能



### Linux

#### 基于socket网络编程和tcp/ip协议栈，讲讲从客户端send()开始，到服务端recv()结束的过程（报文是怎么一步步到达网卡的）

服务器端：
 socket() → bind() → listen() → accept() → recv()/read() ↔ send()/write() → close()
 创建socket → 绑定socket和端口号 → 监听端口号 → 接收来自客户端的连接请求 → 从socket中读取字符 → 关闭socket

客户端：
 socket() → connect() → send()/write() ↔ recv()/read() → close()
 创建socket → 连接指定服务器的IP/端口号 → 向socket中写入信息 → 关闭socket

1. 双方通过socket()建立套接字s

2. 服务端通过bind()，绑定套接字与本地地址

3. 服务端调用listen()，监听端口号，等待客户端连接

4. 客户端调用connect()，与服务端连接

5. 服务端的accept()返回套接字号ns，双方建立连接

6. 数据交互：双方调用send()/recv()或者write()/read()，在ns上完成加密数据交互

   > - send()/recv()和write()/read()都是用于网络通信的函数
   > - send()/recv()相较于write()/read()提供了第四个参数flags来控制读写操作，前面的参数都是一样的，flag的取值有：
   >   -  0： 与write()/read()无异 
   >   - MSG_DONTWAIT：将单个I／O操作设置为非阻塞模式 
   >   - MSG_OOB：指明发送的是带外信息
   >   - send()-MSG_DONTROUTE：告诉内核，目标主机在本地网络，不用查路由表 
   >   - recv()-MSG_PEEK：可以查看可读的信息，在接收数据后不会将这些数据丢失
   >   - recv()-MSG_WAITALL：通知内核直到读到请求的数据字节数时，才返回。

7. 客户端调用close()关闭套接字s，结束此次TCP通信

8. 服务端调用close()关闭套接字ns，与该客户端断开连接

9. 如果服务端不需要继续等待其他客户端了，就调用close()关闭套接字s，TCP服务结束

**数据在内存中的流动**

1. 当调用send时，先比较待发送数据的长度len和套接字s的发送缓冲区的长度
   - 如果len>s.len，send就返回SOCKET_ERROR（数据太大了，发送缓冲区容不下，要切包）
   - 如果len<=s.len，send就先检查协议是否正在发送s缓冲区中的数据，是的话就先等待数据发送完；否则就比较len和发送缓冲区的剩余空间：
     - 如果发送缓冲区有足够空闲内存，则send把数据copy到剩余空间中
     - 如果发送缓冲区中空闲内存不足，则send一直等待数据发送，直到缓冲区中有足够的位置
2. 如果send复制数据进套接字的发送缓冲区成功，则返回实际copy的字节数；如果发送出错/等待协议发送数据过程中出现网络错误，返回SOCKET_ERROR

> 注意⚠️：send把数据复制进缓冲区之后就返回了，此时数据不一定已经发送到连接的另一端。如果这个数据发送失败了，那么下一个send函数就会返回SOCKET_ERROR
>
> 顺便提一下sync与fsync，这两个系统调用是用于把数据写入磁盘的：
>
> - sync把数据排入写队列就返回了，即其返回时数据不一定成功落盘了
> - fsync等待数据成功落盘之后才返回。MySQL的double write机制就是使用fsync系统调用把double write buffer中的数据写入磁盘的

1. 当调用recv时，先等待套接字s的发送缓冲中的数据传送完成（先发送后接收）：
   - 如果发送过程中出现了网络错误，则recv返回SOCKET_ERROR
2. 数据传送完成后，recv就会检查套接字s的接收缓冲区，如果没有数据或者正在接收数据，则一直等待
3. 当协议接收完数据之后，recv函数就把接收缓冲区的数据copy到buf中（接收到的数据可能大于buf的长度，这种情况下就要多次调用recv复制数据）
   - 复制成功后返回实际复制的字节数
   - 复制失败返回SOCKET_ERROR
   - 等待接收数据过程中网络中断，返回0



#### Linux中epoll处理accept惊群问题

现在网络编程中经常用到多进程/多线程模型，大概的思路是父进程创建套接字socket，执行bing、listen后，调用fork创建多个子进程，每个子进程都继承了父进程的socket，并调用accept开始监听等待网络连接。惊群是因为当多线程/多进程在同时阻塞等待一个事件，该事件发生后，就会唤醒所有等待的线程。但是事件只能被一个线程处理，其他线程获取失败，就只能重新进入休眠状态，这些线程状态的切换会浪费大量性能。即**产生条件为多个线程同时阻塞等待处理同一个事件**

在Linux2.6版本后，通过引入一个标记为WQ_FLAG_EXCLUSIVE解决了accept惊群问题，**当有事件到来之后，只会唤醒等待队列上的第一个进程或线程**。所以，Linux2.6版本后的服务器如果采用**accept阻塞调用方式**，是不会出现惊群现象的

但是，实际工程中通常会使用select、poll、epoll机制。此时，服务器并不是accept阻塞调用方式，而是阻塞在select、poll、epoll_wait。在早期的Linux版本中，内核对于阻塞在epoll_wait的进程也是采用全部唤醒的机制，存在惊群问题；但是之后的Linux版本**部分**解决了epoll的惊群问题：

- Linux4.5版本设置`EPOLLEXCLUSIVE`标志位，但是这样限制了并行量
- Linux3.9后socket提供`SO_REUSEPORT`标志，使用这个标志后会允许多个socket绑定和监听同一个端口，这样就相当于每个进程都有一个socket，问题就转化为处理accept的惊群问题了

既然说部分解决，就是说epoll还是存在惊群问题的，epoll存在惊群的场景如下：

1. **epoll_create在fork子进程之前**：这样的话，子进程就会继承父进程创建的epoll对象，也就是说多个子进程使用的都是同一个epoll对象，那么之后调用epoll_ctl把文件描述符加入到epoll对象进行统一监控的话，都会影响到其他进程的epoll_wait

2. **epoll_create在fork子进程之后，并且子进程监听同一个fd，且该fd出现POLLIN事件**：如果epoll_create在fork子进程之后，则每个进程都有自己的epoll监控文件，其调用epoll_ctl不会对别的子进程的epoll_wait造成影响。但是如果有新的客户端请求接入，监听描述符出现POLLIN事件（表示描述符可读，有新连接接入），此时内核仍然会唤醒所有进程

   > 针对这种情况，nginx的解决方案是使用mutex互斥锁，每个子进程在epoll_wait之前先取申请锁，申请到的话就继续处理，获取不到的话就等待。并且设置了一个负载均衡算法（当某一个子进程的任务量达到总设置量的7/8时，则不再尝试去申请锁）



### 网卡中的数据是怎么到达用户进程的

发送方的发送数据的处理流程大致为：用户空间 -> 内核 -> 网卡 -> 网络

其中用户空间 -> 内核是通过调用send()/write()函数来把数据报写入发送缓冲区，内核再根据不同的协议走不通的发送流程。以TCP为例，TCP是一种流协议，内核只是将数据包追加到套接字的发送队列中，真正发送数据的时刻，则是由TCP协议来控制的。TCP协议处理完成之后会交给IP协议继续处理，最后会调用网卡的发送函数，将数据包发送到网卡。

接收方的接收数据的处理流程大致为：网络 -> 网卡 -> 内核(epoll等) -> 进程(业务处理逻辑)

网卡将数据包通过**DMA**的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。

> IO需要两次拷贝：**磁盘控制器缓冲区->内核缓冲区，内核缓冲区->用户空间**。DMA就是在进行IO操作的时候，拷贝数据的工作不再由CPU负责，而是由DMA控制器完成，这样复制数据期间CPU就可以去做其他工作了，从而大大提高了CPU的效率

数据的到达对于网卡来说是一个无法预料的事件，主要通过轮询和通知机制来得知数据的到达：

1. 轮询：就是不断轮询网卡来查看数据是否到来，会浪费CPU资源。在很少发送数据的情况会导致大量的空轮询

2. 通知：就是网卡接收到数据后通知CPU，CPU响应中断后处理数据。现在千兆、万兆网卡已经很常见了，当有大量数据的到达网卡的时候，可能会在很短时间内产生大量的中断，CPU就不得不反复切换上下文来响应中断，严重影响性能

   > Linux做了优化，组合了通知和轮询的机制，一开始是通知机制，当CPU响应网卡中断后，不会只处理一个数据就退出，而是轮询一段时间尝试获取新数据

数据离开网卡驱动之后就进入到了协议栈，经过IP层、网络层协议的处理，就会触发IO读事件，比如epoll的reactor模型中，就会触发对应的读事件，然后回调对应的IO处理函数，数据之后会交给业务线程来处理，比如Netty的数据接收处理流程就是这样的。



### 对于socket编程，accept、connect，在三次握手中属于第几次

![img](https://img-blog.csdn.net/2018041116433571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dvZG9w/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

accept函数由TCP服务器调用，用于从已完成连接队列对头返回下一个已完成连接，所以accept是在三次握手之后的。

> 放在三次握手之后是因为一旦调用accept函数，就需要给此次连接分配资源，假设有大量的客户端连接服务器，在发送SYN之后不再理会服务端的回复（也就是DDoS攻击）。所以为了避免这个问题，accept放在了三次握手之后

connect函数由TCP客户端调用，用于发送SYN，也就是第一次握手（客户端请求连接）。服务端收到SYN后会把这个连接放入到backlog队列（半连接队列），在收到客户端的ACK之后就把这个请求移到accept队列。

> SYN洪泛攻击就是通过伪造不存在的IP地址向服务端发送大量的SYN包（不可能向服务端回应ACK），导致服务端的半连接队列中存储大量的半连接。通常看到服务器上有大量的半连接，并且IP地址是随机的，就基本可以判断为是一次SYN洪泛攻击。解决方法：
>
> 1. SYN Cookie：这个是最重要的，即服务端不再存储半连接，在接收到客户端发送的SYN包后，服务端**不会随机返回一个初始序号**，而是通过计算源ip、目标ip、SYN端口号以及只有该服务器知道的`secret number`，四个值一起计算hash值对应的一个`SYN Cookie`，然后以该Cookie**作为序列号**放在SYN+ACK包中返回给客户端，**并且不记录客户端的半连接信息**。当有客户端的ACK返回时，ACK的值需要验证，如果服务器计算的Cookie值+1后与客户端返回的ACK确认号一致，则连接建立成功
> 2. 加固TCP/IP协议栈防护，如加大半连接队列长度、缩短超时时间



### KeepAlive与Keep-Alive

#### TCP的KeepAlive

每当服务端收到客户端的数据时，就重置保活计时器。如果保活计时器到时了（一般为2小时），服务端还没有收到客户端发送的数据，就会每隔75秒发送一个探测报文段给客户端，当连续发送10次后仍然没有收到客户端的来信，则服务器认为客户端出现故障，主动关闭连接。这个过程就是TCP的KeepAlive机制

1. 怎么开启？

   TCP的KeepAlive不是默认开启的，Linux上也没有全局的选项开启。需要在TCP的socket中单独开启

2. 不足：

   - 只能检测连接是否存活而不能检测连接是否可用：如果客户端发生了死锁，但是操作系统仍然可以响应探测报文，那么就不会关闭这个连接（即KeepAlive机制是操作系统在TCP层完成的，应用层无法感知）

   - 依赖于操作系统的实现，不灵活，所以默认是关闭的。而且默认为2小时，时间较长

   - 代理或者负载均衡器会使其失效

     > socket proxy只管转发TCP层具体的数据包而不会转发TCP协议内的实现细节的包，所以如果TCP使用了代理，那么KeepAlive机制就失效了

所以实际上KeepAlive并不适用于保活，通常还是依赖于应用层实现的心跳机制。



#### HTTP的Keep-Alive

把短连接转化为长连接，HTTP1.0中默认关闭，可以通过设置`Connection:Keep-Alive`开启；HTTP1.1默认开启



### socket什么情况下可读/写

满足以下任一条件时，socket可读：

1. 该套接字接收缓冲区中的数据字节数大于等于套接字接收缓存区低水位。对于TCP和UDP套接字而言，缓冲区低水位的值默认为1。那就意味着，默认情况下，只要缓冲区中有数据，那就是可读的。我们可以通过使用SO_RCVLOWAT套接字选项(参见setsockopt函数)来设置该套接字的低水位大小。此种描述符就绪(可读)的情况下，当我们使用read/recv等对该套接字执行读操作的时候，套接字不会阻塞，而是成功返回一个大于0的值（即可读数据的大小）。
2. 该连接的读半部关闭（也就是接收了FIN的TCP连接）。对这样的套接字的读操作，将不会阻塞，而是返回0（也就是EOF）。
3. 该套接字是一个listen的监听套接字，并且目前已经完成的连接数不为0。对这样的套接字进行accept操作通常不会阻塞。
4. 有一个错误套接字待处理。对这样的套接字的读操作将不阻塞并返回-1（也就是返回了一个错误），同时把errno设置成确切的错误条件。这些待处理错误(pending error)也可以通过指定SO_ERROR套接字选项调用getsockopt获取并清除。

满足以下任一条件时，socket可写：

1. 该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓存区低水位标记时，并且该套接字已经成功连接（UDP套接字不需要连接）。对于TCP和UDP而言，这个低水位的值默认为2048，而套接字默认的发送缓冲区大小是8k，这就意味着一般一个套接字连接成功后，就是处于可写状态的。我们可以通过SO_SNDLOWAT套接字选项（参见setsockopt函数）来设置这个低水位。此种情况下，我们设置该套接字为非阻塞，对该套接字进行写操作(如write,send等)，将不阻塞，并返回一个正值（例如由传输层接受的字节数，即发送的数据大小）。
2. 该连接的写半部关闭(主动发送FIN包的TCP连接)。对这样的套接字的写操作将会产生SIGPIPE信号。所以我们的网络程序基本都要自定义处理SIGPIPE信号。因为SIGPIPE信号的默认处理方式是程序退出。
3. 使用非阻塞的connect套接字已建立连接，或者connect已经以失败告终。即connect有结果了。
4. 有一个错误的套接字待处理。对这样的套接字的写操作将不阻塞并返回-1（也就是返回了一个错误），同时把errno设置成确切的错误条件。这些待处理的错误也可以通过指定SO_ERROR套接字选项调用getsockopt获取并清除。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fef95f784ecf420483817c106c7316c9~tplv-k3u1fbpfcp-zoom-in-crop-mark:1304:0:0:0.awebp)



## 海量数据相关

主要思路：

1. 桶排序->排序
2. 位图法->寻找重复/没有出现的数据
3. hash+建堆->寻找出现次数最多的

### 一个文件中有10G整数，乱序排序，内存限制2G，找出中位数/前100个大的数

1. 通用方法-==桶排序==：把10G的大文件按照数据的大小划分为5个2G的小文件，每个小文件存储不同范围的数据，然后进行桶排序
2. 针对于求最大/小的n个数：==内存中维护一个固定大小的堆==，然后遍历一遍文件中的数字，放入堆中，最后堆中的数据就是所求结果



### 一个文件中有40亿个整数，每个整数为4个字节，内存为1GB，寻找这个文件里整数不包含的一个整数/重复的整数

==位图法==：4字节，可以表示4G个不同的值，另每个值对应1bit，则需要4G/8bit=512M的内存，初始状态，对这个512M的内存清零，然后对这40亿个整数进行遍历并记录，把遍历到的数字对应的位置1，如果本来就是1说明这个整数重复。遍历完后位图中为0的就是不包含的数



### 腾讯服务器每秒有2w个QQ号同时上线，找出5min内重新登入的qq号并打印出来





### 海量日志数据，提取出某日访问百度次数最多的那个IP

通过哈希算法把IP地址分散到小文件中，同样的IP地址一定会映射到同一个文件中，对每个小文件中的IP地址进行计数，记录该小文件的访问次数最多的IP和访问次数；然后对多个小文件的记录结果进行排序，找到访问次数最多的那个IP



### 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请统计最热门的10个查询串，要求使用的内存不能超过1G。

1. 首先对这个1kw个数据进行hash统计，映射成3百万个查询串，每个对应一个频率，这一步需要O(n)的时间
2. 建堆，维护一个大小为10的小顶堆，如果遍历到的元素大于堆顶元素，则替换堆顶元素。这一步需要O（n）+O（nlogn） = O（nlogn）

最终的时间复杂度为O（nlogn）



### 对10亿个电话号码去重

1. 哈希法：通过哈希把电话号码映射到多个小文件，相同的电话号码一定会映射到相同的小文件中，之后对小文件去重即可
2. 位图法：需要遍历一次所有电话号码，当发现对应位已经为1，就说明该电话号码重复，删除当前电话号码



## 生成全局唯一ID

1. UUID：UUID生成的是36位长度的16进制字符串

   - 无序：无法预测生成顺序，不能生成递增有序的数字（不适用于数据库，MySQL维护主键索引成本太大）

2. 数据库自增主键

   - 单机版用auto_increment
   - 集群版根据机器数量和步长设置自增，但是这样不便于扩展，集群增加节点的话需要重新计算集群步长
   - 集群版也可以使用ID分段的形式，即服务器的ID起始值远远大于其他机器

3. Redis：Redis是单线程的，天生保证原子性，因此可以适应incr和incrby命令实现，同样根据机器来设置步长

   - 维护麻烦、配置麻烦

4. 雪花算法：雪花算法生成的是64bit大小的整数，long类型

   - 1bit符号位+41bit时间戳位+10bit工作进程位+12bit序列号位
     - 10bit的工作进程位意味着可以部署在1024个机器上，其中包括5位datacenter和5位workId

   - 按照时间有序生成
   - 分布式环境不会产生碰撞（datacenter和workId可以区分），效率高
   - 如果时间回拨，会产生重复ID，不过这个出现概率很小



## 性能测试

1. 响应时间
2. 吞吐量
3. 并发数
4. 资源利用率
5. TPS-每秒事务数



## HTTP重定向

URL重定向，也被称为URL转发，是一种当实际资源，如单个页面、表单或者整个Web应用被迁移到新的URL下的时候，保持原有链接可用的技术。HTTP协议使用HTTP重定向来执行此类操作

- 永久重定向：这种重定向操作是永久性的。它表示原URL不应再被使用，而应该优先选用新的URL。搜索引擎、聚合内容阅读器、爬虫识别在收到一下状态码时，会更新旧URL的资源

  - 301:当前请求的资源已被移除使用，响应的Location头字段会提供资源现在的URL，直接使用GET方法发起新请求

    > 301之后，浏览器会记住第一次的301，忽律之后其他的重定向。这是因为浏览器会缓存301永久重定向

  - 308:与301类似，但是使用原请求方法发起新请求

- 临时重定向：有时候请求的资源无法从其标准地址访问，但是却可以从另外的地方访问。搜索引擎不会记录该新的、临时的链接。在创建、更新或者删除资源的时候，临时重定向也可以用于显示临时性的进度页面

  - 302:与301类似，但是客户端只应该将Location返回的URL当作临时资源来使用，将来请求的时候还是用旧的URL，直接使用GET方法发起新请求
  - 303:用于在PUT或者POST请求之后进行重定向，这样在结果页就不会再次出发重定向了
  - 307:与302类似，但是使用原请求方法发起新请求

- 特殊重定向：

  - 304:使页面跳转到本地陈旧的缓存版本当中，即表示资源未修改，相当于将资源重定向到本地缓存
  - 300:手工重定向，当请求的 URL 对应有多个资源时（如同一个 HTML 的不同语言的版本），返回这个代码时，可以返回一个可选列表，这样用户可以自行选择。通过 Location 头字段可以自定首选内容。



## Git

![image-20220324111503536](https://tva1.sinaimg.cn/large/e6c9d24egy1h0ksvlf2uqj20fs08laao.jpg)



### git pull与git fetch的区别

- git pull命令从中央存储库中提取特定分支的新更改或提交，并更新本地存储库中的目标分支

- git fetch命令也用于相同的目的，但是工作方式略有不同：

  - 执行git fetch时，它会从所需的分支中提取所有的新提交，并将其存储在本地存储库中的新分支中
  - 如果要在目标分支中反映这些更改，必须在git fetch之后执行git merge
  - 只有在对目标分支和获取的分支进行合并之后才会更新目标分支

  > git pull=git fetch+git merge



### git stash

git stash命令是把工作区修改的内容存储在栈区：

- 解决冲突文件时，先执行git stash再解决冲突，避免冲突没解决好导致文件混乱
- 遇到紧急开发任务但目前任务不能提交的时候，先执行git stash把内容存储到栈区，之后可以通过git stash pop取出栈区的内容
- 切换分支时，当前工作空间内容不能提交时，先执行git stash再进行分支切换



### git merge与git rebase的区别

这两个都是合并分支的命令

- git merge branch会把branch分支的内容pull到本地，然后与本地分支的内容一并形成一个commit提交到主分支上，合并后的分支与主分支一致
- git rebase branch会把branch分支优先合并到主分支，然后把本地分支的commit放到主分支后面，合并后的分支就好像从合并后主分支又拉了一个分支一样，本地分支本身不会保留提交历史



## 解决哈希冲突

1. 开放定址法
   - 删除元素时不能真的删除，否则可能会引起其他元素的查找错误
   - 存储的元素不能大于数组的长度，如果超过就需要扩容，开放定址法扩容耗费性能非常大
   - 记录是存放在桶数组中的，而桶数组必然存在空槽，所以当记录本身尺寸（size）很大并且记录总数规模很大时，空槽占用的空间会导致明显的内存浪费
2. 多次哈希法
   - 不易产生聚集，但是增加了计算时间
3. 拉链法
   - 适用于频繁插入和删除的情况
   - 存储的数据在内存中是随机分布的，这样在查询数据的时候，相比于连续存储的数组，查询会比较慢
   - 动态分配内存，不会造成内存的浪费
4. 建立公共溢出区：把哈希表分为基本区和溢出区两部分，一旦产生哈希冲突就把冲突的元素放到溢出区中



## static

1. static方法：即静态方法，可以不依赖于任何对象进行访问。因此对于静态方法来说，是没有this的，因此在静态方法中不能访问非静态成员方法和非静态成员变量

2. static变量：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载的时候会被初始化。而非静态变量是对象所独享的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响

   > static成员变量的初始化顺序按照定义的顺序进行初始化

3. static代码块：静态代码块可以置于类中的任何地方，在类被初次加载的时候，会按照static块在代码中的顺序依次执行，并且只会执行一次



## 内部类与静态内部类的区别

1. 变量和方法声明：

   - 内部类中的变量和方法不能声明为静态的

     > 静态类型的属性和方法，在类加载的时候就会存在于内存中。使用某个类的静态属性和方法，那么这个类必须要加载到虚拟机中。但是非静态内部类并不随外部类一起加载，只有在实例化外部类之后才会加载。
     >
     > 我们设想一个场景：在外部类并没有实例化，内部类还没有加载的时候如果调用内部类的静态成员或方法，内部类还没有加载，却试图在内存中创建该内部类的静态成员，就会产生冲突。所以非静态内部类不能有静态成员变量或静态方法。

   - 静态内部类的变量和方法可以声明为静态的或者非静态的

2. 实例化：
   - 内部类：A.B b = new A().new B()
   - 静态内部类：A.B b = new A.B()
3. 引用外部类：
   - 内部类可以引用外部类的静态或者非静态属性及方法
   - 静态内部类只能引用外部类的静态属性及方法



## MySQL与MongoDB

与关系型数据库相比，MongoDB的优点：

1. 弱一致性（最终一致），更能保证用户的访问速度
2. 文档结构的存储方式，能够更便捷的获取数据
3. 内置GridFS（分布式文件系统），支持海量数据存储
4. 内置Sharding
5. 第三方支持丰富
6. 性能优越

与关系型数据库相比，MongoDB的缺点：

1. 不支持事务操作
2. 占用空间过大
3. 没有成熟的维护工具



## HTTP劫持

### 基本步骤

1. 标识HTTP连接：在TCP连接中，找出应用层采用了HTTP协议的连接并进行标识

2. 篡改HTTP响应体：可以通过网关来获取数据包进行内容的篡改

3. 抢先回包：将篡改后的数据包抢先返回，这样后面正常的数据包在到达用户端之后就会被直接丢弃

   > 这一步骤可以通过抓包来查看是否有两个回包以及通过与正常的回包时间对比可以得出是否被HTTP劫持的结论



### 防范

#### 事前加密

1. HTTPS

   很大一部分HTTP劫持的原因就是在数据是明文传输的，使用HTTPS之后，会在HTTP的协议之上使用SSL/TLS进行加密保护。使用HTTPS也会带来一些问题：

   - 性能有所降低，HTTPS握手相比HTTP多了时延（TLS1.2是2RTT，TLS1.3是1.5RTT，经历一次完整握手后能实现0RTT）

   - 由于运营商可能会使用DNS劫持，在DNS劫持之下，HTTPS的服务完全用不了，因此会导致白屏

     > DNS劫持即让域名映射到别的ip地址

2. 加密代理

   在用户侧和目标WEB服务器之间增加一个代理服务器，在用户和代理之间会经过运营商的节点，这里使用各种加密手段来保证安全，在代理服务器与WEB服务之间使用HTTP请求，只需要确认代理与WEB服务之间不会被HTTP劫持就可以避开HTTP劫持



#### 事中加密

1. 拆分HTTP请求数据包

   在HTTP劫持的步骤中，第一步就是标记HTTP连接，因此只要躲过了这次标记，那么就无法继续HTTP劫持了。拆分数据包就是把HTTP请求的数据包拆分成多个，运营商的旁路设备由于没有完整的TCP/IP协议栈，因此不会被标志，而目标WEB服务器有完整的TCP/IP协议栈，可以把接收到的数据包拼成完整的HTTP连接而不会影响服务



#### 事后屏蔽

通过浏览器Api，根据若干规则去匹配DOM中的节点，对匹配到的节点作拦截和隐藏

CSP（内容安全策略），DOM事件监听等。

CSP是浏览器附加的一层安全层，用于对抗跨站脚本与数据注入，运营商植入内容性质与数据注入类似，因此，可以用CSP对抗运营商劫持。通过在HTTP响应头或meta标签设置好规则，支持拦截和上报劫持信息的功能。

DOM事件监听主要是监听DOMNodeInserted、DOMContentLoaded、DOMAttrModified等事件，可以在前端DOM结构发生变化时触发回调，这时补充一些检测逻辑，即可判断是不是业务的正常UI逻辑，如果不是，即可认为是来自劫持



## 操作系统为什么要分用户态和内核态？

CPU中有些指令是非常危险的，如果错用可能会造成严重后果，因此不能让任意程序都能使用这些危险指令。所以，操作系统把指令分为了特权指令和非特权指令，特权指令只有在内核态中才能执行。

由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 – 用户态和内核态。

用户态转换到内核态：

1. 系统调用：用户态进程主动要求切换到内核态的一种方式
2. 中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果原来执行的执行是用户态下的程序，那么这个转换的过程自然也就发生了用户态到内核态的转换
3. 异常



## 用户缓冲区与内核缓冲区

1. 用户缓冲区

   用户进程通过系统调用访问系统资源的时候，需要切换到内核态；在系统调用后，又要切换回用户态，堆栈必须恢复成用户进程的上下文，这种切换会耗费大量性能。

   一般程序在读取文件的时候，会先申请一块缓冲区，然后每次调用系统调用read，读取指定长度的数据入buffer中。之后的程序如果要读取该文件，只需要到buffer中获取数据，直到buffer使用完再进行一次系统调用。

   因此，用户缓冲区的目的是**减少系统调用的次数**，从而降低操作系统在用户态与核心态切换所耗费的时间。

2. 内核缓冲区

   当一个用户进程要从磁盘中读取数据时，内核一般不直接读磁盘，而是将内核缓冲区中的数据复制到进程缓冲区/用户缓冲区中。

   但若是内核缓冲区中没有数据，内核会把对数据块的请求，加入到请求队列，然后把进程挂起，为其它进程提供服务。等到数据已经读取到内核缓冲区时，把内核缓冲区中的数据读取到用户进程中，才会通知进程。（具体的调度/通知操作就是IO模型的概念了）

   内核缓冲区，是为了在OS级别，提高磁盘IO效率，优化磁盘写操作



传统的文件访问：如果有多个进程访问同一个文件，则每个进程在自己的用户缓冲区中都有一个该文件的副本，如果都是只读操作，不会对文件造成任何修改，那么完全可以读取同一个文件而不是保存副本。

mmap就是实现了内核缓冲区和用户缓冲区的共享内存，把内核缓冲区映射到用户缓冲区，这样就无需把数据从内核缓冲区复制到用户缓冲区，从而减少了一次系统调用。



## 多线程相关

<img src="https://cdn.nlark.com/yuque/0/2022/png/1206726/1648547974912-cfb0ecf6-c1e9-4074-ae1a-68ce1061a46c.png" alt="image.png" style="zoom:50%;" />

怎么保证打印出来的i一定为1？

1. CountDownLatch

2. join

   ```java
   final int[] i = {0};
   Thread thread1 = new Thread(new Runnable() {
       @Override
       public void run() {
           i[0] = 1;
       }
   });
   Thread thread2 = new Thread(new Runnable() {
       @Override
       public void run() {
           System.out.println(i[0] + " ");
       }
   });
   thread1.start();
   try {
       thread1.join();
   } catch (InterruptedException e) {
       e.printStackTrace();
   }
   thread2.start();
   ```

   join方法使用了synchronized修饰，并且底层调用了wait方法。先循环调用isAlive()方法来判断当前线程是否已经启动处于活跃状态，如果是则调用wait方法

3. notify/wait

   - wait和notify是为了处理线程调度随机性的问题的，但是这个随机性不太好，需要保证先wait再notify才能保证程序正常运行。因为如果是先notify再wait的话，由于调用了wait使得线程阻塞，而又没有其他线程调用notify唤醒该线程，就会导致调用wait方法的线程一直阻塞。

   - wait使用：

     - wait内部做了三件事：释放锁、等待其他线程的通知（唤醒）、被唤醒后重新获取锁并继续执行。

       > 因此wait必须要搭配synchronized使用，wait哪个对象就得给哪个对象加锁

     - wait方法会让出CPU

   - notify执行完后不会立即释放锁，而是要等执行完同步代码块内的代码/中途遇到wait才释放锁，所以平时使用notify/notifyAll的时候注意使用完后尽快退出临界区

   ```java
   final Integer[] i = {0};
   Thread thread1 = new Thread(new Runnable() {
       @Override
       public void run() {
           synchronized (i) {
               i[0] = 1;
               i.notify();
           }
       }
   });
   Thread thread2 = new Thread(new Runnable() {
       @Override
       public void run() {
           synchronized (i) {
              // 不是死循环！！！wait会释放锁释放CPU
              // 这个循环的作用是避免先notify后wait导致该线程无限期阻塞
               while (i[0] != 1) {
                   try {
                       wait();
                   } catch (InterruptedException e) {
                       e.printStackTrace();
                   }
               }
               System.out.println(i[0] + " ");
           }
       }
   });
   thread2.start();
   thread1.start();
   ```

4. await/signal

   先创建Lock锁，然后调用其newCondition方法获取Condition对象，然后在锁范围内进行await和signal

   ```java
   final Integer[] i = {0};
   Lock lock = new ReentrantLock();
   Condition condition = lock.newCondition();
   Thread thread1 = new Thread(new Runnable() {
       @Override
       public void run() {
           lock.lock();
           try {
               i[0] = 1;
               condition.signal();
           } finally {
               lock.unlock();
           }
       }
   });
   Thread thread2 = new Thread(new Runnable() {
       @Override
       public void run() {
           lock.lock();
           try {
              // 跟wait/notify一样，通过这个循环保证signal后不会再await
               while (i[0] != 1) {
                   condition.await();
               }
             System.out.println(i[0] + " ");
           } catch (InterruptedException e) {
               e.printStackTrace();
           } finally {
               lock.unlock();
           }
       }
   });
   thread2.start();
   thread1.start();
   ```

5. park/unpark

   - 优点是不像wait/notify一样需要依赖synchronized、await/signal需要依赖Lock，park/unpark只需要调用LockSupport的静态方法
   - unpark方法的参数为线程，更加符合阻塞线程的直观定义，可以准确的唤醒一个线程。而notify是随机唤醒一个线程，notifyAll唤醒所有线程
   - 即使先执行了unpark，最终调用park的线程还是会被唤醒，从而避免了因为线程的启动顺序导致线程的无限期阻塞，因此不需要像wait/notify、signal/await一样要借助循环
   - park/unpark的设计原理核心是“许可”(permit)：park是等待一个许可，unpark是为某线程提供一个许可。permit不能叠加，也就是说permit的个数要么是0，要么是1。也就是不管连续调用多少次unpark，permit也是1个。线程调用一次park就会消耗掉permit，再一次调用park又会阻塞住。如果某线程A调用park，那么除非另外一个线程调用unpark(A)给A一个许可，否则线程A将阻塞在park操作上。

   ```java
   final Integer[] i = {0};
   Thread thread2 = new Thread(new Runnable() {
       @Override
       public void run() {
           LockSupport.park();
           System.out.println(i[0] + " ");
       }
   });
   Thread thread1 = new Thread(new Runnable() {
       @Override
       public void run() {
           i[0] = 1;
           LockSupport.unpark(thread2);
       }
   });
   thread2.start();
   thread1.start();
   ```



### Thread.sleep()和Object.wait()的区别

1. 锁：sleep不会释放锁，wait会释放锁
2. 时间参数：sleep必须传入时间参数，wait不传入的话表示永久阻塞（不唤醒的话）
3. CPU：二者都会释放CPU



### Thread.sleep()和Condition.await()的区别

1. await底层是调用LockSupport.park()来实现阻塞当前线程的
2. 锁：sleep不会释放锁，await释放锁（底层的park不会释放锁，释放锁的逻辑是Condition自己实现的）



### Thread.sleep()和LockSupport.park()的区别

1. 锁：都不会释放锁
2. 唤醒：sleep无法从外部唤醒，只能自己醒；park可以通过调用unpark唤醒
3. 捕获异常：sleep需要捕获`InterruptedException`中断异常；park不需要捕获异常
4. sleep本身就是一个native方法，park底层调用Unsafe的native方法



### Object.wait()和LockSupport.park()的区别

1. wait需要在synchronized块中执行，park不依赖锁
2. 锁：wait会释放锁，park不会释放锁
3. 捕获异常：wait需要捕获`InterruptedException`中断异常；park不需要捕获异常
4. 如果先notify再wait，会抛出`IllegalMonitorStateException`异常；如果先unpark再park，线程不会被阻塞，直接跳过park



## 手机OS与PC OS的区别/客户端开发需要注意什么？

1. 交互逻辑的区别：PC是鼠标点按，而现在大多数人使用的智能机是要用手进行触控操作。
   - 触控操作可以产生的信息量比鼠标更大：相比于PC，触控的操作方式会有比较多的滑动触控方式
   - 操作精度：PC端的光标比较小，所以按钮可以做的比较小/精细；但是手机端，用手指触控的话精度有限，所以按钮的设置要合理（够大）
   - 分辨率/画面大小：手机相比于PC屏幕小很多，一个页面内可以展示的信息量也会相对较少，因此界面设计的时候要更加注意如何提取重点，在小屏幕内尽可能的展示足够多的重点信息
2. 性能限制：现代手机对续航很看重，因此手机操作系统对应用的性能限制相对于PC来说会比较大，允许分配的内存空间和CPU资源限制也会比PC更大。所以客户端开发要更加注意内存控制，防止OOM问题的出现



## fd文件描述符是什么

在Linux操作系统中，它有一种概念，即万物皆文件。它把键盘、鼠标看作字符设备文件、硬盘、光驱看作块设备文件等等，把所有的东西都抽象成了文件，提供了统一的接口，方便应用程序调用。

文件描述符：File descriptor,简称fd，当应用程序请求内核打开/新建一个文件时，内核会返回一个文件描述符用于对应这个打开/新建的文件，其fd本质上就是一个非负整数。实际上，它是一个**索引值，指向内核为每一个进程所维护的该进程打开文件的记录表**。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

每个进程都有自己独立的一份文件描述符表，因此同一个文件可能在两个进程中返回的fd是不一样的，通过进程ID+fd ID可以确定唯一一个文件。

多个进程之间的fd：

1. 两个进程中分别产生生成两个独立的fd
2. 两个进程可以任意对文件进行读写操作，操作系统并不保证写的原子性
3. 进程可以通过系统调用对文件加锁，从而实现对文件内容的保护
4. 任何一个进程删除该文件时，另外一个进程不会立即出现读写失败
5. 两个进程可以分别读取文件的不同部分而不会相互影响
6. 一个进程对文件长度和内容的修改另外一个进程可以立即感知



## 数据库

### 数据库范式

1. 第一范式：保证每列的原子性

   > 如地址中包含省、市、区，如果需要单独访问省，就要把省提取出来单独建立一个字段

2. 第二范式：确保表中的每一列都与主键相关，即一张表只能保存一种数据，这样很大程度上减少了数据库的冗余

   > 比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。这样就产生一个问题：这个表中是以订单编号和商品编号作为联合主键。这样在该表中商品名称、单位、商品价格等信息不与该表的主键相关，而仅仅是与商品编号相关。所以在这里违反了第二范式的设计原则。而如果把这个订单信息表进行拆分，把商品信息分离到另一个表中，把订单项目表也分离到另一个表中，就非常完美了

3. 第三范式：确保表中的每一列都与主键直接相关，而不是间接相关。

   > 比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段



### 范式与反范式

- 范式：保证每个事实数据会出现且只出现一次
  - 范式化的更新操作通常比反范式化更快，因为反范式化的更新操作需要修改多个地方的冗余数据
  - 范式化的表通常更小，执行操作会更快
  - 表查询时可能需要进行关联查询，这样可能会使得一些索引策略失效
- 反范式：信息是冗余的，一个事实数据可能会存储在多个地方
  - 所有数据都在一张表中，很好的避免了关联查询
  - 单独的一张表也能使用更加有效的索引策略
  - 有大量的数据冗余，修改操作需要修改很多地方，并且冗余数据也会浪费大量内存

在实际应用中，范式与反范式经常混合使用，常见的反范式化数据是复制或者缓存



### 关系型数据库与非关系型数据库

- 关系型：

- - 采用关系模型来组织数据的数据库
  - 最大的特点是事务一致性
  - 简单来说，关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织
  - 应用：Oracle、MySQL

- 非关系型：

- - 使用键值对存储数据
  - 严格上不是一种数据库，而是一种数据结构化存储方式
  - 一般不支持ACID特性
  - 优点：无需sql层解析，读写性能高；基于键值对，数据没有耦合性
  - 应用：Nosql、Redis、MongoDb

  

### left join、right join以及inner join的区别

- left join：左关联，主表在左边，右边为从表。如果左侧的主表中没有关联字段，会用null 填满
- right join：右关联，主表在右边和letf join相反
- inner join：内关联只会显示主表和从表相关联的字段，不会出现null



### 一张表,里面有ID自增主键,当insert了17条记录之后,删除了第15,16,17条记录,再把Mysql重启,再insert一条记录,这条记录的ID是18还是15 ？

- MyISAM会将自增列信息持久化在文件中
- MySQL8.0前将自增信息存在内存中，重启后通过max(id)得到最大自增列；8.0后会写入redo log并在每个检查点存储在私有的系统表中

在MySQL 8.0之前：

1)如果是MyISAM表，则数据库重启后，ID值为18

2)如果是InnoDB表，则数据库重启后，ID值为15

在MySQL 8.0开始，

1)如果是MyISAM表，则数据库重启后，ID值为18

2)如果是InnoDB表，则数据库重启后，ID值为18



### 实现自增列

1. 插入语句在执行前无法确定要插入多少记录的情况：采用`AUTO-INC`锁

- - 先在表级加一个`AUTO-INC`锁
  - 为每一条待插入的自动递增的列分配递增值
  - 执行语句
  - 语句执行后，释放`AUTO-INC`锁 (注意：不是事务结束才释放)

执行前无法确定插入几条数据：如insert ……select、 load data等

1. 插入语句在执行前可以确定要插入多少记录的情况：适用于采用轻量级锁

- - 获取轻量级锁，生成本次插入语句需要用到的自动递增的列的值
  - 释放锁
  - 执行插入语句

执行前可以确定插入几条数据：如insert ……values(……), (……)

- 8.0以前，两种方式混合使用，插入数确定用轻量级锁，不确定用自增锁
- 以后，一律使用轻量级锁



### 视图View

- 视图隐藏了底层的表结构，简化了数据访问操作（视图是查询语句执行后返回的已经处理好的符合查询条件的结果集，所以使用视图的用户不需要关心查询条件）
- 因为隐藏了底层的表结构，所以大大加强了安全性，用户只能看到视图提供的数据（因为对于表的权限管理并不限制到某个行或者某个列，但是使用视图就可以实现）
- 使用视图，方便了权限管理，让用户对视图有权限而不是对底层表有权限，进一步加强了安全性
- 数据独立：一旦视图的结构被确定了，可以屏蔽表结构变化对用户的影响。源表对视图以外的列的修改对视图没有任何影响，如果对视图内的列进行修改的话，只需要对视图也进行修改即可，不会对应用程序造成影响



## 如何验证HTTPS证书？

数字证书是用来认证公钥持有者的身份，以防止第三方进行冒充，也就是用来告诉客户端该服务端的身份是否可信。一个数字证书通常包含了：

- 公钥
- 持有者信息
- 证书认证机构CA的信息
- CA对这份文件的数字签名及使用的算法
- 证书有效期
- 额外信息

1. 签发过程：
   - 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
   - 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
   - 最后将 Certificate Signature 添加在文件证书上，形成数字证书
2. 验证过程：
   - 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
   - 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
   - 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信



## HTTP

### 一个TCP连接可以发多少个HTTP请求

这个要视使用的HTTP协议版本而定：

- HTTP1.0中默认为短连接，一个TCP连接对应一个HTTP连接，完成一个HTTP请求后就断开TCP连接。因此在HTTP1.0中一个TCP连接只能发1个HTTP请求
- HTTP1.1中默认使用长连接，不会完成一个HTTP请求后就断开TCP连接，因此在HTTP1.1中一个TCP连接可以发送多个HTTP请求



### 一个TCP连接中多个HTTP请求可以同时发送吗？

- 在HTTP1.1中，单个TCP连接在同一时刻只能处理一个请求，即只能等前一个请求完成后才能处理下一个请求。虽然其提出了管道化的概念尝试解决这个问题，但是默认是关闭的：

  - 管道化即客户端可以不需要等到请求的响应就能继续发送下一个请求，但是响应的顺序必须和请求的顺序一致

    > 这是因为HTTP1.1是个文本协议，无法区分返回的响应对应的是哪一个请求，因此必须保持响应和请求的顺序一致来判断响应对应哪个请求

  - 流水线实现复杂

  - 队头阻塞问题：假设处理前面的请求耗费了大量时间，那么后面的请求都需要等待前面的请求完成并响应后才能响应

- HTTP2.0中通过二进制分帧+多路复用实现了一个TCP连接中可以同时完成多个HTTP连接。

  - 不同于HTTP1.1及之前的版本，是基于文本格式解析，这也是导致需要按请求顺序响应的原因。HTTP2.0基于二进制进行解析，可以把请求拆分成多个互不依赖的二进制分帧，并可以乱序发送，在不同的流上传输，然后在另一端进行组装
  - 既然可以不按顺序响应，那么HTTP层面的队头阻塞问题就解决了，但是由于HTTP2.0仍然是基于TCP的，所以TCP层面的队头阻塞仍然存在：TCP是有序传输，如果没有收到前面的确认，就会阻塞后续数据的传输

- HTTP3.0基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，彻底解决了队头阻塞问题



## 面向对象

1. 封装：即把客观事物封装成抽象的类
2. 继承：即可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展
   - 继承/泛化：即extends继承，Java中不支持多继承
   - 组合/聚合：
3. 多态：允许将子类类型的指针赋值给父类类型的指针。虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用。最常见的多态就是将子类传入父类参数中，运行时调用父类方法时通过传入的子类决定具体的内部结构或行为。
   - 覆盖：即子类重新定义父类的虚函数的做法（重写、实现接口）



## CSRF攻击（跨域请求伪造攻击）

1. 用户打开浏览器，访问受信任网站A，并登陆
2. 网站A验证用户信息成功后，返回Cookie信息给用户，用户登录成功，之后可以正常发送请求到网站A
3. 用户未退出网站A的时候在同一浏览器访问恶意网站B
4. 恶意网站B返回一些攻击性代码，**在用户不知情的情况下携带其Cookie请求访问网站A**
5. 网站A不知道该恶意请求实际上是网站B发起的，会按照用户的正常请求进行处理

漏洞检测/防御：

1. 验证HTTP refer字段：HTTP头中的refer字段记录了该HTTP请求的来源地址，如果要进行CSRF攻击，只能从自己的恶意网站构造请求，也就是说这个恶意请求的refer字段记录的是恶意网站的地址。因此服务器只需要验证refer字段中的地址是合法的，如果非法则拒绝请求即可。

   这个方法就相当于把安全性都依赖于第三方（浏览器）来保障，并不是完全安全，比如可以篡改refer值，这样的话仍然可以攻击。不过这种方法简单易行，不需要改变当前系统的任何已有代码和逻辑

2. 请求地址中添加token（参数形式）并验证：CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。



## WebSocket

HTTP协议有一个缺陷：通信只能由客户端发起（虽然HTTP2.0中新增了服务器推送的功能，但是这个功能只能向客户端推送客户端前一次请求相关的消息，比如静态资源）

HTTP单向请求的特点就导致了如果客户端想要获知服务端连续的状态变化十分困难，只能使用轮询，效率低，十分浪费资源。

为了解决这个问题，WebSocket协议诞生了，其最大特点就是**服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种**，其他的特点有：

1. 建立在TCP协议之上
2. 与HTTP协议有着良好的兼容性，默认端口也是80和443，握手阶段采用HTTP协议，因此握手时不容易被屏蔽，能通过各种HTTP代理服务器
3. 数据格式轻量，性能开销小，通信高效
4. 支持文本格式和二进制格式
5. 没有同源限制，客户端可以与任意服务器通信
6. 协议标识符是ws（加密则为wss）



## TCP/IP协议栈

![1.png](https://img.php.cn/upload/image/821/258/677/1608097737308858.png)

1. 应用层

   - 负责处理应用程序的逻辑
   - 数据链路层、网络层、传输层负责处理网络通信的细节，因此这几层必须稳定且高效，所以它们都在内核空间实现。而应用层在用户空间中实现，因为其负责处理许多应用逻辑，如果在内核空间实现的话，会导致内核空间十分庞大。也有少量的服务器程序是在内核中实现的，从而减少了应用程序在用户空间和内核空间中来回切换，从而提高了效率
   - 常用协议：
     - OSPF：开放最短路径优先协议，是一种动态路由更新协议，用于路由器之间的通信，以告知对方各自的路由信息
     - DNS：把域名转换成IP地址
     - telnet：远程登录协议
     - HTTP：基于请求与响应模式的、无状态的协议

2. 传输层

   -  为两台主机上的应用程序提供端到端的通信，传输层只关心通信的起始端和目的端，而不在乎数据包的中转过程
   - 常用协议：
     - TCP：为应用层提供可靠的、面向连接、面向字节流的服务
     - UDP：为应用层提供不可靠的、无连接的、面向数据报的服务

3. 网络层

   - 负责数据包的选路和转发

   - 对应设备：路由器

   - 常用协议：

     - IP：根据数据包的目的IP地址来决定如何把它发送给目的主机，如果数据包不能直达目的主机，则会在路由表中选取一个合适的下一跳路由器，并转发给该路由器

     - ICMP：是IP协议的重要补充，主要用于检测网络连接

       > ICMP协议并非严格意义上的网络层协议，因为它使用了处于同一层的IP协议提供的服务，而一般来说，上层协议使用下层协议提供的服务

4. 数据链路层

   - 实现了网卡接口的网络驱动程序，以处理数据在物理媒介上的传输
   - 对应设备：网线、网桥、集线器、交换机
   - 常用协议：
     - ARP地址解析协议：把IP地址转换为MAC地址
     - RARP逆地址解析协议：把MAC地址转换为IP地址



## Java从源代码到运行的全过程

1. 源代码
2. 编译（javac，又称为前端编译器）
   1. 词法分析
   2. 语法分析
   3. 语义分析
   4. 生成字节码
3. 类装载
4. 字节码校验
5. 翻译字节码（解析执行）/ JIT编译器（编译执行）
   - 解析执行就是逐行把字节码解析成字节码，解析到哪里执行到哪里，如果遇到了循环，那么循环多少次，循环体的代码就会被解析多少次。速度快，但是遇到如循环体这种会重复进行无意义的解析
   - 编译执行就是先寻找热点代码，如循环，编译成字节码并缓存在本地，之后只要执行到该部分的代码都无需进行编译，而是直接从缓存取。速度比解析满，并且需要额外的内存
6. 运行



## 对称加密与非对称加密

这个对称与非对称指的就是加密与解密使用的密钥是否是同一个。

1. 加解密过程：对称加密算法的加密与解密使用的密钥是同一个；非对称加密算法一般使用公钥进行加密，私钥进行解密
2. 效率：对称加密的解密速度比较快，非对称加密的加解密速度相对较慢，只适合对少量数据的使用
3. 安全性：对称加密的密钥需要双方进行交换，无法确保密钥被安全传递，如果密钥泄漏了，那么传输过的所有密文都可以被破解；非对称加密算法中私钥是基于不同算法生成的随机数，并根据加密算法推导出公钥并发送给对方供给对方发送数据时加密使用，即**非对称加密过程中只有公钥在网络上传输过，私钥一直保留在本地，并且私钥到公钥的推导过程是单向的，也就是说公钥无法反推导出私钥**，因此公钥泄漏了也不会造成被破解
4. TLS1.2中采用非对称加密算法RSA，不保证前向安全（如果密钥泄漏了则之前传输过的所有密文都可以被破解）；TLS1.3中采用非对称加密算法DH（椭圆曲线加密），保证前向安全
