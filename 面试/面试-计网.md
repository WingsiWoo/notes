# 面试-计网

## HTTP

### HTTP1.0与HTTP1.1的对比

1. ==长连接（连接复用）==

   - HTTP1.0不支持长连接，每个HTTP请求都会创建一个新的TCP连接
   - HTTP1.1默认开启`Connection:Keep-Alive`开启长连接，并且HTTP1.1新增了请求的管道化处理，在一个TCP连接上可以传送多个HTTP请求和响应，在一定程度上减少了连接的创建的消耗和延迟，不过由于服务端仍然需要根据请求顺序响应，因此仍然没有解决HOLB队头阻塞问题

2. ==缓存处理==

   - HTTP1.0采用`Pragma+Expires`的方式进行缓存处理，`Expires`即把设定的过期时间和本地时间进行比较来确定缓存是否有效，如果本地时间不正确则可能达不到预期的效果
   - HTTP1.1采用`Cache-Control`来进行缓存控制

3. ==新增响应码==

   在HTTP1.1中新增了24个错误状态响应码，如`409(Conflict)`表示请求的资源 与资源的当前状态发生冲突;`410(Gone)`表示服务器上的某个资源被永久性的删除。

4. ==断点续传（分块传输）==

   - HTTP1.0不支持断点续传，传输的对象必须是完整的，如果传输中断了，下一次重新开始传输时就要从头开始传输
   - HTTP1.1支持断点续传，传输的对象可以不是完整的

5. ==请求部分对象==

   - HTTP1.0必须请求完整的对象，如果客户端只需要一部分数据，但服务端却只能传输完整的数据过来，就会造成带宽浪费
   - HTTP1.1可以通过设置range头域来请求一部分对象，返回码是`206(Partial Content)`，这样就方便了开发者自由的选择以便于充分利用带宽和连接。

6. ==Host头处理==

   - HTTP1.0认为每个IP地址只会有一个主机，因此请求URL中不传递host
   - 随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误(`400 Bad Request`)



### HTTP1.1与HTTP2.0的对比

1. ==二进制分帧==
   - HTTP1.1基于文本格式解析，但是由于文本格式的表现十分多样，因此要做到健壮性比较困难
   - HTTP2.0采用二进制分帧的方法，基于二进制解析，由于二进制只有0和1，因此要做到健壮性容易得多。并且在二进制分帧层上，HTTP2.0会把传输信息分为多个二进制帧
   
2. ==头部压缩==
   - HTTP1.x中，HTTP请求和响应都是由状态行、头部、消息主体三部分组成的。一般而言，消息主体都会经过压缩，或者本身传输的就是压缩过后的二进制文件。但状态行和头部却没有经过任何压缩，直接以纯文本传输。
   - 在HTTP2.0中，使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。
   
3. ==多路复用（连接共享）==
   - 在HTTP1.1中，浏览器和客户端在同一时间、针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞，这也是为何一些站点会有多个静态资源CDN域名的原因之一。
   - HTTP2.0中，采用多路复用，多个`HTTP Request`可以共用一个TCP连接。归功于二进制分帧机制，HTTP2.0不再依赖多个TCP连接去实现多流并行，每个数据流都可以被拆分成很多个互不依赖的帧，可以乱序发送，然后在另一端重新组合。不仅可以减少消息交互往返的时间，还可以避免创建新连接造成的延迟，使得 TCP 的效率更高。
   
   > HTTP2.0通过多路复用解决了HTTP层面的队头阻塞问题
   
4. ==服务器推送==
   - HTTP1.x中，服务器发送数据都需要先收到客户端的请求
   - HTTP2.0中，添加了服务器推送的功能，服务器可以主动的向客户端推送数据而无需等待客户端的请求，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。服务器推送还有一个很大的优势：**可以缓存**。也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。



### HTTP3.0解决了什么问题？

1. 基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，彻底解决了队头阻塞问题
2. 重新定义了TLS协议加密QUIC头部的方式，既提高了网络攻击的成本，又降低了建立连接的速度（仅需要1RTT就可以同时完成建立连接和密钥协商）
3. 将Packet、QUIC Frame、HTTP3 Frame分离，实现了连接迁移功能，降低了5G环境下高速移动设备的连接维护成本



## HTTP与HTTPS

|              |        HTTP        |              HTTPS              |
| :----------: | :----------------: | :-----------------------------: |
|     端口     |         80         |               443               |
|    安全性    | 无加密，安全性较差 |     有加密机制，安全性较高      |
|   资源消耗   |        较少        |        加密消耗较多资源         |
| 是否需要证书 |         否         |               是                |
|     协议     |   运行在TCP之上    | 运行在SSL之上，SSL运行在TCP之上 |



## HTTPS过程

HTTPS = HTTP + SSL/TLS，即TCP三次握手+TLS四次握手

1. `第一次握手`

   经历TCP三次握手后，进入TLS握手阶段。客户端向服务端发送请求：

   - 自己使用的SSL/TLS版本
   - 生成的随机数`Client Random`，用于生成会话密钥
   - 客户端支持的密码套件列表

2. `第二次握手`

   服务端收到请求后，会确认自己所支持的SSL/TLS版本，如果不支持就直接关闭此次连接；如果支持的话就从客户端发送过来的加密算法选择一种，生成一个随机数`Server Random`，向客户端发送响应：

   - SSL/TLS版本
   - 服务器选择的密码套件
   - 随机数`Server Random`
   - CA颁发的数字证书，里面携带一个公钥`public key`（私钥`private key`自己保留，不能泄漏）

   > 证书本身携带一个电子签名，可以用于验证证书的完整性和真实性，防止证书被篡改
   >
   > 这一对密钥就是非对称加密的密钥

3. `第三次握手`

   客户端收到后，会先验证证书的有效性，如果证书有效，则进行后续操作，发送Change Cipher Key Exchange消息给服务端

   - 生成随机数`pre-master`，并且用服务器发过来的公钥`public key`加密

     > 这个随机数就是对称加密的密钥

   - `Change Cipher Spec`，通知服务器开始使用加密通话

   - 加密后的握手数据摘要`Encrypted HandShare Message`

4. `第四次握手`

   服务器收到后，会用自己的私钥`private key`对客户端发来的随机数`pre-master`进行解密，之后的数据传输会用这个随机数进行对称加密，然后向客户端发送响应：

   - `Change Cipher Spec`，通知客户端开始使用加密通话
   - 加密后的握手数据摘要`Encrypted HandShare Message`

> 添加的非对称加密完美解决了对称加密密钥暴露的问题

![image-20220111143011205](https://tva1.sinaimg.cn/large/008i3skNgy1gy9pwfhdxcj30nj0iw0ug.jpg)



#### DH算法

以上的RSA非对称加密存在一个问题，即不支持**前向保密**。服务器的私钥一旦泄漏，那么对称加密的密钥就会被破解，之前发送过的被第三方截获的TLS密文都会被破解。

因此提出了DH算法：客户端和服务器都各自产生一个密钥对，即有两对密钥，然后把各自的公钥通过TLS互换。然后双方通过自己的私钥+对方的公钥构造本地密钥，构造出来的密钥是一样的，之后双方就可以通过本地密钥进行数据的加密和解密。因此即使私钥泄漏了，也不会导致密钥被第三方解密

> TLS1.3使用了DH算法进行全面握手，只需要两次握手（一次往返，1RTT）就可以完成握手



### 中间人攻击

1. 客户端本地请求被劫持，所有的请求都发送到中间人
2. 中间人返回证书给客户端
3. 客户端与中间人进行对称加密传输，中间人借用服务端的证书与服务端进行对称加密传输。即中间人对客户端假装自己是服务端，对服务端假装自己是客户端，从而能获取客户端想要与服务端相互传输的数据

![image-20220118213807453](https://tva1.sinaimg.cn/large/008i3skNgy1gyi5lwcx8pj30ip08p0t0.jpg)

所以HTTPS建议CA认证机构颁发证书，就是为了避免用户不知情的中间人攻击。客户端收到中间人的证书后，发现这个证书并不是CA认证机构颁发的，所以就不会进行后续数据传输



### 只有CA认证机构可以生成证书吗？

- 如果用户要求浏览器不提示安全风险，就只能使用认证机构签发的证书

- 绝大部分情况下，浏览器只会提示安全风险，并不限制网站的访问，所以技术上谁都可以生成证书。

  > 像信安的那个gitlab就是使用手动安装私有证书的形式实现HTTPS访问



### HTTPS会被抓明文包吗？

HTTPS传输的数据是对称加密过的，因此常规情况下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。

而由于技术上不一定要CA认证机构颁发证书，可以在用户授权（知情）的情况下，组建中间人网络。即抓包工具生成一个证书，用户手动把这个证书安装到客户端中，之后抓包工具就充当中间人的角色，客户端发起的所有请求都会发送到抓包工具，抓包工具再转发请求到服务器；服务器返回数据给抓包工具，抓包工具再转发回给客户端。

所以**HTTPS是不能防抓包的**，使用HTTPS安全的意义是其可以**防止用户在不知情的情况下被劫持请求，通信链路被监听**，对于像这种**主动授信的抓包操作是不提供防护的**。



### HTTPS可以保证服务端和客户端都是可信的吗？

HTTPS单向认证只是客户端认证了服务器，而没有服务器认证客户端，所以只能保证服务端是可信的。为了保证服务端和客户端都是可信的，需要进行**双向认证**

1. 客户端向服务端发送HTTPS建立连接请求，携带自己的SSL/TLS协议版本
2. 服务端将本机的`公钥证书server.crt`发送给客户端
3. 客户端收到证书后，首先对证书进行认证，认证成功后取出证书中的公钥，并发送自己的`公钥证书client.crt`给服务端
4. 服务端使用`根证书root.crt`解密客户端公钥证书，取出客户端公钥
5. 客户端发送自己支持的加密方案给服务器
6. 服务器选择一个双方都能接受的加密方案，**使用客户端的公钥加密选择的加密方案**，并发送给客户端
7. 客户端**使用自己的私钥解密加密方案**，**并生成一个随机数，使用服务器公钥加密**后传给服务器
8. 服务器收到后**用自己的私钥解密随机数，得到了之后对称加密的密钥（随机数）**
9. 之后双方可以使用这个密钥进行对称加密通信



## TCP

### TCP三次握手过程

1. 客户端向服务端**发送一个SYN包**，并随机选择一个**`seq=x`**作为初始序号，然后进入`SYN-SENT`（同步已发送状态）
2. 服务端收到客户端发来的SYN包后，向客户端**发送一个SYN+ACK包**，并随机选择一个**`seq=y`**作为初始序号，然后进入`SYN-RECV`（同步已收到状态）
3. 客户端收到服务端发来的ACK包后，向服务端**发送一个ACK包**，序号为**`seq=x+1`**，然后进入`ESTABLISHED`（连接已建立状态）
4. 服务端收到客户端发来的ACK包后，进入`ESTABLISHED`（连接已建立状态）

![image-20220110155148669](https://tva1.sinaimg.cn/large/008i3skNgy1gy8mn1uym7j30n10gnq44.jpg)



#### 为什么需要三次握手？

1. ==防止已过期的连接请求报文传送到服务器，因而造成错误和资源浪费==

   - 假设客户端传送了一个连接请求报文A给服务器，但是由于某些原因这个报文无法按时到达服务器。
   - 客户端在等待超时后仍然没有收到服务端发来的ACK包，选择重新发送一个连接请求报文B。
   - 这一次连接顺利建立，完成后双方关闭连接进入`CLOSED`（关闭状态）
   - 此时之前那个连接请求报文A又到达了服务器，服务器收到后向客户端发送一个ACK包，并直接进入`ESTABLISHED`状态（服务端认为连接已建立）
   - 由于客户端已经进入`CLOSED`状态，是不会建立连接的，但是**服务器在两次握手的情况下误以为连接已经建立，就会长时间等待客户端发送数据，最后自己异常关闭连接，造成资源浪费**

   > 服务端设有一个TCP保活计时器，当连续2小时客户端都没有发送任何数据，服务端就会每隔75秒发送一个探测报文，如果发送10次都得不到客户端的回应的话，就会关闭这个连接，之后客户端再发送数据，服务端会返回一个RST包表示异常连接

2. ==三次握手才能让客户端和服务端都能确定自己和对方的接收和发送能力正常==

   - 第一次握手：客户端发送SYN包，无法确定任何能力；服务端收到SYN包，确定对方的发送能力和自己的接收能力正常

   - 第二次握手：服务端发送SYN+ACK包，客户端收到后，确定对方的发送能力和接收能力（对方接收到SYN包才会发送ACK包）和自己的接收能力以及自己的发送能力正常（SYN包发送成功）。至此，客户端确认完毕

     > 如果只是两次握手，服务端无法确认自己的发送能力和对方的接收能力是否正常

   - 第三次握手：客户端发送ACK包，服务端收到后，确定自己的发送能力和对方的接收能力正常（对方收到ACK包后才会发送ACK包）

3. ==告知对方自己的初始序号，并得知对方的初始序号==

   TCP能实现有序传输的一个重要原因就是维护了序号字段和确认号字段。如果只是两次握手，客户端（发起方）可以确认序号字段和确认号字段，但是**服务端由于不会收到ACK包，因此无法确认确认号字段**



#### SYN洪泛攻击

SYN洪泛攻击指攻击者伪造大量不存在的IP地址，向服务端发送SYN包。服务端收到SYN包后，会向这个虚假的IP地址发送SYN+ACK包，并等待对方确认。由于服务端不可能会收到ACK包，因此服务端会不断等待超时后重发，浪费了大量资源。

**这些伪造的 SYN 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。**

检测：当在服务器上看到大量的半连接状态（处于`SENT-RECV`），并且IP地址是随机的，基本可以判定这是一个SYN洪泛攻击

解决：

- 通过防火墙、路由器等过滤网关防护

- 加固TCP/IP协议栈防护，如增大最大半连接数、缩短超时时间

- `SYN Cookies`技术

  在接收到客户端发送的SYN包后，服务端不会随机返回一个初始序号，而是通过计算源ip、目标ip、SYN端口号以及只有该服务器知道的`secret number`，四个值一起计算hash值对应的一个`SYN Cookie`，然后以该Cookie作为序列号放在SYN+ACK包中返回给客户端，**并且不记录客户端的半连接信息**。当有客户端的ACK返回时，ACK的值需要验证，如果服务器计算的Cookie值+1后与客户端返回的ACK确认号一致，则连接建立成功。

  由于服务端不会记录客户端的半连接信息，因此不会被大量的SYN洪泛攻击导致的半连接所影响。



#### 如果客户端发送的ACK包丢失了会怎么样？

- 客户端发送ACK包后就会进入`ESTABLISHED`状态，即客户端认为连接已经成功建立。
- 而服务端由于没有收到ACK包，就会等待3、6、12秒后**重发SYN+ACK包**，以便**提醒客户端重新发送ACK包**。
- 如果还是没有收到ACK包，服务端就会关闭这个连接。当客户端发来数据时，服务端会**发送一个RST包**（Reset，标志复位，用于因为异常关闭的连接），客户端收到RST包就知道连接失败了



### TCP四次挥手过程

1. 客户端向服务端**发送FIN+ACK连接释放报文**，其中`seq=u`，`ack=k`，并进入`FIN-WAIT-1`（终止等待1状态）。之后客户端不再发送数据，但是仍然要接受服务端发来的数据
   - u即客户端发送的上一个报文的最后一个字节序号+1
   - k即服务端发送的上一个报文的最后一个字节序号+1
2. 服务端收到后**发回ACK包**，并进入`CLOSE-WAIT`（关闭等待状态），之后继续发送剩余的数据
3. 客户端收到ACK包后，进入`FIN-WAIT-2`（终止等待2状态），**TCP连接就变为了半连接状态，即客户端到服务端方向的连接已经释放了**
4. 服务端发送完最后的数据后，**发送FIN包**，请求关闭连接，其中`seq=w`，`ack=u+1`，并进入`LAST-ACK`（最后确认状态）
   - w即服务端发送的上一个报文的最后一个字节序号+1
   - `ack=u+1`是因为这期间客户端没有发送数据
5. 客户端收到后**发送ACK包**，进入`TIME-WAIT`（时间等待状态）。**客户端到TCP的连接还没有释放**
6. 服务端收到ACK包后进入`CLOSED`（连接关闭状态）。**服务端到客户端方向、服务端到TCP的连接已经释放了**
7. 客户端**等待2MSL时间**后，进入`CLOSED`状态，此时TCP连接完全关闭

![image-20220110162055764](https://tva1.sinaimg.cn/large/008i3skNgy1gy8nhcr7tnj30l70juabk.jpg)



#### 为什么需要四次挥手？

- 服务端在收到客户端的FIN+ACK包后，不能马上关闭连接，因为自己可能还有数据要发送。但是必须要做出应答，否则客户端会以为FIN+ACK包发送失败，而继续重新发送
- 服务端发送完数据后才能发送FIN+ACK包。多了一次确认



#### 为什么要等待2MSL？

1. 确保ACK报文一定能到达服务端

   2MSL是TCP报文在网络上传输的最长时间，即这2MSL内，TCP报文都会从网络中消失。在这2MSL内，如果服务端没有收到客户端的ACK报文，就会**重发FIN+ACK报文**，如果客户端发送后直接进入`CLOSED`状态，就会收不到这个重发的FIN+ACK报文，而服务端由于一直收不到ACK报文而无法顺利关闭

   > TCP设有一个保活计时器，默认为**2小时**，每次服务端收到客户端发来的数据，都会重置这个保活计时器。如果客户端2小时都没有给服务端发送数据，服务端就会每隔**75秒**给客户端发送一个**TCP探测报文**，**连续发送10次**后客户端仍然没有回应，那么服务端就会认为连接已经断开

2. 防止已失效的连接请求报文出现在之后的连接中。

   TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。



### 如何优化高并发TCP链接中产生的大量的TIME_WAIT的状态

如果系统中存在大量的TIME_WAIT状态，把所有系统可用端口都占完了且尚未被系统回收时，就会出现无法向服务端创建新的socket连接的情况，此时系统几乎停转，任何连接都不能创建

统计状态的命令：

1. netstat（性能一般）
2. ss -s（性能较高）

解决：

1. 调整系统内核参数
2. 把短连接优化为长连接



### 拥塞控制

TCP Reno使用了四种算法来实现拥塞控制：

- ==慢开始==

  **使窗口cwnd指数增长（`cwnd = cwnd * 2`）**，从小到大逐渐增大拥塞窗口的大小

- ==拥塞避免==

  拥塞窗口到达门限值`ssthresh`后，采用拥塞避免算法，**使窗口cwnd加法增长（`cwnd = cwnd + 1`）**

- ==快重传==

  当收到**3个重复确认**之后，无需等待重传计时器到时，可以立即重传

- ==快恢复==

  执行完快重传算法后，不是执行慢开始算法，而是执行快恢复算法，**把门限值`ssthresh`和拥塞窗口大小`cwnd`都调整为当前窗口大小的一半（`ssthresh = cwnd / 2，cwnd = cwnd / 2 = ssthresh`）**

  > TCP Tahoe协议是最早的TCP拥塞控制版本，它只采用了慢开始、拥塞避免、快重传三种算法，当发生重传后直接采用慢开始算法，乘法减小：**门限值减半（`ssthresh = ssthresh / 2`）、拥塞窗口大小设为1（`cwnd = 1`）**
  >
  > 慢开始和拥塞避免结合起来就是AIMD算法（Add Increment，Multiple Decrement）

![image-20220111141705886](https://tva1.sinaimg.cn/large/008i3skNgy1gy9pium5nlj30mh09a755.jpg)



### TCP Fast Open

常规的情况下，客户端和服务端需要经过TCP三次握手建立连接后才能进行通信。其中，TCP的第一二次握手是不能携带数据的，第三次握手客户端可以携带数据发送ACK包给服务端，因为这时候客户端已经是ESTABLISHED（连接已建立）状态了，即客户端这一方已经建立完连接了。

TCP Fast Open是为了绕开TCP三次握手发送数据，在Linux3.7内核版本之后，提供了TCP Fast Open功能，这个功能可以减少TCP连接建立的时延。要使用TCP Fast Open功能，**客户端和服务端都要同时支持才会生效**。

TCP Fast Open过程：

1. 客户端发送SYN报文，该报文包含Fast Open选项，且该选项的Cookie为空，表示该客户端向服务端请求Fast Open Cookie
2. 服务器要先检查自己是否支持TCP Fast Open，如果支持，则生成Cookie，并把该Cookie置于SYN-ACK报文中的Fast Open选项发送给客户端
3. 客户端收到SYN-ACK包后，本地缓存Fast Open选项中的Cookie，并向服务端发送ACK包

> 以上实际上是基本的TCP三次握手，只不过多了一个Fast Open选项填充Cookie

4. 之后双方如果需要重新建立连接，客户端在第一次握手的时候把缓存的Cookie放入Fast Open选项中，并携带应用数据（第一次握手就可以发送数据），发送SYN包给服务端

5. 服务器收到SYN包后会对Cookie进行校验

   - 如果Cookie有效，则接收应用数据并交给应用程序处理，并在随后发出的SYN-ACK包对SYN和应用数据进行确认；

   - 如果Cookie无效，则丢弃SYN包中的应用数据，并在随后发出的SYN-ACK包对SYN进行确认

6. 客户端收到SYN-ACK包后检查服务端的确认情况：

   - 如果应用数据没有被确认，则重新发送

   - 如果应用数据被确认，则后面TCP正常传输

> 所以TCP Fast Open**需要一次完整的TCP三次握手过程**，之后的通信才可以**绕过三次握手发送数据**（借用Cookie缓存之前连接的相关信息），这样子就**减少了握手带来的1.5个RTT的时间消耗**



### TCP四个保活计时器

1. ==重传计时器==

   - 目的：统计报文的等待确认时间，以便决定是否需要重传，以保证数据的可靠传输
   - 创建时间：TCP发送报文段后开始计时
   - 如果收到了确认，则撤销此计时器；如果到时后没有收到确认，则重新发送数据，并重置重传计时器
   - 重传时间：2RTT

2. ==坚持计时器==

   - 目的：解决零窗口大小通知可能导致的死锁问题

     > 这个死锁问题即：当接收端的窗口大小为0时，会向发送端发送一个零窗口通知报文，发送端收到后就会停止发送数据，等待可以继续发送数据的通知；当接收缓存有空间则会给发送端发送一个窗口大小，即通知发送端可以继续发送数据了，但是这个通知的报文可能会丢失，这样的话就会造成死锁问题，接收端一直等待数据传输，而发送端由于没有收到通知误认为接收端窗口仍为0，不会发送数据

   - 当发送端收到零窗口通知报文后，就会设置一个坚持计时器，坚持计时器到时后就会向接收端发送一个探测报文，检测接收端是否仍为零窗口，并把计时器的值加倍并复位，直到大于门限值（一般为60秒）

3. ==保活计时器==

   - 为了防止两个TCP连接出现长时间的空闲，这种情况很有可能是客户端出现故障，服务器会一直等待
   - 每当服务端收到客户端的数据时，就重置保活计时器。如果保活计时器到时了（一般为2小时），服务端还没有收到客户端发送的数据，就会每隔75秒发送一个探测报文段给客户端，当连续发送10次后仍然没有收到客户端的来信，则服务器认为客户端出现故障，主动关闭连接

4. ==时间等待计时器==

   - 用于计时TCP四次挥手中的TIME_WAIT状态等待的2MSL时间



### 什么是TCP粘包、拆包问题？



### TCP是怎么保证可靠传输的？



### 流量控制和拥塞控制有什么区别？



### 糊涂窗口综合征



## UDP

### TCP与UDP对比

### 怎么实现UDP的可靠传输？

### 什么是UDP洪水攻击



## Cookie、Session、Token

- Cookie

  是服务端发送给客户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器发起请求时被一并携带。通常，它用于告知服务器端两个请求是否来自同一浏览器，使得无状态的HTTP记录稳定的状态信息成为了可能

  主要用于：

  1. session管理：基于cookie的session管理，设置一个唯一的cookie表示本次会话，基于这个标识进行用户授权
  2. 个性化
  3. 追踪用户信息

- Session

  代表着服务器和客户端一次会话的过程，存储着特定用户会话所需的属性和配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在Session中的信息不会丢失，而是在整个用户会话期间一直存在下去。当客户端关闭会话，或者Session超时都会失效
  
- Token

  Token是由服务端生成的一串字符串，以作客户端进行请求的令牌。当客户端第一次登陆之后，获得了服务端分发的token令牌，之后客户端携带token请求服务器，而无需再携带用户名和密码，服务端也无需查询数据库进行校验。从而减少频繁的查询数据库，减轻服务器的压力



### Cookie与Session对比

|              |                 Cookie                 |             Session              |
| :----------: | :------------------------------------: | :------------------------------: |
|   保存位置   |            客户端（浏览器）            |              服务器              |
| 存储数据类型 |                 ASCII                  |             任意类型             |
| 存储数据大小 |            较少，不能超过4K            |                多                |
|    有效期    |        较长，客户端关闭不会失效        |      较短，客户端关闭会失效      |
|    安全性    | 低（存放在浏览器中的数据可能会被盗取） | 高（存储在服务器上所以无法伪造） |



### Session与Token对比

- session存储在服务端，token存储在客户端
- session机制存在服务器压力增大、CSRF跨站伪造请求攻击、扩展性差等问题
- token提供认证和授权功能，作为身份认证，token比session安全性更高
- session这种会话存储方式只适用于客户端代码和服务端代码运行在同一台服务器上，而token适用于项目级的前后端分离（前后端代码可以运行在不同服务器下）



### Cookie种类

- `session cookie`

  当`cookie`没有设置超时时间，那么`cookie`会在浏览器退出时销毁

- `persistent cookie/tracking cookie`

  设置了超时时间的`cookie`，在达到超时时间后会被销毁。`cookie`的维持可以持续到浏览器退出之后，如果还没到达超时时间，即使退出了浏览器`cookie`也不会被销毁。这种`cookie`被持久化在浏览器中，很多站点用这种`cookie`跟踪用户的历史记录，用于追踪用户行为

- `secure cookie`

  服务器端设置`cookie`时可以指定`secure`属性，这时`cookie`只有通过https传输的时候才会带到网络请求中，不加密的http请求不会带有`secure cookie`

  ```
  Set-Cookie: foo=bar; Path=/; Secure
  ```

- `HttpOnly cookie`

  服务器设置`cookie`时可以指定`HttpOnly`属性，设置了这个属性的`cookie`在`javascript`中无法获取到，只会在网络传输过程中带到服务器

  ```
  Set-Cookie: foo=bar; Path=/; HttpOnly
  ```

- `third-party cookie`

  第三方`cookie`的使用场景通常是`iframe`，例如www.a.com嵌入了一个www.ad.com的广告iframe，呢么www.ad.com设置的cookie不属于www.a.com，被称作第三方`cookie`

- `super cookie`

  `super cookie`会被声明从属于某个域名，这样的话这个`cookie`会在任何该域名下都生效，这样会有很大的安全性问题。浏览器做出了限制，不允许设置顶级域名`cookie`和公共后缀`cookie`，如果有些浏览器使用的顶级域名和`public suffix`列表有问题，那么就可以针对`super cookie`进行攻击了

- `zombie cookie/evercookie`

  指的是当用户通过浏览器的设置清除`cookie`后可以自动重新创建的`cookie`。原理是通过使用多重技术记录同样的内容，当`cookie`被删除时，可以从其他存储中恢复



### Cookie与Session结合

1. 用户第一次请求服务器时，服务器根据用户提交的相关信息调用`getSession()`方法创建`Session`，并创建一个特殊的`Cookie`（`name`为`JSESSIONID`的固定值，`value`为`session`对象的ID），同时该`Cookie`会记录此`SessionID`属于哪一个域名。然后将该`Cookie`发送至浏览器端
2. 用户第二次请求服务器，请求前会先自动查找该域名下是否有`Cookie`存在，如果有就一并携带发送给服务器。服务器从`Cookie`中提取到`SessionID`去寻找对应的Session信息
   - 如果没有找到说明用户没有登陆或者登陆失效
   - 找到的话就可以执行后续操作



### 如果客户端禁止Cookie使用，还能继续使用Session吗？

因为SessionID是通过Cookie来传递的，如果客户端禁用了Cookie，那么就无法向服务端传递SessionID，也就无法得到Session

可采用其他实现途径：

1. 手动通过URL、隐藏表单传递SessionID
2. 用文件、数据库等形式保存SessionID，在跨页过程中手动调用



### 分布式Session

如果应用程序采用分布式架构，使用多台服务器支撑用户请求。那么如果一个用户请求第一次请求服务器A，第二次请求服务器B，就会出现明明已经登陆了，但是由于服务器B上没有Session信息而导致无法正常继续访问

解决方法：

- ==客户端存储==：把信息存放在Cookie里。这样就会面临敏感信息泄漏的风险
- ==复制Session==：所有的Session在每个服务器上都有一份，当一个服务器上的Session信息发生变化时，就会广播给其他服务器通知它们要对Session进行修改。浪费服务器内存、Session维护困难
- ==Nginx ip_hash策略==：通过`ip_hash`的方式保证同一个IP固定访问一个服务器。负载均衡问题
- ==🌟共享Session==：服务端无状态化，把用户的Session存放在第三方缓存中间件上（如Redis）来统一管理，从而保证分发给每一个服务器的响应结果一致



## XSS攻击

跨站脚本攻击XSS，指恶意攻击者往Web页面内插入恶意script代码，当用户浏览该Web页面时，嵌在Web里面的script代码会被执行，从而达到恶意攻击用户的目的。



### 反射型XSS

![img](https://img-blog.csdnimg.cn/20190115094753418.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTE5MTky,size_16,color_FFFFFF,t_70)

**非持久化，服务器中没有XSS代码**，需要欺骗用户去点击恶意链接才能触发XSS代码，一般用于盗取用户的Cookie信息



### 存储型XSS

![img](https://img-blog.csdnimg.cn/20190115094820160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTE5MTky,size_16,color_FFFFFF,t_70)

**持久化，恶意代码是存储在服务器中的**。当用户查看了服务器的存在恶意脚本的页面后，就会触发恶意代码的执行，这种XSS比较危险，容易造成蠕虫，盗窃Cookie

> 蠕虫是一种能够利用系统漏洞通过网络进行自我传播的恶意程序，它是利用网络进行复制和传播，传染途径是通过网络和电子邮件



### DOM型XSS

不经过后端，DOM-XSS漏洞是基于文档对象模型(Document Objeet Model,DOM)的一种漏洞，DOM-XSS是通过url传入参数去控制触发的，其实也属于反射型XSS。



### XSS的防御

1. 对输入（和URL参数）进行过滤（特殊字符进行转义），对输出进行编码

   对提交的所有内容进行过滤，对url中的参数进行过滤，过滤掉会导致脚本执行的相关内容；然后对动态输出到页面的内容进行HTML编码，使得脚本无法在浏览器中执行。虽然对输入过滤可以被绕过，但还是能拦截很大一部分XSS攻击

2. `Cookie`设置`HttpOnly`属性，这样的话js无法获取`Cookie`的信息，从而拦截了存储型XSS攻击



## DDoS攻击

DDoS攻击即分布式拒绝服务攻击，采用分布式的方法，通过在网络上占领多台“肉鸡”，用它们向服务器发起攻击

### 基本过程

1. 扫描大量主机以寻找可入侵主机目标
2. 攻击有安全漏洞的主机并获取控制权
3. 入侵主机中安装攻击程序
4. 用入侵主机继续扫描和入侵
5. 当“肉鸡”达到一定数量后，攻击者可以通过主控机发出攻击命令。

由于攻击主控机的位置非常灵活，并且发布命令的时间非常短（发出攻击命令后可以立即关闭并脱离网络），因此难以追踪以定位。“肉鸡”收到攻击命令后就会对服务器发出大量的服务请求数据包，并且不回应服务器的要求回复，以此耗尽服务器的资源和带宽。



### 攻击识别

1. Ping测试（流量攻击）

   如果发现Ping超时或者丢包严重，则当前可能正在经受DDoS攻击。若发现相同交换机的服务器上也无法访问，则基本可以确定为流量攻击。Ping测试的前提是受害主机到服务器间的**ICMP协议**没有被路由器和防火墙等设备屏蔽

2. Telnet测试（资源耗尽攻击）

   其显著特征是远程终端连接服务器失败，相对流量攻击，资源耗尽攻击易判断，若网站访问突然非常缓慢或无法访问，但可Ping通，则很可能遭受攻击，若在服务器上用Netstat-na命令观察到大量 SYN_RECEIVED（收到了客户端发来的连接请求报文）、 TIME_WAIT， FIN_ WAIT_1等状态，而EASTBLISHED很少，可判定为资源耗尽攻击，特征是受害主机Ping不通或丢包严重而Ping相同交换机上的服务器正常，则原因是攻击导致系统内核或应用程序CPU利用率达100%无法回应Ping命令，但因仍有带宽，可ping通相同交换机上主机。



### 攻击方式

1. **SYN洪泛攻击**

   “肉鸡”通过发起连接请求报文并且不回应服务器的SYN+ACK包，在服务器上使用Netstat-na命令可以观察到大量的SYN_RECEIVED状态，大量的这种攻击会导致Ping失败，TCP/IP栈失效，并会出现系统凝固现象，即不响应键盘和鼠标。

2. **TCP全连接攻击**

   一般情况下，常规防火墙大多具备过滤 TearDrop、Land等DOS攻击的能力，但对于正常的TCP连接是放过的。而服务器可以支持的TCP全连接是有限的，“肉鸡”就是通过与服务器建立大量的TCP全连接，这样的话可以绕过常规防火墙的检查，以耗尽服务器资源。

   - 可以绕过常规防火墙检查
   - 需要大量的僵尸主机
   - 僵尸主机IP暴露，容易追踪

3. **TCP刷script攻击**

   这种攻击主要是针对存在ASP、JSP、PHP、CGI等脚本程序，并调用 MSSQL Server、My SQL Server、 Oracle等数据库的网站系统而设计的，特征是和服务器建立正常的TCP连接，不断的向脚本程序提交查询、列表等大量耗费数据库资源的调用，典型的以小博大的攻击方法。

   一般来说，提交一个POST或者GET请求所耗费的资源和占用的带宽对客户端来说几乎是可以忽略的，但是服务器为了完成这个请求可能需要在大量数据中查找，这种处理对服务器的消耗是非常大的

   - 可以绕过普通防火墙防护，轻松找一些Proxy代理就可以实现
   - 对付只有静态页面的网页效果会大打折扣（因为对静态资源的访问消耗并不是特别大），并且某些代理可能会暴露攻击者IP
   - 典型表现是页面响应缓慢、ASP程序失效、数据库占用CPU高等



#### 防御方式

1. **高防服务器**

   高防服务器主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等。缺点是成本高

2. **黑名单**

   遇到疑似攻击的就拉入黑名单，禁止其之后的访问（阻止攻击）。缺点是可能会影响正常流量，影响到正常业务

3. **DDoS清洗**

   DDoS 清洗会对用户请求数据进行实时监控，及时发现DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量。

4. **CDN加速**

   在现实中，CDN 服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃。



## 在浏览器输入一个网址www.baidu.com后执行的全部过程

1. DNS域名解析

   - 浏览器先搜索**自己的DNS缓存**（浏览器有维护一张域名和IP的对应表）

   - 如果搜索不到，就搜索**操作系统中的DNS缓存**

   - 还是没有，则搜索**操作系统的hosts文件**（在Windows环境下，维护着一张域名与IP的对应表，位置一般在C:\Windows\System32\drivers\etc\hosts）

   - 若没有，则操作系统把域名发送到**本地域名服务器**，本地域名服务器查询自己的DNS缓存，如果查找成功则返回结果

     > 操作系统→本地域名服务器是**递归查询方式**（发送域名）

   - 如果本地域名服务器也查询不到，则向**根域名服务器**发起请求

     > 本地域名服务器→根域名服务器是**迭代查询方式**（发送请求）
     >
     > 根域名服务器虽然没有每个域名的具体信息，但是存储了负责如com、net、org等的解析的顶级域名服务器的地址。此处，根域名服务器会返回负责解析com域的顶级域名服务器的地址

   - 本地域名服务器向com域的**顶级域名服务器**发起请求，顶级域名服务器会返回baidu.com的权限域名服务器的地址

     > 权限域名服务器，用来保存该区中的所有主机域名到IP地址的映射

   - 本地域名服务器向baidu.com的**权限域名服务器**发起请求，得到www.baidu.com的IP地址

   - 本地域名服务器把IP地址缓存起来并返回给操作系统

   - 操作系统把IP地址缓存起来并返回给浏览器

   - 浏览器缓存IP地址

2. 浏览器从1024-65535中选择一个随机端口向服务器的80端口发起TCP三次连接请求（🌟TCP三次握手过程）

3. 建立TCP连接完成后发送HTTP连接（🌟HTTP协议、HTTPS过程）

4. 服务端响应HTTP请求，处理请求完成后返回HTML给客户端

5. 浏览器解析HTML代码，并请求HTML中的资源，以及渲染页面

### 使用到的协议

- `DNS`：解析域名，获取IP地址，**属于应用层**
- `TCP`：HTTP协议基于TCP协议，**属于传输层**
- `HTTP`：使用HTTP协议访问页面，**属于应用层**
- `IP`：发送数据在网络层使用IP协议，**属于网络层**
- `OSPF`：IP数据包的路由选择使用OPSF协议，**属于传输层**
- `ARP`：IP地址转换为MAC地址，**属于IP层**



## CDN

CDN也就是内容分发网络(Content Delivery Network)，它是构筑在现有Internet上的一种先进的流量分配网络。其目的是**通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。**有别于镜像，它比镜像更智能，可以这样一个比喻：CDN = 镜像(Mirror) + 缓存(Cache) + 整体负载均衡(GSLB)。因而，CDN可以明显提高Internet中信息流动的效率。

目前**CDN都以缓存网站中的静态数据为主**，如CSS、JS、图片和静态页面等数据。用户从主站服务器请求到动态内容后再从CDN上下载这些静态数据，从而加速网页数据内容的下载速度，如淘宝有90%以上的数据都是由CDN来提供的。



## 负载均衡

### 链路负载均衡

即通过DNS把域名动态解析成不同的IP地址，用户根据解析的IP地址去访问目标服务器。负载均衡是由DNS解析来完成的，即用户最终访问哪个服务器是由DNS Server来控制的。

- 用户会直接访问目标服务器，不需要经过其他的代理服务器，访问速度比较快
- DNS在用户本地和本地域名服务器都有缓存，一旦某台目标服务器挂掉，则很难更新用户的域名解析结构，如果没有及时更新，那么用户将无法访问这个域名，后果非常严重



### 集群负载均衡

通常分为硬件负载均衡和软件负载均衡

- 硬件负载均衡即使用一台专门的硬件设备来转发请求
  - 性能好
  - 成本高、不能进行动态扩容
- 使用代理服务器进行访问，是现在使用最普遍的一种负载均衡方式
  - 成本低
  - 一次访问请求可能会多次经过代理服务器，会增加网络延时



### 操作系统负载均衡

利用操作系统级别的软中断或者硬件中断来达到负载均衡，如可以设置多队列网卡来实现



## 盗链



## DNS劫持
