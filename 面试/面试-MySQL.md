# 面试-MySQL

## 数据库基础

### 数据库三大范式是什么

1. 第一范式（1NF）
   - 强调的是列的原子性，数据库的每一列都是不可分割的原子项
   - 尽量合并属性一样的列，确保不产生冗余数据
2. 第二范式（2NF）
   - 在第一范式的基础上要求实体的属性完全依赖于主键
   - 即数据库中的每一行数据必须可以被唯一的区分，区分的根据（唯一属性）就是主键
3. 第三范式（3NF）
   - 任何非主属性不依赖于其他非主属性



### MySQL支持的存储引擎

|     功能     | InnoDB | MyISAM | Memory | Archive |
| :----------: | :----: | :----: | :----: | :-----: |
|   存储限制   |  64TB  | 256TB  |  RAM   | 无限制  |
|   支持事务   |   √    |   ✕    |   ✕    |    ✕    |
| 支持全文索引 |   ✕    |   √    |   ✕    |    ✕    |
|  支持树索引  |   √    |   √    |   √    |    ✕    |
| 支持哈希索引 |   ✕    |   ✕    |   √    |    ✕    |
| 支持数据缓存 |   √    |   ✕    |   -    |    ✕    |
|   支持外键   |   √    |   ✕    |   ✕    |    ✕    |

> 哈希索引（散列索引）进行等值比较的时候比较快
>
> B树索引优于散列索引的是，可以使用部分查询和通配查询，也可以使用<、>和>=等操作符方便数据挖掘
>
> 全文索引是一种特殊类型的索引,它查找的是文本中的关键词,而不是直接比较索引中的值。当使用Blob或者Text这种大文本类型的时候，如果直接使用like搜索这个字段中的某些字符，不走索引，这个时候就要对这个字段使用全文索引（只对英语好用，因为其本身已经用空格进行分词了；而对于中文之类的非自然语言，就需要借助ES和Slor这样的站内索引引擎实现）
>
> 所以MySQL的全文索引实际上非常鸡肋，在实际使用中，缓存使用Redis或者Mongodb实现，查询大文本中的字符用ES或者Solr实现。



#### InnoDB和MyISAM的区别

- ==事务、外键==

  InnoDB支持，MyISAM不支持

- ==全文索引==

  InnoDB不支持，MyISAM支持，故查询效率上MyISAM要更高

- ==索引==

  - InnoDB支持聚簇索引和二级索引，MyISAM中全部都是二级索引

  - 聚簇索引即索引树的叶子结点保存着数据文件。MyISAM中叶子结点保存的是数据文件的指针，一定需要回表操作

    > 所以MyISAM表可以没有主键

- ==表的具体行数==

  - InnoDB没有保存表的具体行数，只有一个估计值，故count(*)的时候需要计算，效率比较慢

    > 事务的原因，不同事务看到的表的总行数可能是不一样的，而count(*)统计的是对本事务而言的可以统计的总行数，所以没有把总行数存储起来方便查询

  - MyISAM中把一个表的总行数存在了磁盘上，如果执行不带条件的count(*)直接到磁盘上读取即可，效率很快。但是如果是带条件的count(\*)，那还是需要计算的

- ==锁==

  - InnoDB支持行级锁和表级锁，默认为行级锁
  - MyISAM只支持表级锁



#### 选择方案

- 如果要提供提交、回滚和恢复的事务安全（ACID 兼容）能力，并要求实现并发控制，InnoDB 是一个很好的选择。
- 如果数据表主要用来插入和查询记录，则 MyISAM 引擎提供较高的处理效率。
- 如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存的 MEMORY 引擎中，MySQL 中使用该引擎作为临时表，存放查询的中间结果（缓存）。
- 如果只有 INSERT 和 SELECT 操作，可以选择Archive 引擎，Archive 存储引擎支持高并发的插入操作，但是本身并不是事务安全的。Archive 存储引擎非常适合存储归档数据，如记录日志信息可以使用 Archive 引擎。



### varchar和char的区别

- char是一个定长字段，假如申请了一个字段char(10)，那么无论实际存储多少内容，该字段都占用10个字符
- 而varchar是一个变长字段，其占用空间为实际存储长度+1，额外的一个字符是用来存储该字符串的长度的。
- 检索效率上来说，char > varchar



### in和exist的区别

- exist对外表用loop逐条查询，每次查询都会查看exist的子查询，如果子查询不返回NULL，则exist为真，就把当前loop到的外表记录放入结果集中，反之则丢弃loop到的外表记录。对返回结果的字段没有要求
- in是把外表和内表作hash连接，然后在内存中遍历比较。要求返回结果必须只有一个字段
- 性能问题
  - 假设外表为A，内表为B。由于in需要把B表中的数据全部遍历，因此B表数据越多，in查询效率越慢。而exist并不关心B中的数据有多少，只关心其是否为NULL，因此不会对B进行缓存，其不需要便利操作，只需要多次查询。
    - 查询中两个表的大小相当，用in和exist差别不大
    - 如果大表在外，用in（小表在内遍历快）
    - 如果大表在内，用exist（大表在内查询快）
  - not in查询内外表都使用全表扫描，用不了索引
  - not exist的子查询仍然能用到索引，所以not exist效率一定比not in高



## 事务

### 事务的ACID特性

- ==原子性（Atomicity）==

  原子性是指事务要么全部执行，要么全部不执行。如果事务的执行过程中发生了错误，那么就会回滚到事务执行前的起点，撤销事务执行过的操作（以保证数据库的一致性）

  example：假设一个事务，A向B转账100元，包含两个操作：扣除A账户100元，B账户入账100元。如果这个事务不具有原子性的话，可能会出现这样的情况：扣除A账户100元后，发生了异常导致没有完成第二个操作，导致A明明把钱转出去了，B却没有收到，这100元不翼而飞

- ==一致性（Consistency）==

  数据库中只包含成功事务提交的结果。

- ==隔离性（Isolation）==

  并发执行的各个事务之间不能相互干扰

- ==持久性（Durability）==

  一个事务一旦提交，其对数据库的操作结果就是永久的，接下来的其他操作或故障都不应该对其产生任何影响



### 脏读、幻读、不可重复读

- ==脏读==

  事务A读取了事务B更新的数据后，B事务回滚了，那么A读取到的数据就是脏数据

- ==不可重复读==

  在事务A多次读取的过程中，事务B对该数据进行了更新/删除并提交，导致事务A后面再次读取发现无法读取到这条数据

- ==幻读==

  在事务A多次读取过程中，事务B插入了一条新的数据，导致事务A再次读取发现多了一条数据

  example：事务A要把所有红色数据都改成蓝色，在A修改完毕提交之前，B插入了一条红色数据，A提交之后发现明明自己已经把数据全部都改了，数据库中还是有一条红色数据



### 四种隔离级别

|           隔离级别           | 脏读 | 不可重复读 | 幻读 |
| :--------------------------: | :--: | :--------: | :--: |
| 读未提交（READ UNCOMMITTED） |  √   |     √      |  √   |
|  读已提交（READ COMMITTED）  |  ✕   |     √      |  √   |
| 可重复读（REPEATABLE READ）  |  ✕   |     ✕      |  √   |
|   可串行化（SERIALIZABLE）   |  ✕   |     ✕      |  ✕   |

- ==读未提交==

  所有事务可以看到其他未提交事务的执行结果

- ==读已提交==

  所有事务只能看到其他已提交事务的执行结果

- ==可重复读==（MySQL默认的事务隔离级别）

  确保并发事务的多个实例在同时读取数据时，会看到同样的数据

- ==可串行化==

  通过强制事务排序，使之不可能相互冲突，从而解决了幻读问题。

  > 在每个读的数据行上都加上共享锁，可能会导致大量的锁竞争和超时现象，严重降低并发度



### InnoDB存储引擎是怎么在可重复读隔离级别解决幻读问题的？

幻读问题即一个事务的提交造成了另一个事务多次查询结果的不一致性。（其实是不可重复读的一种特殊情况，主要针对的是插入操作）

1. MVCC并没有完全解决幻读问题，其只是利用快照读在某些场景下规避了幻读：如上图，事务A的两次查询结果是一致的，因此没有幻读问题

   <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h02k5uhel9j20ka0aw3yt.jpg" alt="image-20220308163320506" style="zoom:80%;" />

2. 但是如果如下图，事务A不加条件的update会作用在表中所有行上，包括事务B插入的新数据。因此导致这条新数据产生了一个新版本，trx_id为事务A的id。所以事务A第二次查询的时候会误以为这条数据对其是可见的，导致第二次查询出现了新的数据，这个场景下，就算是产生了幻读问题了

   | 时间点 |                       事务A                        |       事务B       |
   | :----: | :------------------------------------------------: | :---------------: |
   |   1    |                      开启事务                      |                   |
   |   2    |                                                    |     开启事务      |
   |   3    |      查询数据where name=haha，得到（1，2，3）      |                   |
   |   4    |                                                    | 插入数据(4,sgtsf) |
   |   5    |                                                    |       提交        |
   |   6    | update set xx=xx ➡️ 使得事务B插入的数据产生了新版本 |                   |
   |   7    |    查询数据where name=haha，得到（1，2，3，4）     |                   |

3. 想要完全避免，需要手动把快照读调整为当前读，通过行锁+间隙锁的方式来彻底解决幻读问题，详看-幻读怎么产生的，MySQL怎么解决



## MVCC

### 什么是MVCC？

MVCC即多版本并发控制，它通过实现**读写冲突的无锁并发控制**，大大提高了数据库的性能。

在没有MVCC前，想要解决读写冲突的话，当同一行发生读写请求的时候，则给该行加上行锁。但是MVCC通过快照读，使得读写不需要加锁也可以实现并发安全。

但是，MVCC无法解决写写冲突问题（上面说的第二类更新丢失）



### MVCC的实现原理

几个要点：版本链、undo_log、ReadView

1. 每行数据中有一些隐藏字段：

   - row_id：如果该表没有设置主键的话，就会自动添加该隐藏列作为自增主键
   - trx_id：记录着最后一次更新该条记录的事务ID
   - roll_pointer：指向undo_log中该条记录的上一个版本，通过这个roll_pointer指针，把一条记录的多个版本串联起来形成了一个版本链
   - 删除flag：当删除一条数据时，其实并不是真正的删除，而是修改了这个flag，因为如果真正删除的话就无法回滚删除操作了

2. 更新一条记录的过程：

   - 把该条记录的旧值移入undo_log
   - 修改记录的trx_id，并让roll_pointer指向旧值
   - 当事务回滚的时候就可以通过对undo_log的日志进行逆向操作来进行数据还原了

3. ReadView，即快照

   - 快照中维持着几个有关于事务ID的值：

     - `m_ids`：在生成该ReadView时活跃的事务id列表
     - `min_trx_id`：`m_ids`中的最小值，可以理解为生成该ReadView时活跃的事务中最早的事务
     - `max_trx_id`：生成该ReadView时系统应该分配给下一个事务的id，不一定是`m_ids`的最大值（因为可能在生成之后分配之前有其他事务）
     - `creator_trx_id`：生成该ReadView的事务id

     > 某条记录的最新版本对于当前事务不一定是可见的，会根据当前事务id和快照中这几个值来判断该版本是否可见，如果不可见则顺着版本链向前一个版本继续判断
     >
     > 可见的：
     >
     > 1. creator_trx_id = 数据中的trx_id，即该条记录就是这个事务自己修改的，因此可见
     > 2. 数据中的trx_id < min_trx_id，说明这条数据在当前事务开启之前就已经存在了，因此可见
     >
     > 不可见的：
     >
     > 1. 数据中的trx_id >= max_trx_id，说明这个版本是在ReadView创建之后才产生的
     > 2. 数据中的trx_id在m_ids中，说明生成ReadView的时候，生成这个版本的事务还没有提交（活跃中），因此对于当前事务也是不可见的（无法看见其他事务还没有提交的数据）

   - 读已提交级别下，事务中每次操作都生成一个ReadView；可重复读级别下，事务中只有第一次查询生成一个ReadView，之后所有操作都在这个ReadView下完成



### 怎么利用版本号实现可重复读？



## 索引

### 以a、b、c为顺序建立的联合索引，以下几种查询条件是否会走联合索引？

1. WHERE a = ?

   √

2. WHERE a = ? AND b = ?

   条件ab都会走索引

3. WHERE a = ? AND c = ?

   条件a会走索引，条件c不会走。因为是按照a、b、c顺序建立的，因此索引的排序依据依次是a、b、c，所以根据条件a查询完的结果集中c的值是乱序的，走不了索引

4. WHERE b = ? AND c = ?

   不走索引，理由同3

5. WHERE b = ? AND a = ?

   条件ab都走索引，因为查询优化器会把其优化为3

6. WHERE a = ? AND b = ? AND c = ?

   √



## 日志

### MySQL中的日志

#### CheckPoint机制

随着MySQL的运行，Buffer Pool中的数据页会被修改成脏数据页，当你开启事物进行一系列的操作时MySQL会为你不停的记录一堆日志，拿redo log来说，redo log也是需要往先往内存中写，再以块的形式刷新回磁盘。

无论怎样，都会存在这样一个中间过程：内存中存在脏数据页、和脏日志未来得及刷新回磁盘。

而本小节中要说的Checkpoint机制就是将这些脏数据刷新回磁盘的机制，即只要发生Checkpoint，就要将脏数据刷新回磁盘，反过来，当MySQL重启时会去找Checkpoint，并且根据Checkpoint的特性。MySQL可以明确的知道checkponit之前的脏数据已经落过盘了，重启时没必要进行重做。

看到这里你已经大概知道Checkpoint是什么了。我们在稍微总结一下Checkpoint机制的作用：

1. 所谓的崩溃恢复，其实就是MySQL重启时照着redo log中的最后一次Checkpoint之后的日志回放一遍
2. 因为Checkpoint会不断的更新，并且**MySQL重启时只需要对Checkpoint之后的数据进行恢复**，所以Checkpoint会缩短MySQL重启的时间。
3. **因此每次进行Checkpoint时buffer pool中的脏数据页、redo log中的脏日志都会落盘**。所以Checkpoint实际上起到了为这两者进行瘦身的作用。维持两个的可用性。



#### redo log

==实现了事务的持久性==。事务的持久性即只要事务提交成功，那么其对数据库作的修改就是永久有效的，最简单的实现就是每次事务提交的时候，都把该事务设计修改的数据页全部刷到磁盘中，但是这样有严重的性能问题：

1. InnoDB是以页为单位进行磁盘交互的，但是一个事务可能只会修改一个数据页里面的几个字节，这时候如果把完整的数据页刷到磁盘中就太浪费了
2. 随机IO性能低

为了解决这个性能问题，就提出了redo log，其包括了两部分：一个是在内存中的日志缓冲，另一个是磁盘上的日志文件。MySQL每执行一条DML语句，就把记录写到日志缓冲中，之后在合适的时机把缓冲刷到磁盘中（顺序IO）。WAL保证了数据持久化的同时，减少了随机IO 。

> WAL即：
>
> 1. 修改记录前，要先写日志
> 2. 事务提交过程中，日志一定要先刷盘，才能算事务提交完成

写入时机：

![img](https://pic4.zhimg.com/80/v2-213622cb332c35e77eea6667a471d8ef_720w.jpg)

redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。



#### undo log

==实现了事务的原子性==。每次对数据库数据进行修改的时候，就会在undo log中追加一条逻辑相反的，这样在发生错误事务需要回滚时，只要逆序执行undo log中记录的就可以了。

同时，undo log也是MVCC实现的关键，版本链就是undo log中的多条记录通过指针串联起来的



#### bin log

bin log用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。bin log是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录bin log日志。

> - 逻辑日志：可以简单理解为记录的就是sql语句。
> - 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更。

bin log是通过追加的方式进行写入的，可以通过`max_binlog_size`参数设置每个bin log文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

bin log主要用于主从同步和数据恢复。

对于InnoDB存储引擎而言，只有在事务提交时才会记录big log，此时记录还在内存中，那么big log是什么时候刷到磁盘中的呢？mysql通过`sync_binlog`参数控制biglog的刷盘时机，取值范围是0-N：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次commit的时候都要将bin log写入磁盘；
- N：每N个事务，才会将bin log写入磁盘。

从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。

binlog的三种格式：

> 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。

- `STATEMENT`

  基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。

  - 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能；
  - 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。

- `ROW`

  基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。

  - 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题；
  - 缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨

- `MIXED`

  基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog



### bin log与redo log的区别

1. `redolog`是InnoDB引擎特有的，因为其支持事务；`binlog`是MySQL的server层实现的，所有引擎都可以使用
2. 写入时机：`redolog`是在事务执行过程中不断写入的；而`binlog`是在事务最终提交前才写入的
2. 内容形式：redolog是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是语句的原始逻辑
2. 写入方式：redolog是循环写入，当写满后会从头开始写，覆盖之前的数据；binlog会新开一个文件继续写
2. 恢复数据的不同：redo日志是表空间页面落盘之前的对应操作日志，也就是说恢复的是在内存中，但是未落盘的这部分数据；binlog恢复的是已经确定在磁盘中的表空间数据，经常用于主从复制



### 事务与日志的关系（事务的实现原理）

1. 原子性：通过`undo log`实现，`undolog`是逻辑日志，每当事务执行了一条修改数据的语句，就会向`undolog`中追加一条相反的语句，这样在事务回滚的时候就可以通过回溯日志来达到恢复数据的目的

2. 持久性：通过`redo log`实现，`redolog`也是逻辑日志，在事务执行的过程中写入内存中的`redo log`，然后引擎在合适的时机将记录刷到磁盘中，假设`redolog`一秒刷一次，那么宕机的话只会丢失这一秒的数据，其余的已更新但还没来得及写入磁盘的数据可以根据日志恢复

   > WAL保证一致性和持久性：先写日志再写磁盘；日志刷盘完才能成功提交事务

3. 隔离性：MVCC快照读



### redo log与bin log的写入顺序（两阶段提交）

首先说明，单纯的谁先写入都会造成数据不一致性问题：

1. `redolog`先写，`binlog`后写：假设`redolog`写完后还没来得及写`binlog`的时候，MySQL进程崩溃重启。重启后仍然能通过`redolog`恢复数据，但是如果要进行数据同步的话，由于`binlog`中并没有记录到这次修改，这样就会导致从库没有同步到这条修改的数据，导致了数据的不一致
2. `binlog`先写，`redolog`后写：假设`binlog`写完之后`crash`了，由于`redolog`还没写，使用binlog来恢复的时候就多出了一个无效的事务

为了让`redolog`和`binlog`之间的逻辑一致，`redolog`的写入拆成了两个逻辑：`prepare`和`commit`，这就是两阶段提交，步骤如下：

1. 事务提交，进入`redolog`的`prepare`阶段
2. 写`binlog`
3. `redolog commit`，事务提交完成

在两阶段提交下，崩溃恢复有如下情况：

- 进入`redolog prepare`、`binlog`写之前的崩溃恢复：发现`redolog`还没提交，同时`binlog`中也没有对应数据，因此这个事务会回滚

- `binlog`写完成、`redolog commit`之前的崩溃恢复：`redolog`和`binlog`的数据通过XID联系起来，崩溃恢复时会顺序扫描`redolog`：
  - 如果是`prepare+commit`的`redolog`，就直接提交
  - 如果是只有`prepare`而没有`commit`的，就拿着XID到`binlog`中寻找对应的数据，如果binlog中的数据完整就提交
  
  > 如果一个事务的prepare阶段和binlog落盘成功，则这个事务一定提交成功



## 慢SQL排查思路

1. 是否为SQL语句本身导致的慢SQL
   - 可以用EXPLAIN语句查看SQL语句的执行计划，是否有走索引
   - SQL语句是否select的数据量非常大
2. SQL慢查询是否是其他外在因素导致的
   - 慢SQL执行期间，请求量是否很大
   - 是否有定时任务在大量操作数据库，导致锁表
3. SQL慢查询是否只在一个机房出现
   - 跨机房请求导致慢SQL
4. SQL慢查询是否由于网络问题
   - 可以用tcpdump抓包看看，是否出现了重传的现象
   - 比如应用到数据库不是直连的，应用→中间件A→中间件B→数据库实例。中间的网络是否正常



## 优化

### count(*)很慢，如何优化？

首先要明确的是，在不同的存储引擎中，count(*)有不同的实现方式：

- MyISAM把表的准确行数存储在了磁盘上，所以如果是不带条件的count(*)，MyISAM引擎会直接到磁盘上读取准确行数，效率十分快；但是如果是带条件的count(\*)，就只能像InnoDB一样读取数据并统计了

- 由于InnoDB的事务特性，在同一时刻表中的总行数对不同事务是不一样的，所以没有存储具体行数，而是会统计本事务可以统计的总行数。

  > 由于count(*)只是统计行数，不需要具体的数据内容，所以InnoDB会选择一棵最小的索引树，在保证正确的前提下，尽可能减少扫描的数据量

  ![image-20220117141403905](https://tva1.sinaimg.cn/large/008i3skNgy1gygn5i6depj30pk09i3z6.jpg)

  > 可以看到不同的事务同时调用count(*)得到的结果是不一样的

​		

优化：

1. 在数据库保存计数

   可以利用事务的特性把问题解决

   <img src="https://tva1.sinaimg.cn/large/008i3skNgy1gygn7nhj7vj30jg0abaah.jpg" alt="image-20220117141607212" style="zoom: 67%;" />

   > 如上图，事务A把计数值+1，但是由于还没提交，所以这个更新操作对事务B是不可见的，因此事务B查看到的结果也是本事务可以统计的数据总数

2. 如果不需要十分精确的行数，可以使用show table status命令查看估计行数

3. 用缓存系统保存计数，如Redis

   存在崩溃丢失的问题，计数不精确

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1gygn5blwxrj30jv072dg3.jpg" alt="image-20220117141350890" style="zoom:67%;" />

4. 按照效率排序的话，count(字段) < count(主键id) < count(1) ≈ count(*)

   - 对于count(字段)来说，InnoDB会遍历整张，判断指定的字段是否为空，如果不为空才按行累加

   - 对于count(主键id)来说，InnoDB会遍历整张表，把每一行的主键ID都拿出来，因为主键ID是不可能为空的，就直接按行累加

     > 由于InnoDB已经专门针对count(*)进行优化了，所以就没有再优化count(主键id)

   - 对于count(1)来说，InnoDB会遍历整张表，但不取值，而是直接放个1进去，自然也不可能为空，直接按行累加

     > 这样就比count(主键id)少了一个取值的操作，所以效率更高