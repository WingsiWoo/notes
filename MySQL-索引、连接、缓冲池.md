



# MySQL-索引、连接、优化、Buffer Pool

## InnoDB行

### 指定行格式

```sql
CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称
    
ALTER TABLE 表名 ROW_FORMAT=行格式名称
```



### Compact行格式

![image_1c9g4t114n0j1gkro2r1h8h1d1t16.png-42.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e8fafc21aa~tplv-t2oaga2asx-watermark.awebp)

#### 记录的额外信息

这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息。

##### 变长字段长度列表

MySQL支持一些变长数据类型：

- VARCHAR(N)
- VARBINARY(N)
- TEXT
- BLOB

拥有这些数据类型的列称为变长字段，变长字段中存储多少字节的数据是不固定的，所以在存储真实数据时需要把这些数据的长度也存起来。

在`Compact`行格式中，把所有变长字段的真实数据占用的字节长度都**存放在记录的开头部位**，从而形成一个变长字段长度列表，各变长字段数据占用的字节数**按照列的顺序逆序存放**。

![image-20211110200027105](https://tva1.sinaimg.cn/large/008i3skNgy1gwab104usnj31bq0ba40e.jpg)

具体用1个还是2个字节来表示真实数据占用的字节数，`InnoDB`有它的一套规则，我们首先声明一下`W`、`M`和`L`的意思：

1. 假设**某个字符集中表示一个字符最多需要使用的字节数为`W`**，也就是使用`SHOW CHARSET`语句的结果中的`Maxlen`列，比方说`utf8`字符集中的`W`就是`3`，`gbk`字符集中的`W`就是`2`，`ascii`字符集中的`W`就是`1`。
2. 对于变长类型`VARCHAR(M)`来说，这种**类型表示能存储最多`M`个字符**（注意是字符不是字节），所以这个类型能表示的字符串最多占用的字节数就是`M×W`。
3. 假设它**实际存储的字符串占用的字节数是`L`**。

所以确定使用1个字节还是2个字节表示真正字符串占用的字节数的规则就是这样：

- 如果`M×W <= 255`，那么使用1个字节（2^8^-1=255）来表示真正字符串占用的字节数。

  > 也就是说InnoDB在读记录的变长字段长度列表时先查看表结构，如果某个变长字段允许存储的最大字节数不大于255时，可以认为只使用1个字节来表示真正字符串占用的字节数。

- 如果`M×W > 255`，则分为两种情况：

  - 如果`L <= 127`，则用1个字节来表示真正字符串占用的字节数。
  - 如果`L > 127`，则用2个字节来表示真正字符串占用的字节数。

**如果某个变长字段的M×W>255，怎么区分正在读取的某个字节是一个单独的字段长度还是半个字段长度？**

InnoDB使用字节的第一个二进制位作为标志位：

- 标志位为0，该字节是一个单独的字段长度
- 标志位为1，该字节是半个字段长度

> 所以除去两个标志位，有14位可用于存储字段长度，故字段最大长度为2^14^B=16KB。如果某个字段长度大于16KB，如果该记录在单个页面中无法存储时，InnoDB会把一部分数据存放到溢出页中，在变长字段长度列表处只存储留在本页面的长度。

> 变长字段长度列表不是一定存在的，如果表中所有列都不是变长数据类型，这一部分就不需要，并且变长字段长度列表不存储值为NULL的列内容占用的长度



##### NULL值列表

为了避免记录的真实数据中存储NULL值，浪费空间，Compact行格式把值为NULL的列统一管理起来，存储到NULL值列表。处理过程如下：

1. 统计表中允许存储NULL的列
2. 每个允许存储NULL的列对应一个二进制位，二进制位**按照列的顺序逆序排序**
   - 二进制位的值为1，该列的值为NULL
   - 二进制位的值为0，该列的值不为NULL
3. NULL值列表必须用整数个字节的位表示，如果使用的二进制位数个数不是整数个字节，就在**字节的高位处补0**

> NULL值列表也不是一定存在的，如果表中所有列都是NOT NULL，这一部分也不需要



##### 记录头信息

记录头信息由固定的5个字节组成（40个二进制位），不同位代表不同意思：

![image_1c9geiglj1ah31meo80ci8n1eli8f.png-29.5kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e97718ef01~tplv-t2oaga2asx-watermark.awebp)

|     名称     | 大小（bit） |                     描述                     |
| :----------: | :---------: | :------------------------------------------: |
|   预留位1    |      1      |                   没有使用                   |
|   预留位2    |      1      |                   没有使用                   |
| delete_mask  |      1      |             标记该记录是否被删除             |
| min_rec_mask |      1      | B+树的每层非叶子结点的最小记录都会添加该标记 |
|   n_owned    |      4      |           表示当前记录拥有的记录数           |
|   heap_no    |     13      |        表示当前记录在记录堆的位置信息        |
| record_type  |      3      |              表示当前记录的类型              |
| next_record  |     16      |           表示下一条记录的相对位置           |

> 记录的类型：
>
> - 0-普通记录
> - 1-B+树非叶子结点记录
> - 2-最小记录
> - 3-最大记录



#### 记录的真实数据

MySQL会为每个记录默认的添加一些列（也称为隐藏列）

|    列名     | 是否必须 | 占用空间 |         描述         |
| :---------: | :------: | :------: | :------------------: |
|  DB_ROW_ID  |    否    |    6B    | 行ID，记录的唯一标识 |
|  DB_TRX_ID  |    是    |    6B    |        事务ID        |
| DB_ROLL_PTR |    是    |    7B    |       回滚指针       |



##### 主键生成策略

1. 优先使用用户自定义主键作为主键
2. 如果用户没有定义主键，则选取一个Unique键作为主键
3. 如果用户没有定义Unique键，则生成一个隐藏的DB_ROW_ID列作为主键，其值会由存储引擎自动生成



##### CHAR(M)的存储格式

对于 ***CHAR(M)*** 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。

另外有一点还需要注意，变长字符集的`CHAR(M)`类型的列要求至少占用`M`个字节，而`VARCHAR(M)`却没有这个要求。比方说对于使用`utf8`字符集的`CHAR(10)`的列来说，该列存储的数据字节长度的范围是10～30个字节。即使我们向该列中存储一个空字符串也会占用`10`个字节，*这是怕将来更新该列的值的字节长度大于原有值的字节长度而小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片*。



### Redundant行格式

![image_1c9h896lcuqi16081qub1v8c12jkft.png-36.2kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e99a69ba3d~tplv-t2oaga2asx-watermark.awebp)

Redundant是MySQL5.0之前使用的一种行格式。



#### 字段长度偏移列表

1. Redundant行格式会把该条记录中所有列（包括隐藏列）的长度信息都按照逆序存储到字段长度偏移列表
2. 采用两个相邻数值的差值来计算各个列值的长度

> 某条记录的字段长度偏移列表为：
>
> ```
> 25 24 1A 17 13 0C 06
> ```
>
> 由于字段长度偏移列表是逆序存放，故最后一个长度为第一列长度，每个字段长度为：
>
> ```
> 第一列：06
> 第二列：0C-06=06
> 第三列：13-0C=07
> 以此类推：06 06 07 04 03 0A 01
> ```



#### 记录头信息

`Redundant`行格式的记录头信息占用`6`字节，`48`个二进制位，这些二进制位代表的意思如下：

|      名称       | 大小（bit） |                             描述                             |
| :-------------: | :---------: | :----------------------------------------------------------: |
|     预留位1     |      1      |                           没有使用                           |
|     预留位2     |      1      |                           没有使用                           |
|   delete_mask   |      1      |                     标记该记录是否被删除                     |
|  min_rec_mask   |      1      |         B+树的每层非叶子结点的最小记录都会添加该标记         |
|     n_owned     |      4      |                   表示当前记录拥有的记录数                   |
|     heap_no     |     13      |                表示当前记录在记录堆的位置信息                |
|     n_field     |     10      |                      表示记录中列的数量                      |
| 1byte_offs_flag |      1      | 标记字段长度偏移列表中每个列对应的偏移量是用1字节还是2字节表示的 |
|   next_record   |     16      |                   表示下一条记录的相对位置                   |



#### NULL值处理

列对应的偏移量值的第一个比特位作为是否为NULL的依据，所以一个字节中只有7位可以真正用来存储长度：2^7^-1=127，所以只要长度超过127位就要使用2个字节来存储。

- 如果存储NULL值的字段是定长类型的，则NULL值也将占用记录的真实数据部分，并将该字段对应的数据使用0x00字节填充
- 如果存储NULL值的字段是变长数据类型的，则不在记录的真实数据处占用任何存储空间



#### CHAR(M)列的存储格式

不管该列使用的字符集是什么，只要是使用`CHAR(M)`类型，占用的真实数据空间就是该字符集表示一个字符最多需要的字节数和`M`的乘积。由此可以看出来，使用`Redundant`行格式的`CHAR(M)`类型的列是不会产生碎片的。



#### 行溢出数据

##### VARCHAR(M)最多能存储的数据

对于VARCHAR(M)类型的列最多可以占用65535（2^16^-1）个字节。如果使用ascii字符集，一个字符就代表一个字节，VARCHAR(65535)不可用

这是因为`MySQL`对一条记录占用的最大存储空间是有限制的，除了`BLOB`或者`TEXT`类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过`65535`个字节。所以`MySQL`服务器建议我们把过长的存储类型改为`TEXT`或者`BLOB`的类型。这个`65535`个字节除了列本身的数据之外，还包括一些其他的数据（`storage overhead`），比如说我们为了存储一个`VARCHAR(M)`类型的列，其实需要占用3部分存储空间：

- 真实数据

- 真实数据占用字节的长度

- `NULL`值标识，如果该列有`NOT NULL`属性则可以没有这部分存储空间

  > - 如果该VARCHAR类型的列没有NOT NULL属性，那么最多只能存储65532个字节的数据，因为真实数据的长度可能占用2个字节，NULL值标识需要占用1个字节
  > - 如果该VARCHAR类型的列有NOT NULL属性，那么最多能存储65535-2=65533个字节的数据

如果不是使用ascii字符集，那`M`的最大取值取决于该字符集表示一个字符最多需要的字节数。在列的值允许为`NULL`的情况下，`gbk`字符集表示一个字符最多需要`2`个字节，那在该字符集下，`M`的最大取值就是`32766`（也就是：65532/2），也就是说最多能存储`32766`个字符；`utf8`字符集表示一个字符最多需要`3`个字节，那在该字符集下，`M`的最大取值就是`21844`，就是说最多能存储`21844`（也就是：65532/3）个字符。

> 注意以上情况都是在表中只有一个字段的前提下成立的，一个行中的所有列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节！



##### 记录中的数据太多产生的溢出

在`Compact`和`Redundant`行格式中，对于占用存储空间非常大的列，在`记录的真实数据`处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后`记录的真实数据`处用20个字节存储指向这些页的地址（当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页，如图所示：

![image_1d48e3imu1vcp5rsh8cg0b1o169.png-149kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e9aab47ea5~tplv-t2oaga2asx-watermark.awebp)

从图中可以看出来，对于`Compact`和`Redundant`行格式来说，如果某一列中的数据非常多的话，**在本记录的真实数据处只会存储该列的前`768`个字节的数据和一个指向其他页的地址**，然后把剩下的数据存放到其他页中，这个过程也叫做`行溢出`，存储超出`768`字节的那些页面也被称为`溢出页`。画一个简图就是这样：

![image_1conbskr7apj19ns1d194vs1buo1t.png-35.8kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e9a5d5637a~tplv-t2oaga2asx-watermark.awebp)

最后需要注意的是，不只是 ***VARCHAR(M)*** 类型的列，其他的 ***TEXT***、***BLOB*** 类型的列在存储数据非常多的时候也会发生`行溢出`。



##### 行溢出的临界点

`MySQL`规定一个页中至少存放两行记录：

- 每个页除了存放记录以外，还需要存储一些额外的信息，需要132B的空间
- 每个记录需要的额外信息是27B
  - 2个字节用于存储真实数据的长度
  - 1个字节用于存储列是否是NULL值
  - 5个字节大小的头信息
  - 6个字节的`row_id`列
  - 6个字节的`transaction_id`列
  - 7个字节的`roll_pointer`列

假设一个列中存储的数据字节数为n，并且表中只有一个列，MySQL规定如果该列满足`132+2×（27+n）< 16384→n < 8099`（一页为16KB=16384B）



### Dynamic、Compressed行格式

**`MySQL5.7`的默认行格式为`Dynamic`**，`Dynamic`和`Compressed`行格式与Compact行格式很相似，只不过在处理行溢出数据时有点不一样，它们不会再记录的真实数据处存储字段真实数据的前768个字节，而是把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址

![image_1conbtnmr1sg1hao1nf41pi1eb72a.png-29.9kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/12/169710e9b2c2b71e~tplv-t2oaga2asx-watermark.awebp)

`Compressed`行格式和`Dynamic`不同的一点是，`Compressed`行格式会采用压缩算法对页面进行压缩，以节省空间。



### Q&A

1. **记录的额外信息里的列表为什么要逆序存储？**



## InnoDB数据页

页是`InnoDB`管理存储空间的基本单位，一个页的大小一般是16KB。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/17/16f13ee1e2dfac7c~tplv-t2oaga2asx-watermark.awebp)

|        名称        |       中文名       | 占用空间大小 |         简单描述         |
| :----------------: | :----------------: | :----------: | :----------------------: |
|    File Header     |      文件头部      |     38B      |     页的一些通用信息     |
|    Page Header     |      页面头部      |     56B      |   数据页专有的一些信息   |
| Infimum + Supremum | 最小记录和最大记录 |     26B      |     两个虚拟的行记录     |
|    User Records    |      用户记录      |      -       |   实际存储的行记录内容   |
|     Free Space     |      空闲空间      |      -       |    页中尚未使用的空间    |
|   Page Directory   |      页面目录      |      -       | 页中的某些记录的相对位置 |
|    File Trailer    |      文件尾部      |      8B      |      校验页是否完整      |



### 记录在页中的存储

在页刚生成的时候是没有`User Records`这一部分的，每当插入一条记录时，都会从`Free Space`部分申请一个记录大小的空间划分到`User Records`部分。当`Free Space`完全被`User Records`部分替代后，就意味着这个页已经使用完了，如果还有新的记录插入的话就要去申请新的页了。



![image-20211113103957044](https://tva1.sinaimg.cn/large/008i3skNgy1gwdboq28z0j319o066gmm.jpg)

- `delete_mask`

  标记着当前记录是否被删除。`MySQL`并不会真正的删除记录，而只是把对应记录的删除标志位设置为1。这是因为如果把被删除的记录立即从磁盘上移除，把之后的记录进行重新排列需要消耗性能，所以只是打一个删除标记，所有被删除掉的记录会组成一个**垃圾链表**，在这个链表中的记录占用的空间称之为**可重用空间**，之后如果有新记录插入到表中时可能会覆盖这些记录占用的空间。

- `min_rec_mask`

- `n_owned`

- `heap_no`

  表示当前记录在本页中的位置，序号从2开始。每个页中有两个自动插入的伪记录/虚拟记录，序号分别为0和1，分别代表最小和最大记录。

  ![image_1c9ra45eam7t1mil9o1h3ucqdhv.png-50.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c100ff0ccc2~tplv-t2oaga2asx-watermark.awebp)

- `record_type`

  - 0-普通记录-即自己插入的记录
  - 1-B+树非叶子结点记录
  - 2-最小记录
  - 3-最大记录

- `next_record`

  表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。记录按照主键从小到大的顺序形成了一个单链表

  > 这个下一条记录指的是按照主键值从小到大的顺序的下一条记录，而不是插入顺序的下一条记录
  >
  > `Infimum`记录的下一条记录是本页中主键值最小的用户记录，本页中主键值最大的用户记录的下一条记录就是`Supremum`记录

![image_1cot1r96210ph1jng1td41ouj85c13.png-120.5kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c1084c440b4~tplv-t2oaga2asx-watermark.awebp)		

​		如果删除第2条记录，相当于把其从记录链表中移除（但是其仍然存储在磁盘上)

![image_1cul8slbp1om0p31b3u1be11gco9.png-119.6kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c108ee1da43~tplv-t2oaga2asx-watermark.awebp)

​		注意删除一条记录后最大记录的`n_owned`减一，其他记录的`n_owned`仍然为0



### Page Directory（页目录）

为了迅速的根据主键值查找记录，`InnoDB`实现了页目录：

1. 把所有未删除的记录（包括`Infimum`记录和`Supremum`记录）划分为几个组
2. 每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的`n_owned`属性表示该记录拥有多少条记录，也就是组内共有几条记录
3. 将每个组的最后一条记录的地址偏移量单独提出来按顺序存储到靠近页的尾部的地方，即`Page Directory`（页目录）。页目录中的这些地址偏移量被称为槽`Slot`

![image_1couapvdmb5mvm1i0l5m0vcb2a.png-128.2kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c10c57164a6~tplv-t2oaga2asx-watermark.awebp)

如上图，对于6条记录，会被分为两组：一组只有一个最小记录，另一组是剩余的5条记录

![image_1couate3jr19gc18gl1cva1fcg34.png-100.8kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c10f2e61ad5~tplv-t2oaga2asx-watermark.awebp)



分组步骤：

1. 初始情况下一个数据页内只有最小记录和最大记录两条记录，它们分属于两个分组。

   > 对于最小记录所在的分组只能有 ***1*** 条记录
   >
   > 最大记录所在的分组拥有的记录条数只能在 ***1~8*** 条之间
   >
   > 剩下的分组中记录的条数范围只能在是 ***4~8*** 条之间。

2. 之后每插入一条记录，都会从页目录中找到**主键值比本记录的主键值大并且差值最小**的槽，然后把该槽对应的记录的`n_owned`值加1，表示本组内又添加了一条记录，直到该组中的**`n_owned=8`**

3. 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组。

![image_1d6g64af2sgj1816ktl1q22dehp.png-189.1kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c10e3449897~tplv-t2oaga2asx-watermark.awebp)

因为各个槽代表的记录的主键值都是从小到大排序的，所以可以使用**二分法**来进行快速查找。

所以在一个数据页中查找指定主键值的记录的过程分为两步：

1. 通过二分法确定该记录所在的槽，并找到该槽所在分组中主键值最小的那条记录。
2. 通过记录的`next_record`属性遍历该槽所在的组中的各个记录。（通过上一个槽的最大记录的`next_record`可以很方便的找到目标槽的第一个记录）



### Page Header（页面头部）

占用固定的56个字节，专门存储数据页的各种状态信息

![image-20211113114412677](https://tva1.sinaimg.cn/large/008i3skNgy1gwddjjvqt5j30iq0mv40i.jpg)

- `PAGE_DIRECTION`

  假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左边。用来表示最后一条记录插入方向的状态就是`PAGE_DIRECTION`。

- `PAGE_N_DIRECTION`

  假设连续几次插入新记录的方向都是一致的，`InnoDB`会把沿着同一个方向插入记录的条数记下来，这个条数就用`PAGE_N_DIRECTION`这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。



### File Header

各种不同类型的页都会以File Header作为第一个组成部分，它描述了一些针对各种页都通用的一些信息，占用固定的38个字节

![image-20211113114932264](https://tva1.sinaimg.cn/large/008i3skNgy1gwddp3caeaj30if0euq3u.jpg)

- `FIL_PAGE_SPACE_OR_CHKSUM`

  这个代表当前页面的校验和（checksum）。校验和：由长字节串计算而成的较短的字节串，用于比较，省去了直接比较长字节串的时间损耗

- `FIL_PAGE_OFFSET`

  每一个`页`都有一个单独的页号，`InnoDB`通过页号来可以**唯一定位**一个`页`。

- `FIL_PAGE_TYPE`

  这个代表当前`页`的类型，我们前边说过，`InnoDB`为了不同的目的而把页分为不同的类型，我们上边介绍的其实都是存储记录的`数据页`，其实还有很多别的类型的页，具体如下表：

  ![image-20211113115045158](https://tva1.sinaimg.cn/large/008i3skNgy1gwddqcqav9j30eu0gimy9.jpg)

- `FIL_PAGE_PREV`和`FIL_PAGE_NEXT`

  `InnoDB`都是以页为单位存放数据的，当一张表中有很多记录时，`InnoDB`可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的页中存储的话需要把这些页关联起来，`FIL_PAGE_PREV`和`FIL_PAGE_NEXT`就分别代表本页的上一个和下一个页的**页号**。这样通过建立一个**双向链表**把许许多多的页就都串联起来了，而无需这些页在物理上真正连着。需要注意的是，并不是所有类型的页都有上一个和下一个页的属性，不过我们`数据页`（也就是类型为`FIL_PAGE_INDEX`的页）是有这两个属性的，所以所有的数据页其实是一个双链表。就像这样：

  ![image_1ca00fhg418pl1f1a1iav1uo3aou9.png-90.9kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/8/16a95c10eb9d61ce~tplv-t2oaga2asx-watermark.awebp)



### File Trailer

`File Trailer`也是所有类型的页都通用的。为了避免没有完全同步的情况，需要检测每一个页是否完整，`InnoDB`在每个页的尾部都添加了一个8字节的`File Trailer`部分，可以分为2个小部分：

- 前4个字节为页的校验和

  与`File Header`中的校验和相对应。每当一个页面在内存中被修改了，在同步之前就要把`File Header`的校验和算出来，因为`File Header`在页面的最前边，所以校验和会被首先同步到磁盘。当完全写完时，校验和也会被写到页的尾部，如果完全同步成功，页首和页尾的校验和应该是一致的。

  如果二者不一致，就意味着同步出错，`File Header`中的校验和代表已经修改过的页，`File Trailer`中的校验和代表修改前的页

- 后4个字节为页面最后被修改时对应的日志序列位置（LSN）



## B+树索引

在没有索引的情况下，如果表中的记录存放在多个页中，只能从第一个页沿着双向链表逐个向下遍历寻找记录所在的页。

另外，如果不是以主键为搜索条件进行搜索，由于数据页中没有对非主键列建立页目录，这也就意味着无法通过二分法快速定位到记录所在的槽，只能从最小记录开始沿着单向链表依次遍历寻找记录。

索引就是为了提高以上情况的搜索的速度。



### 简单的索引

- 下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。这也就意味着当插入记录时可能会出现记录在页之间的移动，这个过程可以称为页分裂
- 给所有页建立一个目录，这个目录实际上就是索引。由于数据页的编号可能并不是连续的，它们在物理存储上也可能不相邻，所以要为页建立目录，每个页对应一个目录项，每个目录项包括两个部分：
  - 页的用户记录中最小的主键值
  - 页号

![image_1caba0afo11fa1cli1nu070m16bg1j.png-119.1kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/4/9/16a01bd282d6b9b9~tplv-t2oaga2asx-watermark.awebp)



### InnoDB中的索引

以上的简单索引方案存在几个问题：

- `InnoDB`使用页来作为管理存储空间的基本单位，也就是最多能保证`16KB`的连续存储空间。而随着表中记录数量的增多，目录项也会增多，之后会需要非常大的连续的存储空间才能把所有的目录项都放下。
- 为了保证下一个数据页中的主键值一定会大于上一个页中用户记录的主键值，时常需要对用户记录进行移动。

`InnoDB`复用存储用户记录的数据页来存储目录项，并通过记录头信息里的`record_type=1`来表示这是一条目录项记录

|              |                    目录项记录                     |     普通用户记录     |
| :----------: | :-----------------------------------------------: | :------------------: |
| record_type  |                         1                         |          0           |
|      列      |             只有最小主键值和页的编号              | 用户自己定义和隐藏列 |
| min_rec_mask | 存储目录项记录的页中的主键值最小的目录项记录的为1 |          0           |

存储目录项的页实际上也是一个普通的数据页，前面提及的二分法查找在查找目录项上也是适用的。

![image_1cacabsrh17a5133q1otf725gi92q.png-135.7kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/4/9/16a01bd29ebc7a4c~tplv-t2oaga2asx-watermark.awebp)



**加入目录项很多，需要多个页存储，那么怎么根据主键快速定位到存储目标目录项的页呢？**

为这些存储目录项记录的页再生成一个更高级的目录，像一个多级目录一样，大目录里嵌套着小目录，小目录里面才真正存储着目录项记录。随着表中记录的增加，目录的层级会继续增加

![image_1cacafpso19vpkik1j5rtrd17cm3a.png-158.1kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/4/9/16a01bd2a6c7a65f~tplv-t2oaga2asx-watermark.awebp)

这个多级目录实际上就是一个B+树，在叶子结点存储的才是真正的数据。假设一个数据页中可以存放M条记录，那么一个k层的B+树就可以存放M^k^条记录。**一般情况下，使用的B+树都不会超过4层**，这也就意味着通过主键值去查找某条记录最多只需要做4个页面内的查找（查找3个目录项页和一个用户记录页），而在页内可以使用二分法快速定位记录。



#### 聚簇索引

我们上边介绍的`B+`树本身就是一个目录，或者说本身就是一个索引。它有两个特点：

1. 使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义：

   - 页内的记录是按照主键的大小顺序排成一个**单向链表**。
   - 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个**双向链表**。
   - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个**双向链表**。

2. `B+`树的叶子节点存储的是完整的用户记录。

   所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。

我们把具有这两种特性的`B+`树称为`聚簇索引`，所有完整的用户记录都存放在这个`聚簇索引`的叶子节点处。`InnoDB`存储引擎会自动的为我们创建聚簇索引。另外有趣的一点是，在`InnoDB`存储引擎中，`聚簇索引`就是数据的存储方式（所有的用户记录都存储在了`叶子节点`），也就是所谓的**索引即数据，数据即索引**。



#### 二级索引

聚簇索引只能在搜索条件是主键时才能发挥作用，因为B+树中的数据都是按照主键进行排序的。用户如果根据非主键列搜索想走索引时，就需要手动为这个列添加索引，此时`InnoDB`会建立一个根据该列排序的B+树。

但是，**二级索引中的叶子结点存储的并不是完整的用户记录，而只是添加索引的列+主键这两个列的值**。所以如果想要根据非主键列为搜索条件搜索时，需要先通过该列对应的B+树找到叶子结点，从叶子节点中获取主键值，再到聚簇索引中寻找真正的用户记录，这个过程称为`回表`。

> 为什么二级索引的叶子结点不存储完整的用户记录？
>
> 因为如果每个二级索引都存储完整的用户记录，那么存储空间中很大一部分都是重复的数据，所以为了节省存储空间，二级索引的叶子结点只存储索引列+主键值



#### 联合索引

同时为多个列建立索引，即根据多个列的值来进行排序，这种索引就称为联合索引。

假设为c2、c3列建立联合索引，那么会先根据c2的值进行排序，如果c2相同，则根据c3排序。

联合索引本质上也是一个二级索引，只是为多个列建立联合索引只会产生一棵B+树，为多个列建立二级索引会产生多棵树



#### 注意事项

##### 根页面位置不变

根节点页面的位置是从始至终保持不变的，每当InnoDB需要用到索引时都会从固定的地方取出根节点的页号从而访问索引。

B+树的形成过程：

1. 一个表最开始创建时，InnoDB就会为这个表创建一个聚簇索引，并为这个索引创建一个根节点页面，页面内没有任何记录
2. 之后插入用户记录，一开始会直接把用户记录存储到根节点页面中
3. 当根节点页面中的可用空间用完后，再插入记录时会将根节点中所有的记录赋值到一个新分配的页，然后对这个新页进行页分裂操作得到另一个新页，根节点升级为存储目录项记录的页。



##### 内节点中目录项记录的唯一性

聚簇索引中目录项记录的内容是`索引列+页号`，但是这个内容对二级索引来说有些不严谨，因为非主键列是不唯一的，假如存在索引列相同的情况，这时候应该如何排序？

为了解决这个问题，对于二级索引的内节点的目录项记录的内容实际上由三部分组成：`索引列+主键值+页号`



##### 一个页面最少存储两条记录



##### 主键的插入顺序

建议让主键具有`AUTO_INCREMENT`，让存储引擎自己为表生成主键，保证主键随着插入顺序递增。这是因为如果主键时依次增大的话，在修改聚簇索引时只需要在最大记录后插入就行了（如果那个数据页满了就到下一个数据页继续插）。但是如果插入的主键值忽大忽小，就需要对聚簇索引进行页分裂和记录移位，造成性能损耗。



### MyISAM中的索引

`MyISAM`中的索引虽然也使用树形结构，但是将索引和数据分开存储：

- 将表中的记录**按照记录的插入顺序**单独存储在一个文件中，称之为`数据文件`。这个文件并不划分为若干个数据页，可以通过行号快速访问到一条记录

- 索引信息另外存储到索引文件中。`MyISAM`会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是`主键值+行号`的组合。

  所以`MyISAM`中需要一次`回表`操作，从索引中获取到行号后再到数据文件中获取数据，相当于二级索引



### 创建和删除索引

```sql
// 创建表时指定需要建立索引的单个列或者建立联合索引的多个列
CREATE TALBE 表名 (
    各种列的信息 ··· , 
    [KEY|INDEX] 索引名 (需要被索引的单个列或多个列)
)

// 修改表结构时添加索引
ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列);

// 修改表结构时删除索引
ALTER TABLE 表名 DROP [INDEX|KEY] 索引名;
```



### 索引的代价

- 空间上

  一个页会默认占用16KB的存储空间，一棵B+树由大量的数据页节点组成，会占用很大的一片存储空间。

- 时间上

  索引虽然能大幅提升查询的效率，但是会降低增删改操作的效率。这是因为B+树索引每层节点是按照索引值从小到大的顺序而组成双向链表的，内节点的记录也是根据索引值从小到大的顺序组成单向链表，每次对表中的数据进行增删改操作时，都需要修改B+树索引，可能会引起记录移位、页面分裂、页面回收等操作。



### 适用条件

假设有一个索引

```sql
idx_name_birthday_phone_number (name, birthday, phone_number)
```



#### 全值匹配

搜索条件中的列和索引列一致，就称为全值匹配。

```sql
SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone_number = '15123983239';
```

`WHERE`子句中的几个搜索条件的顺序对查询结果没有影响，因为`MySQL`有一个查询优化器，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定搜索条件的额使用顺序。



#### 匹配左边的列

搜索语句中没有包含全部联合索引中的列，只包含左边的

```sql
SELECT * FROM person_info WHERE name = 'Ashburn';
```

但是，如果搜索语句中只包含了右边的列（即跳过了联合索引中前面的列）时，就不会用到B+树索引

```sql
SELECT * FROM person_info WHERE birthday = '1990-09-27';
```

这是因为B+树的数据页和记录的排序是先根据左边的列排序的，在以上例子中排序优先级就是`name→birthday→phone_number`，只有在`name`值相同的情况下才会使用`birthday`排序，也就是说`name`列的值不同的记录中`birthday`的值是无序的，自然就无法根据有序的B+树索引查询了。



#### 匹配列前缀

如果索引列是字符串类型的，字符串排序一般的比较规则是逐个比较字符的大小，即从第一个字符比较，所以字符串的前n个字符，也就是前缀都是排好序的，所以对于字符串类型的索引来说只匹配前缀也是可以走索引的

```sql
SELECT * FROM person_info WHERE name LIKE 'As%';
```

但是，与上面不能匹配右边的列同理，如果只给出后缀或者中间的某个字符串，就无法走索引了

```sql
SELECT * FROM person_info WHERE name LIKE '%As%';
```



#### 匹配范围值

联合索引中，对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找时才能用到索引。

```sql
SELECT * FROM person_info WHERE name > 'Asa' AND name < 'Barlow' AND birthday > '1980-01-01';
```

满足`name>‘Asa’`的多个记录的name值是不一样的，但是只有在`name`值相同的情况下才能用`birthday`列的值进行排序，所以对`birthday`列进行范围查找是用不到索引的



#### 精确匹配左边的列并范围匹配右边的列

如果左边的列是精确匹配，右边的列是范围匹配，那么右边的列可以走索引



#### 用于排序

因为B+树索引本身就是有序的，所以其实从索引中得到的数据就是已经排序好的。

对于`联合索引`有个问题需要注意，`ORDER BY`的子句后边的列的顺序也必须**按照索引列的顺序给出**，否则就走不了索引（B+树索引排序时的顺序性）



#### 用于分组

```sql
SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number
```

这个查询语句相当于做了3次分组操作：

1. 先把记录按照`name`值进行分组，所有`name`值相同的记录划分为一组。
2. 将每个`name`值相同的分组里的记录再按照`birthday`的值进行分组，将`birthday`值相同的记录放到一个小分组里，所以看起来就像在一个大分组里又化分了好多小分组。
3. 再将上一步中产生的小分组按照`phone_number`的值分成更小的分组，所以整体上看起来就像是先把记录分成一个大分组，然后把`大分组`分成若干个`小分组`，然后把若干个`小分组`再细分成更多的`小小分组`。

分组列的顺序也需要和索引列的顺序一致，可以只使用索引列左边的列进行分组……条件和原因都跟匹配、排序的一样



### 不适用条件

#### ASC、DESC混用

联合索引要求各个排序列的排序顺序是一致的，如果不一致的话会导致从索引中取数据的算法的复杂度大幅上升



#### 排序列包含非同一个索引的列



#### 排序列使用了复杂的表达式

要想使用索引进行排序操作，必须保证索引列是**以单独列的形式出现**，而不是修饰过的形式

假设表中有一个整数列`my_col`，我们为这个列建立了索引。下边的两个`WHERE`子句虽然语义是一致的，但是在效率上却有差别：

1. `WHERE my_col * 2 < 4`
2. `WHERE my_col < 4/2`

第1个`WHERE`子句中`my_col`列并不是以单独列的形式出现的，而是以`my_col * 2`这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于`4`，所以这种情况下是使用不到为`my_col`列建立的`B+`树索引的。而第2个`WHERE`子句中`my_col`列并是以单独列的形式出现的，这样的情况可以直接使用`B+`树索引。

所以结论就是：如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。



### 回表的代价

二级索引中获取到的记录的主键的值可能并不连续，而在聚簇索引中是根据主键的值顺序排序的。所以根据这些并不连续的主键到聚簇索引中访问完整的用户记录可能分布在不同的数据页中，这样想要读取完整的结果可能需要访问更多的数据页，这种读取方式称为随机I/O

一般情况下，顺序I/O比随机I/O的性能高很多，所以从二级索引中取用户记录很快，但是回表可能会慢一点。需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。

查询优化器则会事先对表中的记录统计，然后利用这些统计数据来计算需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描。所以使用添加了`LIMIT 10`的查询更容易让查询优化器采用二级索引+回表的方式进行查询。



### 覆盖索引

> 不鼓励使用`SELECT *`的原因

为了彻底告别`回表`操作带来的性能损耗，我们建议：最好在查询列表里只包含索引列。因为只需要索引列的值，这些都包含在二级索引内，所以二级索引得到结果后就不再需要回表到聚簇索引中再查找记录的剩余列，这种只需要用到索引的查询方式称为`索引覆盖`。排序操作也优先使用`覆盖索引`的方式进行查询



### 如何挑选索引

1. 只为用于搜索、排序或分组的列创建索引

2. 考虑列的基数

   列的基数指的是某一列中不重复数据的个数。在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。这个`列的基数`指标非常重要，直接影响我们是否能有效的利用索引。最好为那些列的基数大的列建立索引。

3. 索引列的类型尽量小

   因为二级索引中会存放索引列的值，这是一个重复数据的值。索引列的类型越小意味着这部分重复数据的值占用的存储空间越小，也就意味着节省更多的存储空间和更高效的`I/O`。

4. 索引字符串值的前缀

   索引列的字符串前缀其实也是排好序的，所以索引的设计者提出了个方案—— 只对字符串的前几个字符进行索引也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在`B+`树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题。

   > 对于索引列前缀，因为二级索引中不包含完整的列信息，所以无法对前缀相同，后边的字符不同的记录进行排序，也就是使用索引列前缀的方式无法支持使用索引排序，只好乖乖的用文件排序喽。



## 数据目录

`MySQL`服务器程序在启动时会到文件系统的某个目录下加载一些文件，之后在运行过程中产生的数据页都会存储到这个目录下的某些文件中，这个目录就称为数据目录。



### 结构

#### 数据库在文件系统中的表示

当使用`CREATE DATABASE <database name>`语句创建数据库时，MySQL会做以下事情：

1. 在数据目录下创建一个和数据库名同名的子目录（文件夹）。所以每个数据库都对应着数据目录下的一个文件夹
2. 在这个子目录下创建一个名为`db.opt`的文件，这个文件中包含了该数据库的各种属性



#### 表在文件系统中的表示

**每个表信息=表结构+表数据**

**表结构的存储**

`InnoDB`和`MyISAM`两种存储引擎都在数据目录下对应的数据库子目录下创建了一个专门用于**描述表结构**的文件：`表名.frm`，这个文件是以二进制格式存储的，直接打开的话是乱码的。



##### InnoDB中表数据的存储

`InnoDB`是以页为基本单位来管理存储空间的，一张表可能会对应多个页。为了更好地管理这些页，`InnoDB`提出了一个表空间（文件空间）的概念，这个表空间是一个抽象的概念，它可以对应文件系统上一个或多个真实文件（不同表空间对应的文件数量可能不同）。每一个表空间可以被划分为很多个页，表数据就存放在某个表空间下的某些页里。



###### 系统表空间

默认情况下，`InnoDB`会在数据目录下创建一个名为`ibdata1`、大小为`12M`的文件，这个文件就是对应的系统表空间在文件系统上的表示，它是一个自扩展文件，会自动增加文件大小。



###### 独立表空间

在`MySQL5.6.6`以及之后的版本中，`InnoDB`不会默认的把各个表的数据存储到系统表空间中，而是为每一个表建立一个独立表空间。使用独立表空间来存储表数据的话，会在该表所属数据库对应的子目录下创建一个文件`表名.ibd`



###### 其他类型的表空间



##### MyISAM中表数据的存储

与`InnoDB`中的索引也是数据不同，在`MyISAM`中的索引全部都是二级索引，该存储引擎的数据和索引是分开存放的，所以在文件系统中也分为数据文件和索引文件。

`MyISAM`没有表空间，表数据都存放到对应的数据库子目录下，对于一张表，`MyISAM`会为其创建以下三个文件：

```
表结构：表名.frm
表数据：表名.MYD
表索引：表名.MYI
```



#### 视图在文件系统中的表示

我们知道`MySQL`中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储`视图`的时候是**不需要存储真实的数据**的，只需要把它的结构存储起来就行了。和`表`一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下边，只会存储一个`视图名.frm`的文件。



#### 其他的文件

除了我们上边说的这些用户自己存储的数据以外，`数据目录`下还包括为了更好运行程序的一些额外文件，主要包括这几种类型的文件：

- 服务器进程文件。

  我们知道每运行一个`MySQL`服务器程序，都意味着启动一个进程。`MySQL`服务器会把自己的进程ID写入到一个文件中。

- 服务器日志文件。

  在服务器运行过程中，会产生各种各样的日志，比如常规的查询日志、错误日志、二进制日志、redo日志吧啦吧啦各种日志，这些日志各有各的用途，我们之后会重点唠叨各种日志的用途，现在先了解一下就可以了。

- 默认/自动生成的SSL和RSA证书和密钥文件。

  主要是为了客户端和服务器安全通信而创建的一些文件



### 文件系统对数据库的影响

- 数据库名称和表名称不得超过文件系统所允许的最大长度

- 特殊字符映射成`@+编码值`

  为了避免因为数据库名和表名出现某些特殊字符而造成文件系统不支持的情况，`MySQL`会把数据库名和表名中所有除数字和拉丁字母以外的所有字符在文件名里都映射成 `@+编码值`的形式作为文件名

- 文件长度受文件系统最大长度限制



### 系统数据库

- mysql

  这个数据库贼核心，它存储了`MySQL`的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。

- information_schema

  这个数据库保存着`MySQL`服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。

- performance_schema

  这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对`MySQL`服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。

- sys

  这个数据库主要是通过视图的形式把`information_schema`和`performance_schema`结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。



## InnoDB表空间

### 页面通用部分

任何类型的页面都有下面这种通用的结构：

![image_1crjupisqne61uer17ikh6l1v8k9.png-44.9kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f33c338667~tplv-t2oaga2asx-watermark.awebp)

在`File Header`中有一个4B的部分为`FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID`，代表页属于哪个表空间。如果按照页的默认大小16KB来算，那么一个表空间最多可以拥有2^4×8=32^个页，最多支持16KB×2^32^=64TB的数据。



### 独立表空间结构

#### 区（extent）

一个表空间中可以有2^32^个页，为了方便管理，以**连续的64个页为一个区**（对于16KB的页来说，一个区默认占用1MB空间大小）。不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，**每256个区被划分成一组**。

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f33c4a1c3a~tplv-t2oaga2asx-watermark.awebp" alt="image_1cri1nutcorp5ghf5c7vqagt1j.png-71.4kB" style="zoom:67%;" />

这些组的头几个页面的类型都是类似的，就像这样：

![image_1crjo0hl4q8u1dkdofe187b10fa9.png-105.2kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f33df9307a~tplv-t2oaga2asx-watermark.awebp)

- 第一个组最开始的3个页面的类型是固定的，也就是说extent0这个区最开始的3个页面的类型是固定的，分别是：

  - `FSP_HDR`类型

    这个类型的页面是用来**登记整个表空间的一些整体属性以及本组所有的`区`**，也就是`extent 0` ~ `extent 255`这256个区的属性，稍后详细唠叨。需要注意的一点是，**整个表空间只有一个`FSP_HDR`类型的页面**。

  - `IBUF_BITMAP`类型

    这个类型的页面是存储本组所有的区的所有页面关于`INSERT BUFFER`的信息。

  - `INODE`类型

    这个类型的页面存储了许多称为`INODE`的数据结构

- 其余各组最开始的2个页面的类型是固定的，分别是：

  - `XDES`类型

    全称是`extent descriptor`，**用来登记本组256个区的属性**

    > 上边介绍的`FSP_HDR`类型的页面其实和`XDES`类型的页面的作用类似，只不过`FSP_HDR`类型的页面还会额外存储一些表空间的属性。

  - `IBUF_BITMAP`类型



**为什么要引入区的概念？**

考虑一下下边这个场景：

我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的`B+`树的节点中插入数据。而`B+`树的每一层中的页都会形成一个双向链表，如果是以`页`为单位来分配存储空间的话，**双向链表相邻的两个页之间的物理位置可能离得非常远**。

如果链表中相邻的两个页物理位置离得非常远，就是所谓的`随机I/O`。再一次强调，磁盘的速度和内存的速度差了好几个数量级，`随机I/O`是非常慢的，所以我们应该尽量**让链表中相邻的页的物理位置也相邻**，这样进行范围查询的时候才可以使用所谓的`顺序I/O`。

所以，才引入了区的概念，一个区就是在物理位置上连续的64个页。当表中数据量大的时候，为某个索引非配空间的时候就不再按照页为单位分配，而是按照区为单位分配，以消除大量的`随机I/O`。



#### 段（segment）

在使用B+树索引的范围查询中，只需要定位到最左边和最右边的记录，然后沿着双向链表扫描就可以了。注意，这里的扫描是对叶子节点中的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页面放到申请到的区中的话，进行范围扫描的效果就大打折扣了。所以`InnoDB`对B+树的叶子节点和非叶子节点进行了区别对待，它们各自有自己独有的区。存放叶子节点的区的集合就算是一个`段`（`segment`），存放非叶子节点的区的集合也算是一个`段`。也就是说**==一个索引会生成2个段，一个叶子节点段，一个非叶子节点段==**。



**为段分配空间的策略**

默认情况下一个使用`InnoDB`存储引擎的表只有一个聚簇索引，一个索引会生成2个段，而段是以区为单位申请存储空间的，一个区默认占用1M存储空间。也就是说，默认情况下无论表存储的数据有多少，都需要2M的存储空间，这对于存储记录比较少的表来说十分浪费。

这个问题的症结在于到现在为止我们介绍的区都是非常`纯粹`的，也就是一个区被整个分配给某一个段，或者说区中的所有页面都是为了存储同一个段的数据而存在的，即使段的数据填不满区中所有的页面，那余下的页面也不能挪作他用。

因此`InnoDB`提出了碎片（`fragment`）区的概念，也就是在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的。**碎片区直属于表空间，并不属于任何一个段**。所以此后为某个段分配存储空间的策略是这样的：

1. 在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。
2. 当某个段已经占用了`32个`碎片区页面之后，就会以完整的区为单位来分配存储空间。

所以现在段不能仅定义为是某些区的集合，更精确的应该是**某些零散的页面以及一些完整的区的集合**。



#### 区的分类

- 空闲的区`FREE`：现在还没有用到这个区中的任何页面。
- 有剩余空间的碎片区`FREE_FRAG`：表示碎片区中还有可用的页面。
- 没有剩余空间的碎片区`FULL_FRAG`：表示碎片区中的所有页面都被使用，没有空闲页面。

> 以上三个状态的区都是独立的，直属于表空间

- 附属于某个段的区`FSEG`：每一个索引都可以分为叶子节点段和非叶子节点段，除此之外InnoDB还会另外定义一些特殊作用的段，在这些段中的数据量很大时将使用区来作为基本的分配单位。



#### XDES Entry结构

`InnoDB`有一个`XDES Entry`的结构便于管理区，每一个区都对应着一个`XDES Entry`结构，这个结构记录了对应的区的一些属性。

![image_1crre79uq9971bsdj9s1i0j11en8a.png-96.2kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f343654829~tplv-t2oaga2asx-watermark.awebp)

- `Segment ID`（8字节）

  每一个段都有一个唯一的编号，用ID表示，此处的`Segment ID`字段表示就是该区所在的段。当然前提是该区已经被分配给某个段了，不然的话该字段的值没啥意义。

- `List Node`（12字节）

  这个部分可以将若干个XDES Entry结构串联成一个链表：

  ![image_1crre8tlh1vmqtfipk663l173q97.png-69.1kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f3444b1515~tplv-t2oaga2asx-watermark.awebp)

  如果我们想定位表空间内的某一个位置的话，只需指定页号以及该位置在指定页号中的页内偏移量即可

- `State`（4字节）

  这个字段表明区的状态。可选的值就是我们前边说过的那4个，分别是：`FREE`、`FREE_FRAG`、`FULL_FRAG`和`FSEG`

- `Page State Bitmap`（16字节）

  这个部分共占用16个字节，也就是128个比特位。我们说一个区默认有64个页，这128个比特位被划分为64个部分，每个部分2个比特位，对应区中的一个页。这两个比特位的第一个位表示对应的页是否是空闲的，第二个比特位还没有用。



##### XDES Entry链表

向段中插入数据的过程：

当段中数据较少的时候，首先会查看表空间中是否有状态为`FREE_FRAG`的区，如果还有有空闲空间的碎片区，就从该区中取一些零散的页把数据插进去；否则到表空间下申请一个状态为`FREE`的空闲区，并把该区的状态变为`FREE_FRAG`，然后从该新申请的区中取一些零散的页把数据插进去。之后不同的段使用零散页的时候都会从该区中取，直到该区中没有空闲空间，然后该区的状态就变成了`FULL_FRAG`。

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1gwg30dsldbj30u0106q7f.jpg" alt="image-20211115195627097" style="zoom:67%;" />

表空间的大小是可以不断增大的，表空间越大，区的数量也越大。为了方便查找对应状态的区，可以把`FREE`、`FREE_FRAG`、`FULL_FRAG`这三个状态的区分开，利用`List Node`中的指针把各个区的`XDES Entry`结构连接成不同状态的区双向链表，这样需要哪个状态的区就到对应的链表中取就可以了。



**当段中数据已经占满了32个零散的页后，就直接申请完整的区来插入数据。**

每个段中的区对应的`XDES Entry`结构都建立了三个链表：

- `FREE`链表：同一个段中，所有页面都是空闲的区对应的`XDES Entry`结构会被加入到这个链表。**注意和直属于表空间的`FREE`链表区别开了，此处的`FREE`链表是附属于某个段的。**
- `NOT_FULL`链表：同一个段中，仍有空闲空间的区对应的`XDES Entry`结构会被加入到这个链表。
- `FULL`链表：同一个段中，已经没有空闲空间的区对应的`XDES Entry`结构会被加入到这个链表。



##### 链表基节点

上面介绍的每个链表都对应着一个`List Base Node`结构，这个结构中包含了链表的头结点和尾结点的指针以及这个链表中包含了多少节点的信息

![image_1crrehf6i1jsq1j5cubj1mdoh77a4.png-81.6kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f388927e1c~tplv-t2oaga2asx-watermark.awebp)

- `List Length`表明该链表一共有多少节点
- `First Node Page Number`和`First Node Offset`表明该链表的头节点在表空间中的位置。
- `Last Node Page Number`和`Last Node Offset`表明该链表的尾节点在表空间中的位置。

这个结构在表空间中的位置是固定的，所以`MySQL`可以很方便的找到`XDES Entry`链表



#### 段的结构

段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页面以及一些完整的区组成。像每个区都有对应的`XDES Entry`来记录这个区中的属性一样，`InnoDB`为每个段都定义了一个`INODE Entry`结构来记录一下段中的属性。

![image_1crrju0cnji91a2fhv91ijb15hgb1.png-111.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f4087c4a56~tplv-t2oaga2asx-watermark.awebp)

- `Segment ID`

  就是指这个`INODE Entry`结构对应的段的编号（ID）。

- `NOT_FULL_N_USED`

  这个字段指的是在`NOT_FULL`链表中已经使用了多少个页面。

- 3个`List Base Node`

  分别为段的`FREE`链表、`NOT_FULL`链表、`FULL`链表定义了`List Base Node`，这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的`List Base Node`。

- `Magic Number`：

  这个值是用来标记这个`INODE Entry`是否已经被初始化了（初始化的意思就是把各个字段的值都填进去了）。如果这个数字是`97937874`，表明该`INODE Entry`已经初始化，否则没有被初始化。

- `Fragment Array Entry`

  我们前边强调过无数次段是一些零散页面和一些完整的区的集合，每个`Fragment Array Entry`结构都对应着一个零散的页面，这个结构一共4个字节，表示一个零散页面的页号。

![image-20211115203658564](https://tva1.sinaimg.cn/large/008i3skNgy1gwg46inhtnj316f0u0n1w.jpg)



#### 页的类型

##### FSP_HDR

**表空间中的第一个组的第一个页面的类型是`FSP_HDR`，它存储了表空间的整体属性以及第一个组内256个区的对应的`XDES Entry`结构**

![image_1crmfvigk938c8h1hahglr15329.png-146.8kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f4733af475~tplv-t2oaga2asx-watermark.awebp)

![image-20211115205201877](https://tva1.sinaimg.cn/large/008i3skNgy1gwg4m6873oj30fa0ae3yz.jpg)



###### File Space Header

用于存储表空间的一些整体属性，占用112字节

![image-20211116220759528](https://tva1.sinaimg.cn/large/008i3skNgy1gwhcfke17lj30fb0ndmyt.jpg)

- 前面提及的每个段对应的三个`XDES Entry`链表对应的`List Base Node`就存储在这个页面中`File Space Header`的几个属性里
- `InnoDB`中不是一开始就把所有空闲区对应的`XDES Entry`结构加入到`FREE`链表中，而是一开始只加入一部分，等不够用的时候再把之前没有加入的空闲区加入到`FREE`链表，因此需要`Free Limit`这个属性来指明这些没有加入的空闲区的起始位置
- `Next Unused Segment ID`是为了实现段id的唯一性
- 每个段对应的`INODE Entry`结构会集中存放到一个类型为`INODE`的页中，如果表空间中的段特别多，则会有多个`INODE Entry`结构，可能一个页放不下，因此这些`INODE`类型的页会组成两种列表：
  - `SEG_INODES_FULL`链表，该链表中的`INODE`类型的页面都已经被`INODE Entry`结构填充满了，没空闲空间存放额外的`INODE Entry`了。
  - `SEG_INODES_FREE`链表，该链表中的`INODE`类型的页面仍有空闲空间来存放`INODE Entry`结构。



##### XDES

除了第一个组使用`FSP_HDR`类型来存储`XDES Entry`结构，其他组的第一个页面都是`XDES`类型的。用于存放本组的256个区对应的`XDES Entry`结构



##### IBUF_BITMAP

所有组的第二个页面都是`IBUF_BITMAP`类型的，记录了一些有关`Change Buffer`的信息



##### INODE

第一个组的第三个页面的类型是`INODE`类型，用于存储段对应的`INODE Entry`结构

![image-20211116222612096](https://tva1.sinaimg.cn/large/008i3skNgy1gwhcygu87aj30fi0afgm4.jpg)

`INODE Entry`结构主要包括对应的段内零散页面的地址以及附属于该段的`FREE`、`NOT_FULL`和`FULL`链表的基节点。每个`INODE Entry`结构占用192字节，一个页面里可以存储`85`个这样的结构。

因为一个表空间中可能存在超过85个段，所以可能一个`INODE`类型的页面不足以存储所有的段对应的`INODE Entry`结构，所以就需要额外的`INODE`类型的页面来存储这些结构。为了方便管理这些页，`InnoDB`把这些`INODE`类型的表串联成了两个不同的表，也就是上面提到的`SEG_INODES_FULL`链表和`SEG_INODES_FREE`链表。



### 系统表空间

系统表空间的结构和独立表空间基本类似，只不过由于整个`MySQL`进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的页面，所以会比独立表空间多出一些记录这些信息的页面。因为这个系统表空间最牛逼，相当于是表空间之首，所以它的`表空间 ID`（Space ID）是`0`。



#### 整体结构

系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的页面：

![image_1csbied27ohe1rgg32gquulplm.png-147.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f4911220d8~tplv-t2oaga2asx-watermark.awebp)

可以看到，系统表空间和独立表空间的前三个页面（页号分别为`0`、`1`、`2`，类型分别是`FSP_HDR`、`IBUF_BITMAP`、`INODE`）的类型是一致的，只是页号为`3`～`7`的页面是系统表空间特有的：

![image-20211117100320667](https://tva1.sinaimg.cn/large/008i3skNgy1gwhx3u50oij30fd0b5gly.jpg)

除了这几个记录系统属性的页面之外，系统表空间的`extent 1`和`extent 2`这两个区，也就是页号从`64`~`191`这128个页面被称为`Doublewrite buffer`，也就是**双写缓冲区**。



#### InnoDB数据字典

为了更好的管理用户数据而不得已引入的额外数据称为元数据，比如表中每个列对应的类型是什么，索引对应的字段和索引对应的根页面在哪个表空间的哪个页面……InnoDB存储引擎特意定义了一些列的内部系统表来记录这些元数据

![image-20211117100954626](https://tva1.sinaimg.cn/large/008i3skNgy1gwhxao1crcj30eb0e10tn.jpg)

这些系统表也被称为数据字典，它们都是以B+树的形式保存在系统表空间的某些页面中，其中`SYS_TABLES`、`SYS_COLUMNS`、`SYS_INDEXES`、`SYS_FIELDS`这四个表尤其重要，称之为基本系统表（basic system tables）



##### SYS_TABLES表

![image-20211117101842758](https://tva1.sinaimg.cn/large/008i3skNgy1gwhxjtyhjqj30c90cm3yt.jpg)

这个`SYS_TABLES`表有两个索引：

- 以`NAME`列为主键的聚簇索引
- 以`ID`列建立的二级索引



##### SYS_COLUMNS表

![image-20211117101906725](https://tva1.sinaimg.cn/large/008i3skNgy1gwhxk8iyumj30fe0clq3h.jpg)

这个`SYS_COLUMNS`表只有一个聚集索引：

- 以`(TABLE_ID, POS)`列为主键的聚簇索引



##### SYS_INDEXES表

![image-20211117101925530](https://tva1.sinaimg.cn/large/008i3skNgy1gwhxkkqvvzj30fd0e074y.jpg)

这个`SYS_INDEXES`表只有一个聚集索引：

- 以`(TABLE_ID, ID)`列为主键的聚簇索引



##### SYS_FIELDS表

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1gwhxktg14rj308z05oweh.jpg" alt="image-20211117101940111" style="zoom:67%;" />

这个`SYS_FIELDS`表只有一个聚集索引：

- 以`(INDEX_ID, POS)`列为主键的聚簇索引



#### Data Dictionary Header页面

系统表空间中页号为7的类型为`SYS`的页面为`Data Dictionary Header`，也就是数据字典的头部信息，它记录了上面4个表的聚簇索引和二级索引对应的B+树位置，还记录了整个`InnoDB`存储引擎的一些全局属性。

![image-20211117105323440](https://tva1.sinaimg.cn/large/008i3skNgy1gwhyjwtpr9j30fc0cndgh.jpg)

有Segment Header意味着InnoDB把这些有关数据字典的信息当成一个段来分配存储空间，由于目前需要记录的数据字典信息非常少（Data Dictionary Header部分仅占用了56字节），所以该段只有一个碎片页，也就是页号为7的这个页



##### Data Dictionary Header结构

![image-20211117105957484](https://tva1.sinaimg.cn/large/008i3skNgy1gwhyqqlwhpj309a08njs3.jpg)

- `Max Row ID`：记录所有表的主键中的最大值，是全局共享的
- `Max Table/Index/Space ID`：`InnoDB`存储引擎中所有的表/索引/表空间都对应一个唯一的ID，每次新建时，就会把本字段的值作为ID，然后自增本字段的值
- `Root of SYS_TABLES clust index`：本字段代表`SYS_TABLES`表聚簇索引的根页面的页号。
- `Root of SYS_TABLE_IDS sec index`：本字段代表`SYS_TABLES`表为`ID`列建立的二级索引的根页面的页号。
- `Root of SYS_COLUMNS clust index`：本字段代表`SYS_COLUMNS`表聚簇索引的根页面的页号。
- `Root of SYS_INDEXES clust index`本字段代表`SYS_INDEXES`表聚簇索引的根页面的页号。
- `Root of SYS_FIELDS clust index`：本字段代表`SYS_FIELDS`表聚簇索引的根页面的页号。



##### Segment Header结构的运用

Page Header中有两个属性：`PAGE_BTR_SEG_LEAF`和`PAGE_BTR_SEG_TOP`，都占用10个字节，它们其实对应着一个叫`Segment Header`的结构：

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f48c4472a3~tplv-t2oaga2asx-watermark.awebp" alt="image_1d6a74gu41fuqcqm1htri771d1k16.png-65.1kB" style="zoom:67%;" />

- `Space ID of the INODE Entry`：`INODE Entry`结构所在的表空间ID
- `Page Number of the INODE Entry`：`INODE Entry`结构所在的页面页号
- `Byte Offset of the INODE Entry`：`INODE Entry`结构在该页面中的偏移量

`PAGE_BTR_SEG_LEAF`记录着叶子节点段对应的`INODE Entry`结构的地址是**哪个表空间的哪个页面的哪个偏移量**，`PAGE_BTR_SEG_TOP`记录着非叶子节点段对应的`INODE Entry`结构的地址是哪个表空间的哪个页面的哪个偏移量。这样子索引和其对应的段的关系就建立起来了。不过需要注意的一点是，因为一个索引只对应两个段，所以**只需要在索引的根页面中记录这两个结构即可**。



##### 总结

![image_1d9ppsbelendcbb13hghhn18pe9.png-3564.2kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/1/16a739f4a99c9a08~tplv-t2oaga2asx-watermark.awebp)



## 单表访问方法

`MySQL`把查询的执行方式大致分为以下两种：

1. 使用全表扫描进行查询：即把表的每一行记录都扫描一遍，把符合搜索条件的记录加入到结果集
2. 使用索引进行查询



### const

`MySQL`认为**通过主键或者唯一二级索引列与常数的等值比较来定位一条记录**是很快的，所以把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为`const`，意思是常数级别的，代价是可以忽略不计的。

不过这种`const`访问方法只能在主键列或者唯一二级索引列和一个常数进行**等值比较**时才有效，如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个`const`访问方法才有效（这是因为只有该索引中全部列都采用等值比较才可以定位唯一的一条记录）。



### ref

搜索条件为普通二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为ref。

由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。如果匹配到的记录较少，则回表的代价比较低，查询效率也相对较高。

- 二级索引列值为`NULL`的情况

  不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含`NULL`值的数量并不限制，所以我们采用`key IS NULL`这种形式的搜索条件最多只能使用`ref`的访问方法，而不是`const`的访问方法。

- 对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用`ref`的访问方法，比方说下边这几个查询（`key_part1`、`key_part2`、`key_part3`是一个联合索引）：

  ```sql
  SELECT * FROM single_table WHERE key_part1 = 'god like';
  
  SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary';
  
  SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 = 'legendary' AND key_part3 = 'penta kill';
  ```

  但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为`ref`了，比方说这样：

  ```sql
  SELECT * FROM single_table WHERE key_part1 = 'god like' AND key_part2 > 'legendary';
  ```



### ref_or_null

找出某个二级索引列的值等于某个常数以及该列的值为`NULL`的记录使用的访问方法为`ref_or_null`



### range

利用索引进行范围匹配的访问方法称为`range`。



### index

查询列表都包含在索引中，并且搜索条件中只有索引列，可以通过直接遍历二级索引，不需要回表即可得到所需的结果，这种采用遍历二级索引记录的访问方法称为`range`



### all

全表扫描



### 索引合并

MySQL在一般情况下执行一个查询时最多只会用到单个二级索引，但在某些特殊情况下也可能在一个查询中使用到多个二级索引，MySQL把这种使用到多个索引来完成一次查询的执行方法称为index merge，具体的索引合并算法有下面三种：



#### Intersection合并

即把从多个二级索引查询得到的结果集取交集（多个搜索条件之间使用AND连接）从而得到最终的结果集。

> 联合索引也可以实现这样的效果

**关于只对其中一个搜索条件使用索引，回表后过滤另一个搜索条件以及使用多个二级索引取交集的性能分析：**

读取多个二级索引比只读取一个二级索引更加消耗性能，但是**读取二级索引的操作是顺序I/O，回表操作是随机I/O**。在前面已经分析过顺序I/O的性能要比随机I/O的好得多了，所以如果只读取一个二级索引需要回表的记录数特别多，而读取多个二级索引取交集后的数据很少，即回表的大部分数据都是无用数据，就可能会造成读取多个二级索引的性能消耗比回表造成的消耗更小，此时自然是应该选择读取多个二级索引的方式进行查询了

`MySQL`在某些特定的情况下才可能会使用到`Intersection`索引合并：

1. 二级索引列是等值匹配的情况

   在二级索引中，*记录首先按照索引值进行排序，索引值相等的记录再根据主键排序*。所以等值匹配下取出的记录是根据主键排序好的，如果是范围匹配的话就不是排序好的。

2. 对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。

   联合索引中与1同理。

   **取出的记录是根据主键排好序的有什么好处？**

   这是为了方便后面取交集的操作：取交集时逐个取出两个结果集中的主键，如果两个相同则加入到最终结果集，如果不同则去除较小的那个主键，然后到其所属结果集中取下一个。这个取交集的操作只有在主键排好序的情况下才可以成功，时间复杂度为O(n)，算是比较快的。如果记录没有根据主键排好序，则还要根据主键排序才能进行取交集，这个操作就比较耗时了

3. 主键列可以是范围匹配

   因为二级索引存储的是索引值+主键，所以在二级索引得到的结果的基础上根据主键的范围条件去筛选即可，主键列是范围匹配或是等值匹配并不会影响主键的排序问题



#### Union合并

即把从多个二级索引查询得到的结果集取交集（多个搜索条件之间使用OR连接）从而得到最终的结果集。

1. 二级索引列是等值匹配的情况

2. 对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况。

3. 主键列可以是范围匹配

4. 使用Intersection索引合并的搜索条件

   就是搜索条件的某些部分使用`Intersection`索引合并的方式得到的主键集合和其他方式得到的主键集合取交集，比方说这个查询：

   ```sql
   SELECT * FROM single_table WHERE key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c' OR (key1 = 'a' AND key3 = 'b');
   ```

   优化器可能采用这样的方式来执行这个查询：

   - 先按照搜索条件`key1 = 'a' AND key3 = 'b'`从索引`idx_key1`和`idx_key3`中使用`Intersection`索引合并的方式得到一个主键集合。
   - 再按照搜索条件`key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c'`从联合索引`idx_key_part`中得到另一个主键集合。
   - 采用`Union`索引合并的方式把上述两个主键集合取并集，然后进行回表操作，将结果返回给用户。



#### Sort-Union合并

`Union`索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到`Union`索引合并：

```
SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z'
```

这是因为根据`key1 < 'a'`从`idx_key1`索引中获取的二级索引记录的主键值不是排好序的，根据`key3 > 'z'`从`idx_key3`索引中获取的二级索引记录的主键值也不是排好序的，但是`key1 < 'a'`和`key3 > 'z'`这两个条件又特别让我们动心，所以我们可以这样：

- 先根据`key1 < 'a'`条件从`idx_key1`二级索引中获取记录，并按照记录的主键值进行排序
- 再根据`key3 > 'z'`条件从`idx_key3`二级索引中获取记录，并按照记录的主键值进行排序
- 因为上述的两个二级索引主键值都是排好序的，剩下的操作和`Union`索引合并方式就一样了。

我们把上述这种先按照二级索引记录的主键值进行排序，之后按照`Union`索引合并方式执行的方式称之为`Sort-Union`索引合并，很显然，这种`Sort-Union`索引合并比单纯的`Union`索引合并多了一步对二级索引记录的主键值排序的过程。



**为什么有Sort-Union合并却没有Sort-Intersection合并？**

`Sort-Union`的适用场景是单独根据搜索条件从某个二级索引中获取的记录数比较少，这样即使对这些二级索引记录按照主键值进行排序的成本也不会太高 而`Intersection`索引合并的适用场景是单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大，合并后可以明显降低回表开销，但是如果加入`Sort-Intersection`后，就需要为大量的二级索引记录按照主键值进行排序，这个成本可能比回表查询都高了，所以也就没有引入`Sort-Intersection`这个玩意儿。



## Join-连接

连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户，像这样的结果集就可以称之为笛卡尔积。

> 假如表t1中有m条记录，表t2中有n条记录，那么把这两张表连接起来查询得到的结果集就有m×n条记录。



### 连接过程

1. 确定第一个需要查询的表，这个表称之为**驱动表**
2. 针对上一步骤中从驱动表产生的结果集中的每一条记录，分别需要到另一张表中查找匹配的记录，这张表也可以被称之为**被驱动表**。上一步骤从驱动表中得到了n条记录，就需要查询n次被驱动表



### 内连接与外连接

目的：驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。

- 对于`内连接`的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入到最后的结果集，我们上边提到的连接都是所谓的`内连接`。

  ```sql
  SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件];
  ```

  > 由于对于内连接来说，凡是不符合ON子句或WHERE子句的记录都会被过滤掉，不会加入到结果集，所以内连接的驱动表和被驱动表是可以互换的，并不会影响最后的查询结果

- 对于`外连接`的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。

  > 对于外连接来说，驱动表中的记录即使在被驱动表中找不到符合ON子句条件的记录也要加入到结果集，因此外连接的驱动表和被驱动表是不可以互换的

  - 左外连接

    选取左侧的表为驱动表。

    ```sql
    SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
    ```

  - 右外连接

    选取右侧的表为驱动表。

    ```sql
    SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
    ```

    

**两种不同的连接方式的过滤条件该怎么写？**

放在不同地方的过滤条件是有不同语义的：

- `WHERE`子句中的过滤条件

  `WHERE`子句中的过滤条件就是我们平时见的那种，不论是内连接还是外连接，凡是不符合`WHERE`子句中的过滤条件的记录都不会被加入最后的结果集。

- `ON`子句中的过滤条件

  对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配`ON`子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用`NULL`值填充。

  需要注意的是，这个`ON`子句是专门为外连接驱动表中的记录在被驱动表找不到匹配记录时需要把该记录加入结果集这个场景下提出的，所以如果把`ON`子句放到内连接中，`MySQL`会把它和`WHERE`子句一样对待，也就是说：内连接中的WHERE子句和ON子句是等价的。

> 一般情况下，我们都把只涉及单表的过滤条件放到`WHERE`子句中，把涉及两表的过滤条件都放到`ON`子句中，我们也一般把放到`ON`子句中的过滤条件也称之为`连接条件`。



### 连接原理

#### 嵌套循环连接

访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称为嵌套循环连接，这是最简单，也是最笨拙的一种连接查询算法

![image_1ctsr5ui2cdk1jduqafm7p1d3426.png-129.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/12/25/167e43ab3fa0f107~tplv-t2oaga2asx-watermark.awebp)



#### 使用索引加快连接速度

嵌套循环连接中对被驱动表的多次访问其实就是多次单表查询，可以使用索引进行优化。



#### 基于块的嵌套循环连接

扫描一个表的过程其实是先把这个表从磁盘上加载到内存中，然后从内存中比较匹配条件是否满足。有时候内存里可能并不能完全存放的下表中所有的记录，所以在扫描表前边记录的时候后边的记录可能还在磁盘上，等扫描到后边记录的时候可能内存不足，所以需要把前边的记录从内存中释放掉。所以如果这个被驱动表中的数据特别多而且不能使用索引进行访问， 那就相当于要从磁盘上多次读取这个表，这个I/O代价是非常大的。

为了减少访问被驱动表的次数，`MySQL`提出了一个`join buffer`的概念，`join buffer`就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个`join buffer`中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和`join buffer`中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的I/O代价。

> 最好的情况是`join buffer`足够大，能容纳驱动表结果集中的所有记录，这样只需要访问一次被驱动表就可以完成连接操作了。

这种加入了`join buffer`的嵌套循环连接算法称之为`基于块的嵌套连接`（Block Nested-Loop Join）算法。

> 另外需要注意的是，驱动表的记录并不是所有列都会被放到`join buffer`中，只有查询列表中的列和过滤条件中的列才会被放到`join buffer`中，所以再次提醒我们，最好不要把`*`作为查询列表，只需要把我们关心的列放到查询列表就好了，这样还可以在`join buffer`中放置更多的记录呢哈。



### 基于成本的优化

执行成本=I/O成本+CPU成本

成本常数：读取一个页面花费的成本默认是`1.0`、读取以及检测一条记录是否符合搜索条件的成本默认是`0.2`



#### 单表查询的成本

```sql
CREATE TABLE single_table (
    id INT NOT NULL AUTO_INCREMENT,
    key1 VARCHAR(100),
    key2 INT,
    key3 VARCHAR(100),
    key_part1 VARCHAR(100),
    key_part2 VARCHAR(100),
    key_part3 VARCHAR(100),
    common_field VARCHAR(100),
    PRIMARY KEY (id),
    KEY idx_key1 (key1),
    UNIQUE KEY idx_key2 (key2),
    KEY idx_key3 (key3),
    KEY idx_key_part(key_part1, key_part2, key_part3)
) Engine=InnoDB CHARSET=utf8;
```

在一条单表查询语句真正执行之前，`MySQL`的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的`执行计划`，之后才会调用存储引擎提供的接口真正的执行查询，寻找过程如下：

```sql
SELECT * FROM single_table WHERE 
    key1 IN ('a', 'b', 'c') AND 
    key2 > 10 AND key2 < 1000 AND 
    key3 > key2 AND 
    key_part1 LIKE '%hello%' AND
    common_field = '123';
```

1. 根据搜索条件，找出所有可能使用的索引

   与搜索条件有关的列为`key1`、`key2`、`key3`、`key_part1`、`common_field`

   - `key1 IN`，这个搜索条件可以使用二级索引`idx_key1`
   - `key2 > 10 / < 1000`，这个搜索条件可以使用二级索引`idx_key2`
   - `key3>key2`，这个搜索条件的索引列由于没有和常数比较，所以不能使用idx_key3
   - `key_part1 LIKE '%hello%'` ，这个搜索条件是匹配中间的字符，所以不能走联合索引

   故可能使用的索引，即`possible keys`为`idx_key1`、`idx_key2`

2. 计算全表扫描的代价

   查询成本=I/O成本+CPU成本，所以计算全表扫描的代价需要两个信息：

   - 聚簇索引占用的页面
   - 该表中的记录数

   > MySQL为每个表维护了一系列的统计信息，里面就存储了这两个信息，可以使用`SHOW TABLE STATUS LIKE ‘表名’`来查询

3. 计算使用不同索引执行查询的代价

4. 对比各种执行方案的代价，找出成本最低的那一个



#### 基于索引统计数据的成本计算

有时候使用索引执行查询时会有许多单点区间， 比如使用IN语句就很容易产生非常多的单点区间

对于非唯一二级索引，并不能直接确定一个单点区间对应的二级索引记录的条数有多少，需要通过获取索引对应的B+树的区间最左和最右记录，然后再计算这两条记录之间有多少记录，这种通过直接访问索引对应的B+树来计算某个范围区间对应的索引记录条数的方式称之为`index dive`

为了防止单点区间数量过多，导致index dive操作次数过多损耗大量性能，MySQL提供了一个系统变量`eq_range_index_dive_limit`，它的默认值为200：

- IN语句中的参数<200，将使用`index dive`的方式计算各个单点区间对应的记录条数
- IN语句中的参数≥200，需要使用索引统计数据来进行估算

> 在MySQL 5.7.3以及之前的版本中，`eq_range_index_dive_limit`的默认值为10，之后的版本默认值为200。所以如果大家采用的是5.7.3以及之前的版本的话，很容易采用索引统计数据而不是`index dive`的方式来计算查询成本。当你的查询中使用到了IN查询，但是却实际没有用到索引，就应该考虑一下是不是由于 `eq_range_index_dive_limit` 值太小导致的。



像会为每个表维护一份统计数据一样，`MySQL`也会为表中的每一个索引维护一份统计数据，查看某个表中索引的统计数据可以使用`SHOW INDEX FROM 表名`，它的属性如下表：

![image-20211122145313793](https://tva1.sinaimg.cn/large/008i3skNgy1gwnxl1dpqqj30ih0knq4o.jpg)



结合表的统计信息中的属性Rows（记录表中的记录数）和索引的统计信息中的属性Cardinality（记录索引列中不重复值的数量），可以针对索引列计算出平均一个值重复多少次

```
一个值的重复次数 ≈ Rows ÷ Cardinality
```

所以假设上面式子得出的结果为10，IN子句中参数为20000，那么根据索引统计数据计算出来需要回表的记录数就是：

```
20000×10=200000
```

使用统计数据来计算单点区间对应的索引记录条数可比`index dive`的方式简单多了，但是它的致命弱点就是：不精确！使用统计数据算出来的查询成本与实际所需的成本可能相差非常大。



### 连接查询的成本

#### Condition filtering

`MySQL`中连接查询采用的是嵌套循环连接算法，驱动表会被访问一次，被驱动表可能会被访问多次，所以对于两表连接查询来说，它的查询成本由下边两个部分构成：

- 单次查询驱动表的成本
- 多次查询被驱动表的成本（具体查询多少次取决于对驱动表查询的结果集中有多少条记录）

我们把对驱动表进行查询后得到的记录条数称之为驱动表的`扇出`（英文名：`fanout`）。很显然驱动表的扇出值越小，对被驱动表的查询次数也就越少，连接查询的总成本也就越低。当查询优化器想计算整个连接查询所使用的成本时，就需要计算出驱动表的扇出值

在这两种情况下计算驱动表扇出值时需要靠**猜**：

- 如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要猜满足搜索条件的记录到底有多少条。
- 如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要猜满足*除使用到对应索引的搜索条件外的其他搜索条件*的记录有多少条。

这个**猜**的过程称之为`condition filtering`。



#### 两表连接的成本分析

**连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本**

对于左（外）连接和右（外）连接查询来说，它们的驱动表是固定的，所以想要得到最优的查询方案只需要：

- 分别为驱动表和被驱动表选择成本最低的访问方法。

可是对于内连接来说，驱动表和被驱动表的位置是可以互换的，所以需要考虑两个方面的问题：

- 不同的表作为驱动表最终的查询成本可能是不同的，也就是需要考虑最优的表连接顺序。
- 然后分别为驱动表和被驱动表选择成本最低的访问方法。

比如对于下边这个查询来说：

```sql
SELECT * FROM single_table AS s1 INNER JOIN single_table2 AS s2 
    ON s1.key1 = s2.common_field 
    WHERE s1.key2 > 10 AND s1.key2 < 1000 AND 
          s2.key2 > 1000 AND s2.key2 < 2000;
```

1. 考虑最优的表连接顺序

   - 使用s1作为驱动表的情况

     - 分析对于驱动表的成本最低的执行方案

       涉及s1单表的搜索条件有`s1.key2 > 10 AND s1.key2 < 1000`，所以对表s1的单表查询可能使用到idx_key2索引

     - 分析对于被驱动表的成本最低的执行方案

       涉及s2的搜索条件有 `s2.key2 > 1000 AND s2.key2 < 2000`以及`s2.common_field = 常数`，对于第一个条件可以使用idx_key2索引，对于第二个条件common_field，因为该列没有建立索引，所以只能使用全表扫描

     假设使用索引查询的成本比全表扫描的成本更小，所以此时使用`s1`作为驱动表时的总成本就是（暂时不考虑使用`join buffer`对成本的影响）：

     ```
     使用idx_key2访问s1的成本 + s1的扇出 × 使用idx_key2访问s2的成本
     ```

   - 使用s2作为驱动表的情况

     - 分析对于被驱动表的成本最低的执行方案

       涉及s1的搜索条件有`s1.key2 > 10 AND s1.key2 < 1000`和`s1.key1 = 常数`，使用`idx_key1`可以进行`ref`方式的访问，使用`idx_key2`可以使用`range`方式的访问。这时优化器需要从全表扫描、使用`idx_key1`、使用`idx_key2`这几个方案里选出一个成本最低的方案。

     一般情况下，`ref`的访问方式要比`range`成本更低，这里假设使用`idx_key1`进行对`s1`的访问。所以此时使用`s2`作为驱动表时的总成本就是：

     ```
     使用idx_key2访问s2的成本 + s2的扇出 × 使用idx_key1访问s1的成本
     ```

2. 分别为驱动表和被驱动表选择成本最低的访问方法



连接查询成本占大头的其实是`驱动表扇出数 x 单次访问被驱动表的成本`，所以我们的优化重点其实是下边这两个部分：

- 尽量减少驱动表的扇出

- 对被驱动表的访问成本尽量低

  这一点对于我们实际书写连接查询语句时十分有用，我们需要尽量在被驱动表的连接列上建立索引，这样就可以使用`ref`访问方法来降低访问被驱动表的成本了。如果可以，被驱动表的连接列最好是该表的主键或者唯一二级索引列，这样就可以把访问被驱动表的成本降到更低了。



#### 多表连接的成本分析

对于n表连接，则有n!种连接顺序。

减少计算非常多种连接顺序的成本的方法：

- 提前结束某种顺序的成本评估

  `MySQL`在计算各种链接顺序的成本之前，会维护一个全局的变量，这个变量表示当前最小的连接查询成本。如果在分析某个连接顺序的成本时，该成本已经超过当前最小的连接查询成本，那就压根儿不对该连接顺序继续往下分析了。

- 系统变量`optimizer_search_depth`

  为了防止无穷无尽的分析各种连接顺序的成本，设计`MySQL`的大叔们提出了`optimizer_search_depth`系统变量，如果连接表的个数小于该值，那么就继续穷举分析每一种连接顺序的成本，否则只对与`optimizer_search_depth`值相同数量的表进行穷举分析。很显然，该值越大，成本分析的越精确，越容易得到好的执行计划，但是消耗的时间也就越长，否则得到不是很好的执行计划，但可以省掉很多分析连接成本的时间。

- 根据某些规则压根儿就不考虑某些连接顺序

  即使是有上边两条规则的限制，但是分析多个表不同连接顺序成本花费的时间还是会很长，所以设计`MySQL`的大叔干脆提出了一些所谓的`启发式规则`（就是根据以往经验指定的一些规则），凡是不满足这些规则的连接顺序压根儿就不分析，这样可以极大的减少需要分析的连接顺序的数量，但是也可能造成错失最优的执行计划。他们提供了一个系统变量`optimizer_prune_level`来控制到底是不是用这些启发式规则。



## InnoDB统计数据

`InnoDB`提供了两种存储统计数据的方式：

- 永久性的统计数据

  这种统计数据存储在磁盘上，也就是服务器重启之后这些统计数据还在。

- 非永久性的统计数据

  这种统计数据存储在内存中，当服务器关闭时这些这些统计数据就都被清除掉了，等到服务器重启之后，在某些适当的场景下才会重新收集这些统计数据。

> 系统变量`innodb_stats_persistent`控制到底采用哪种方式去存储统计数据。在`MySQL 5.6.6`之前，`innodb_stats_persistent`的值默认是`OFF`，也就是说`InnoDB`的统计数据默认是存储到内存的，之后的版本中`innodb_stats_persistent`的值默认是`ON`，也就是统计数据默认被存储到磁盘中。
>
> `InnoDB`默认是以表为单位来收集和存储统计数据的，可以在创建和修改表的时候通过指定`STATS_PERSISTENT`属性来指明该表的统计数据存储方式
>
> ```sql
> CREATE TABLE 表名 (...) Engine=InnoDB, STATS_PERSISTENT = (1|0);
> 
> ALTER TABLE 表名 Engine=InnoDB, STATS_PERSISTENT = (1|0);
> ```
>
> 当`STATS_PERSISTENT=1`时，表明我们想把该表的统计数据永久的存储到磁盘上
>
> 当`STATS_PERSISTENT=0`时，表明我们想把该表的统计数据临时的存储到内存中。
>
> 如果我们在创建表时未指定`STATS_PERSISTENT`属性，那默认采用系统变量`innodb_stats_persistent`的值作为该属性的值。



### 基于磁盘的永久统计数据

当我们选择把某个表以及该表索引的统计数据存放到磁盘上时，实际上是把这些统计数据存储到了两个表里，这两个表都位于`mysql`系统数据库下边，其中：

- `innodb_table_stats`存储了关于表的统计数据，每一条记录对应着一个表的统计数据。
- `innodb_index_stats`存储了关于索引的统计数据，每一条记录对应着一个索引的一个统计项的统计数据。



#### 更新统计数据

- 开启`innodb_stats_auto_recalc`

  系统变量`innodb_stats_auto_recalc`决定着服务器是否自动重新计算统计数据，它的默认值是`ON`，也就是该功能默认是开启的。每个表都维护了一个变量，该变量记录着对该表进行增删改的记录条数，如果发生变动的记录数量超过了表大小的`10%`，并且自动重新计算统计数据的功能是打开的，那么服务器会重新进行一次统计数据的计算，并且更新`innodb_table_stats`和`innodb_index_stats`表。不过自动重新计算统计数据的过程是**异步**发生的，也就是即使表中变动的记录数超过了`10%`，自动重新计算统计数据也不会立即发生，可能会延迟几秒才会进行计算。

- 手动调用`ANALYZE TABLE`语句来更新统计信息

  需要注意的是，ANALYZE TABLE语句会立即重新计算统计数据，也就是这个过程是同步的，在表中索引多或者采样页面特别多时这个过程可能会特别慢，请不要没事儿就运行一下`ANALYZE TABLE`语句，最好在业务不是很繁忙的时候再运行。

- 手动更新

  `innodb_table_stats`和`innodb_index_stats`实际上也是两张普通的表，可以通过`UPDATE`语句对表中数据进行更新。

  需要注意的是更新完`innodb_table_stats`只是单纯的修改了一个表的数据，需要让`MySQL`查询优化器重新加载我们更改过的数据，运行下边的命令就可以了：

  ```sql
  FLUSH TABLE single_table;
  ```



### 基于内存的非永久统计数据

与永久性的统计数据不同，非永久性的统计数据采样的页面数量是由`innodb_stats_transient_sample_pages`控制的，这个系统变量的默认值是`8`。

另外，由于非永久性的统计数据经常更新，所以导致`MySQL`查询优化器计算查询成本的时候依赖的是经常变化的统计数据，也就会生成经常变化的执行计划。不过最近的MySQL版本基本上使用的都是基于磁盘的永久统计数据



### innodb_stats_method的使用

我们知道`索引列不重复的值的数量`这个统计数据对于`MySQL`查询优化器十分重要，因为通过它可以计算出在索引列中平均一个值重复多少行，它的应用场景主要有两个：

- 单表查询中单点区间太多，比方说这样：

  ```
  SELECT * FROM tbl_name WHERE key IN ('xx1', 'xx2', ..., 'xxn');
  ```

  当`IN`里的参数数量过多时，采用`index dive`的方式直接访问`B+`树索引去统计每个单点区间对应的记录的数量就太耗费性能了，所以直接依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量。

- 连接查询时，如果有涉及两个表的等值匹配连接条件，该连接条件对应的被驱动表中的列又拥有索引时，则可以使用`ref`访问方法来对被驱动表进行查询，比方说这样：

  ```
  SELECT * FROM t1 JOIN t2 ON t1.column = t2.key WHERE ...;
  ```

  在真正执行对`t2`表的查询前，`t1.comumn`的值是不确定的，所以我们也不能通过`index dive`的方式直接访问`B+`树索引去统计每个单点区间对应的记录的数量，所以也只能依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量。

在统计索引列不重复的值的数量时，有一个比较烦的问题就是索引列中出现`NULL`值怎么办，比方说某个索引列的内容是这样：

```
+------+
| col  |
+------+
|    1 |
|    2 |
| NULL |
| NULL |
+------+
```

此时计算这个`col`列中不重复的值的数量就有下边的分歧：

- 有的人认为`NULL`值代表一个未确定的值，所以每一个`NULL`值都是独一无二的，也就是说统计索引列不重复的值的数量时，应该把`NULL`值当作一个独立的值，所以`col`列的不重复的值的数量就是：`4`（分别是1、2、NULL、NULL这四个值）。
- 有的人认为其实`NULL`值在业务上就是代表没有，所有的`NULL`值代表的意义是一样的，所以`col`列不重复的值的数量就是：`3`（分别是1、2、NULL这三个值）。
- 有的人认为这`NULL`完全没有意义嘛，所以在统计索引列不重复的值的数量时压根儿不能把它们算进来，所以`col`列不重复的值的数量就是：`2`（分别是1、2这两个值）。

`MySQL`提供了一个名为`innodb_stats_method`的系统变量，相当于在计算某个索引列不重复值的数量时如何对待`NULL`值这个锅甩给了用户，这个系统变量有三个候选值：

- `nulls_equal`：认为所有`NULL`值都是相等的。这个值也是`innodb_stats_method`的默认值。

  如果某个索引列中`NULL`值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别多，所以需要回表的数据量更大，倾向于不使用索引进行访问。

- `nulls_unequal`：认为所有`NULL`值都是不相等的。

  如果某个索引列中`NULL`值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别少，所以需要回表的数据量较小，倾向于使用索引进行访问。

- `nulls_ignored`：直接把`NULL`值忽略掉。



## 基于规则的优化

### 条件化简

1. 移除不必要的括号

   ```sql
   ((a = 5 AND b = c) OR ((a > c) AND (c < 5)))
   
   优化后
   (a = 5 and b = c) OR (a > c AND c < 5)
   ```

2. 常量传递

   当某个表达式是列a和常量做等值匹配，并且这个表达式和其他涉及到a的表达式使用`AND`连接起来时，可以把其他表达式中的a的值替换为常量

   ```sql
   a = 5 AND b > a
   
   优化后
   a = 5 AND b > 5
   ```

3. 等值传递

   ```sql
   a = b and b = c and c = 5
   
   优化后
   a = 5 and b = 5 and c = 5
   ```

4. 移除无用条件

   对于一些明显永远为TRUE或者FALSE的表达式，优化器会移除掉它们

5. 表达式计算

   在查询开始执行之前，如果表达式中只包含常量的话，它的值会被先计算出来

   但如果某个列并不是以单独的形式作为表达式的操作数时，比如出现在函数中，出现在某个更复杂的表达式中，优化器是不会尝试对表达式进行化简的。

   前面说过只有搜索条件中索引列和常数使用某些运算符连接起来才可能使用到索引，所以最好让索引列以单独的形式出现在表达式中。

6. HAVING子句和WHERE子句的合并

   如果查询语句中没有出现诸如`SUM`、`MAX`等等的聚集函数以及`GROUP BY`子句，优化器就把`HAVING`子句和`WHERE`子句合并起来

7. 常量表检测

   MySQL表把以下两种表称为常量表：

   - 查询的表中没有记录，或者只有一条记录

     > 表中的数据有多少条是来自于表的统计数据的，而由于InnoDB中表的统计数据是估算的，并不准确。所以这一条并不适用于InnoDB引擎，只能适用于Memory或者MyISAM引擎

   - 使用主键等值匹配或者唯一二级索引列等值匹配作为搜索条件来查询某个表

   优化器在分析一个查询语句时，先首先执行常量表查询，然后把查询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本



### 外连接消除

内连接可能通过优化表的连接顺序来降低整体的查询成本，而外连接却无法优化表的连接顺序。

> 外连接和内连接的本质区别就是：
>
> - 对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充；
> - 而内连接的驱动表的记录如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录会被舍弃。
>
> 右（外）连接和左（外）连接其实只在驱动表的选取方式上是不同的，其余方面都是一样的，所以优化器会首先把右（外）连接查询转换成左（外）连接查询。

无论是外连接还是内连接，凡是不符合WHERE子句中条件的记录都不会参与连接，因此只要在外连接的WHERE子句中指定关于被驱动表相关列的值不为NULL（因为如果匹配不上被驱动表相关列的值会被NULL填充），那么外连接中在被驱动表中找不到符合`ON`子句条件的驱动表记录也就被排除出最后的结果集了，也就是说：在这种情况下：外连接和内连接也就没有什么区别了

我们把这种在外连接查询中，指定的`WHERE`子句中包含被驱动表中的列不为`NULL`值的条件称之为**空值拒绝**（英文名：`reject-NULL`）。在被驱动表的`WHERE`子句符合空值拒绝的条件后，外连接和内连接可以相互转换。**这种转换带来的好处就是查询优化器可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序来执行查询**。



### 子查询优化

#### 按返回的结果集区分子查询

- 标量子查询

  只返回单一值的子查询。

- 行子查询

  返回一条记录（包含多个列）的子查询

- 列子查询

  返回一列（包含多条记录）的子查询

- 表子查询

  返回包含多个列的多条记录的子查询



#### 按与外层查询关系来区分子查询

- 不相关子查询

  如果子查询可以单独运行出结果，而不依赖于外层查询的值，我们就可以把这个子查询称之为`不相关子查询`

- 相关子查询

  子查询的执行需要依赖于外层查询的值，所以这个子查询就是一个`相关子查询`



#### 标量子查询、行子查询的执行方式

1. 先单独执行子查询
2. 然后再将上一步子查询得到的结果当做外层查询的参数再执行外层查询

也就是说，对于包含不相关的标量子查询或行子查询的查询语句来说，MySQL会分别独立执行外层查询和子查询，实际上就是两个单表查询

对于相关的标量子查询或者行子查询：

```sql
SELECT * FROM s1 WHERE 
    key1 = (SELECT common_field FROM s2 WHERE s1.key3 = s2.key3 LIMIT 1);
```

1. 先从外层查询中获取一条记录
2. 从子查询中找出与上一步中获取的那条记录相关的记录，然后执行子查询
3. 最后根据子查询的查询结果来检测外层查询WHERE子句的条件是否成立，如果成立，就把外层查询的那条记录加入到结果集，否则就丢弃
4. 再次执行第一步，获取第二条外层查询中的记录……



#### IN子查询优化

##### 物化表

对于如下不相关的IN子查询：

```sql
SELECT * FROM s1 
    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');
```

如果把子查询和外层查询分别看成两个单独的单表查询效率的话，可能会导致这些问题：

- 结果集太多，内存可能无法完全存放
- 对于外层查询来说，如果子查询的结果集太多，那就意味着IN子句中的参数过多，这就导致：
  - 无法有效的使用索引，只能对外层查询进行全表扫描
  - 在对外层查询执行全表扫描时，由于IN子句中的参数太多，这会导致检测一条记录是否符合IN子句中的参数花费的时间太长

为了解决上面所说的问题，MySQL不直接将不相关子查询的结果集当做外层查询的参数，而是将该结果集写入一个临时表里：

- 该临时表的列就是子查询结果集中的列

- 写入临时表的记录会被去重

- 建立**基于内存的使用Memory存储引擎**的临时表，而且会为该表建立**哈希索引**

  > IN语句的本质就是判断某个操作数在不在某个集合里，如果集合中的数据建立了哈希索引，那么这个匹配的过程就是超级快的。

这个把子查询结果集中的记录保存到临时表的过程称为**物化**（Materialize）。正因为物化表中的记录都建立了索引（基于内存的物化表有哈希索引，基于磁盘的有B+树索引），通过索引执行`IN`语句判断某个操作数在不在子查询结果集中变得非常快，从而提升了子查询语句的性能。



##### 物化表转连接

对于以下查询语句：

```sql
SELECT * FROM s1 
    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');
```

- 从表`s1`的角度来看待，整个查询的意思其实是：对于`s1`表中的每条记录来说，如果该记录的`key1`列的值在子查询对应的物化表中，则该记录会被加入最终的结果集。画个图表示一下就是这样：

  ![image_1cvfj9up26i518t91li5ooq1r0u2d.png-84.9kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/6/16a8dda5369e68c5~tplv-t2oaga2asx-watermark.awebp)

- 从子查询物化表的角度来看待，整个查询的意思其实是：对于子查询物化表的每个值来说，如果能在`s1`表中找到对应的`key1`列的值与该值相等的记录，那么就把这些记录加入到最终的结果集。画个图表示一下就是这样：

  ![image_1cvfjg3os1oh1e3o5c11dhd1odd2q.png-67.4kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/6/16a8dda5394d3903~tplv-t2oaga2asx-watermark.awebp)

也就是说其实上边的查询就相当于表`s1`和子查询物化表`materialized_table`进行**内连接**

```sql
SELECT s1.* FROM s1 INNER JOIN materialized_table ON key1 = m_val;
```



##### 将子查询转换为semi-join

`子查询→物化表→内连接`这个过程少不了需要消耗创建物化表的成本，那么能不能不进行物化操作就直接把子查询转换为连接呢？

对于以下查询语句：

```sql
SELECT * FROM s1 
    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');
```

我们可以把这个查询理解成：对于`s1`表中的某条记录，如果我们能在`s2`表（准确的说是执行完`WHERE s2.key3 = 'a'`之后的结果集）中找到一条或多条记录，这些记录的`common_field`的值等于`s1`表记录的`key1`列的值，那么该条`s1`表的记录就会被加入到最终的结果集。这个过程其实和把`s1`和`s2`两个表连接起来的效果很像：

```sql
SELECT s1.* FROM s1 INNER JOIN s2 
    ON s1.key1 = s2.common_field 
    WHERE s2.key3 = 'a';
```

符合s1.key1 = s2.common_field的结果集有以下三种情况：

- 对于s1表的某条记录来说，s2表中没有任何记录满足，那么该记录不会加入到最后的结果集
- 对于s1表的某条记录来说，s2表中有且只有1条记录满足，那么该记录会被加入1次到最后的结果集
- 对于s1表的某条记录来说，s2表中至少有2条记录满足，那么该记录会被多次加入到最后的结果集

因为情况三的存在，IN子查询和两表连接之间并不完全等价，但是将子查询转换为连接又可以充分发挥优化器的作用，因此MySQL提出了一个新概念——半连接（semi-join）。将`s1`表和`s2`表进行半连接的意思就是：**对于`s1`表的某条记录来说，我们只关心在`s2`表中是否存在与之匹配的记录，而不关心具体有多少条记录与之匹配，最终的结果集中只保留`s1`表的记录。**



**实现方法**

1. Table pullout（子查询中的表上拉）

   **当子查询的查询列表处只有主键或者唯一索引列时**，可以直接把子查询中的表上拉到外层查询的FROM子句中，并把子查询中的搜索条件合并到外层查询的搜索条件中

   > 子查询的查询列表只有主键或者唯一索引列意味着该列的值不会重复，也就不会出现多条记录匹配成功的情况（情况三）

2. DuplicateWeedout execution strategy（重复值消除）

   针对于情况三，s1中的记录可能会多次被添加到最后的结果集中，为了消除重复，建立一个临时表，这样在执行连接查询的过程中，每当某条s1表中的记录要加入结果集时，就首先把这条记录的主键值加入到临时表中，如果添加成功，就把该记录添加到最终的结果集；如果添加失败，说明这条记录已经加入过最终的结果集了，这里直接丢弃它就好了。

3. LooseScan execution strategy（松散扫描）

   把IN子查询转换为半连接查询后，如果将子查询的表作为驱动表执行查询，并且走非唯一索引时，只取值相同的记录的第一条去做匹配操作

   ![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/3/16ecb503727bb15e~tplv-t2oaga2asx-watermark.awebp)

4. Semi-join Materialization execution strategy

   我们之前介绍的先把外层查询的`IN`子句中的不相关子查询进行物化，然后再进行外层查询的表和物化表的连接本质上也算是一种`semi-join`，只不过由于物化表中没有重复的记录，所以可以直接将子查询转为连接查询。

5. FirstMatch execution strategy（首次匹配）

   FirstMatch是一种最原始的半连接执行方式：先取一条外层查询的中的记录，然后到子查询的表中寻找符合匹配条件的记录，如果能找到一条，则将该外层查询的记录放入最终的结果集并且停止查找更多匹配的记录，如果找不到则把该外层查询的记录丢弃掉；然后再开始取下一条外层查询中的记录，重复上边这个过程。



**适用条件**

- 该子查询必须是和`IN`语句组成的布尔表达式，并且在外层查询的`WHERE`或者`ON`子句中出现。
- 外层查询也可以有其他的搜索条件，只不过和`IN`子查询的搜索条件必须使用`AND`连接起来。
- 该子查询必须是一个单一的查询，不能是由若干查询由`UNION`连接起来的形式。
- 该子查询不能包含`GROUP BY`或者`HAVING`语句或者聚集函数。



**不适用情况**

- 外层查询的`WHERE`条件中有其他搜索条件与IN子查询组成的布尔表达式使用`OR`连接起来

  ```sql
  SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE s1.key2 = s2.key2) OR key3 = 'a';
  ```

- 使用`NOT IN`而不是`IN`的情况

  ```sql
  SELECT * FROM s1 
      WHERE key1 NOT IN (SELECT common_field FROM s2 WHERE key3 = 'a')
  ```

  MySQL会尝试把表物化之后再参与查询：先将子查询物化，然后再判断key1是否在物化表的结果集中可以加快查询执行的速度。

  > 由于是NOT IN，因此将子查询物化之后不能转为和外层查询的表的连接

- 在`SELECT`子句中的IN子查询的情况

- 子查询中包含`GROUP BY`、`HAVING`或者聚集函数的情况

- 子查询中包含`UNION`的情况

> 不管子查询是相关的还是不相关的，都可以把`IN`子查询尝试转为`EXISTS`子查询
>
> 其实对于任意一个IN子查询来说，都可以被转为`EXISTS`子查询，通用的例子如下：
>
> ```sql
> outer_expr IN (SELECT inner_expr FROM ... WHERE subquery_where)
> ```
>
> 可以被转换为：
>
> ```sql
> EXISTS (SELECT inner_expr FROM ... WHERE subquery_where AND outer_expr=inner_expr)
> ```
>
> 当然这个过程中有一些特殊情况，比如在`outer_expr`或者`inner_expr`值为`NULL`的情况下就比较特殊。因为有`NULL`值作为操作数的表达式结果往往是`NULL`，而`EXISTS`子查询的结果肯定是`TRUE`或者`FASLE`。
>
> 但是，大部分使用`IN`子查询的场景是把它放在`WHERE`或者`ON`子句中，而`WHERE`或者`ON`子句是不区分`NULL`和`FALSE`的，所以只要我们的`IN`子查询是放在`WHERE`或者`ON`子句中的，那么`IN -> EXISTS`的转换就是没问题的。
>
> 相关子查询中子查询执行的时候是不能走索引的，但是转为EXISTS子查询后就可以使用索引了。
>
> 需要注意的是，如果`IN`子查询不满足转换为`semi-join`的条件，又不能转换为物化表或者转换为物化表的成本太大，那么它就会被转换为`EXISTS`查询。



## Explain详解

一条查询语句在经过`MySQL`查询优化器的各种基于成本和规则的优化会后生成一个所谓的`执行计划`，这个执行计划展示了接下来具体执行查询的方式，比如多表连接的顺序是什么，对于每个表采用什么访问方法来具体执行查询等等。

使用`EXPLAIN`语句可以查看某个语句的具体执行计划

```sql
EXPLAIN 语句;
```

![image-20220103201620721](https://tva1.sinaimg.cn/large/008i3skNgy1gy0qy6aqlhj31e206iabd.jpg)

![image-20220103201651720](https://tva1.sinaimg.cn/large/008i3skNgy1gy0qyolgqkj30dz0i7q3q.jpg)



### 执行计划各列详解

#### table

无论查询语句有多复杂，里面包含了多少个表，到最后也是需要对每个表进行单表访问的，因此`EXPLAIN`语句输出的每条记录里面都对应着某个单表的访问方法，table字段就是这条记录访问的表名

![image-20220103202105266](https://tva1.sinaimg.cn/large/008i3skNgy1gy0r32x3t9j31o4074mzb.jpg)

如上图，这个连接查询语句涉及了两张表s1、s2，因此`EXPLAIN`语句输出的执行计划里面有两条记录，分别是对s1、s2单表的访问方法



#### id

查询语句中每出现一个`SELECT`关键字，就会被分配一个唯一的id值

如上面table中的图，由于查询语句中只有一个`SELECT`关键字，因此两条记录的ID都是1

![image-20220103202406766](https://tva1.sinaimg.cn/large/008i3skNgy1gy0r68b02ej31ly07g40n.jpg)

如上图，由于有两个`SELECT`关键字，因此id分别为1和2

特别注意：查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询，而查询计划是根据优化后的语句设定的，所以想知道查询优化器对某个包含子查询的语句是否进行了重写，直接查看执行计划就好了，比如说：

![image-20220103202611559](https://tva1.sinaimg.cn/large/008i3skNgy1gy0r8ee32lj31ps0bi412.jpg)

输入的查询语句明明有两个SELECT关键字，执行计划中两条记录的ID却都是1，说明查询优化器把子查询转换为了连接查询

**对于`UNION`子句的查询语句来说**，会发现执行计划中会多一条ID为NULL的记录

![image-20220103203049499](https://tva1.sinaimg.cn/large/008i3skNgy1gy0rd8qu7jj31hw088wgz.jpg)

`UNION`子句的作用是把多个查询的结果集合并起来并对结果集中的记录进行去重。`MySQL`使用内部的临时表进行去重，这张临时表就是第三条记录中的`<union1,2>`，即把id为1的查询和id为2的查询的结果集合并起来并去重

> 对于`UNION ALL`子句，由于其只是单纯的把多个查询的结果集中的记录合并成一个并返回，不需要去重，因此就不需要使用临时表，也就不会多出那条ID为NULL的记录
>
> ![image-20220103203408127](https://tva1.sinaimg.cn/large/008i3skNgy1gy0rgonex6j31bk078myu.jpg)



#### select_type

只要知道了某个小查询的`select_type`属性，就知道了这个小查询在整个大查询中扮演了一个什么角色

|         名称         |                             描述                             |
| :------------------: | :----------------------------------------------------------: |
|        SIMPLE        | 查询语句中不包含`UNION`或者子查询的查询都算作是`SIMPLE`类型（连接查询也算是`SIMPLE`类型） |
|       PRIMARY        | 对于包含`UNION`、`UNION ALL`或者子查询的大查询来说，它是由几个小查询组成的，其中最左边的那个查询的`select_type`值就是`PRIMARY` |
|        UNION         | 对于包含`UNION`或者`UNION ALL`的大查询来说，它是由几个小查询组成的，其中除了最左边的那个小查询以外，其余的小查询的`select_type`值就是`UNION` |
|     UNION RESULT     | `MySQL`选择使用临时表来完成`UNION`查询的去重工作，针对该临时表的查询的`select_type`就是`UNION RESULT` |
|       SUBQUERY       | 如果包含子查询的查询语句不能够转为对应的`semi-join`的形式，并且该子查询是不相关子查询，并且查询优化器决定采用将该子查询物化的方案来执行该子查询时，该子查询的第一个`SELECT`关键字代表的那个查询的`select_type`就是`SUBQUERY` |
|  DEPENDENT SUBQUERY  | 如果包含子查询的查询语句不能够转为对应的`semi-join`的形式，并且该子查询是相关子查询，则该子查询的第一个`SELECT`关键字代表的那个查询的`select_type`就是`DEPENDENT SUBQUERY`（可能会被执行多次） |
|   DEPENDENT UNION    | 在包含`UNION`或者`UNION ALL`的大查询中，如果各个小查询都依赖于外层查询的话，那除了最左边的那个小查询之外，其余的小查询的`select_type`的值就是`DEPENDENT UNION`。 |
|       DERIVED        | 对于采用物化的方式执行的包含派生表的查询，该派生表对应的子查询的`select_type`就是`DERIVED` |
|     MATERIALIZED     | 当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的`select_type`属性就是`MATERIALIZED` |
| UNCACHEABLE SUBQUERY |                              -                               |
|  UNCACHEABLE UNION   |                              -                               |



#### type

表明了访问的方法

> 完整的访问方法如下：
>
> `system`，`const`，`eq_ref`，`ref`，`fulltext`，`ref_or_null`，`index_merge`，`unique_subquery`，`index_subquery`，`range`，`index`，`ALL`
>
> 以上访问方法按顺序性能依次变差

- `system`

  当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory，那么对该表的访问方法就是`system`

- `const`

  当我们**根据主键或者唯一二级索引列与常数进行等值匹配**时，对单表的访问方法就是`const`

- `eq_ref`

  在连接查询时，如果**被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问**的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是`eq_ref`

- `ref`

  当**通过普通的二级索引列与常量进行等值匹配**时来查询某个表，那么对该表的访问方法就可能是`ref`

- `ref_or_null`

  当**对普通二级索引进行等值匹配查询，该索引列的值也可以是`NULL`值**时，那么对该表的访问方法就可能是`ref_or_null`

- `index_merge`

  一般情况下对于某个表的查询只能使用到一个索引，但我们唠叨单表访问方法时特意强调了在某些场景下可以使用`Intersection`、`Union`、`Sort-Union`这三种索引合并的方式来执行查询，**使用索引合并的访问方法**就是`index_merge`

- `unique_subquery`

  类似于两表连接中被驱动表的`eq_ref`访问方法，**`unique_subquery`是针对在一些包含`IN`子查询的查询语句中，如果查询优化器决定将`IN`子查询转换为`EXISTS`子查询，而且子查询可以使用到主键进行等值匹配**的话，那么该子查询执行计划的`type`列的值就是`unique_subquery`

- `index_subquery`

  `index_subquery`与`unique_subquery`类似，只不过访问子查询中的表时使用的是普通的索引

- `range`

  如果**使用索引获取某些`范围区间`的记录**，那么就可能使用到`range`访问方法

- `index`

  当我们**可以使用索引覆盖，但需要扫描全部的索引记录时**，该表的访问方法就是`index`

- `all`

  全表扫描



#### possible_keys和key

`possible_keys`列表示在某个查询语句中，对某个表执行单表查询时可能用到的索引有哪些，`key`列表示实际用到的索引有哪些

有一点比较特别，就是在使用`index`访问方法来查询某个表时，`possible_keys`列是空的，而`key`列展示的是实际使用到的索引

> `possible_keys`列中的值并不是越多越好，可能使用的索引越多，查询优化器计算查询成本时就得花费更长时间，所以如果可以的话，尽量删除那些用不到的索引



#### key_len

`key_len`列表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度，它是由这三个部分构成的：

- 对于使用固定长度类型的索引列来说，它实际占用的存储空间的最大长度就是该固定值，对于指定字符集的变长类型的索引列来说，比如某个索引列的类型是`VARCHAR(100)`，使用的字符集是`utf8`，那么该列实际占用的最大存储空间就是`100 × 3 = 300`个字节。
- 如果该索引列可以存储`NULL`值，则`key_len`比不可以存储`NULL`值时多1个字节。
- 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度。

![image-20220103211412248](https://tva1.sinaimg.cn/large/008i3skNgy1gy0smck3c2j31ck062q49.jpg)

1. key1列为`VARCHAR(100)`类型->该列实际最多占用的存储空间为`100 × 3 = 300`个字节
2. 允许为空->`300+1=301`
3. 可变长列，需要2字节来存储变长列的实际长度->`301+2=303`



#### ref

当使用索引列等值匹配的条件去执行查询时，也就是在访问方法是`const`、`eq_ref`、`ref`、`ref_or_null`、`unique_subquery`、`index_subquery`其中之一时，`ref`列展示的就是与索引列作等值匹配的东东是个啥，比如只是一个常数或者是某个列。

![image-20220103211722951](https://tva1.sinaimg.cn/large/008i3skNgy1gy0spnifbij31hk072jt9.jpg)

与s2表的id作等值匹配的对象就是表s1的id



#### rows

如果查询优化器决定使用全表扫描的方式对某个表执行查询时，执行计划的`rows`列就代表预计需要扫描的行数，如果使用索引来执行查询时，执行计划的`rows`列就代表预计扫描的索引记录行数。



#### filtered

之前在分析连接查询的成本时提出过一个`condition filtering`的概念，就是`MySQL`在计算驱动表扇出时采用的一个策略：

- 如果使用的是全表扫描的方式执行的单表查询，那么计算驱动表扇出时需要估计出满足搜索条件的记录到底有多少条。
- 如果使用的是索引执行的单表扫描，那么计算驱动表扇出的时候需要估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。

> 对于单表查询来说，这个值没什么意义



#### extra

- `no tables used`

  查询语句没有FROM子句

- `impossible where`

  WHERE子句永远为FALSE

- `no matching min/max row`

  当查询列表处有`MIN`或者`MAX`聚集函数，但是并没有符合`WHERE`子句中的搜索条件的记录时，将会提示该额外信息

- `using index`

  当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用索引覆盖（无需回表）的情况下，在`Extra`列将会提示该额外信息

- `using index condition`

  如果在查询语句的执行过程中将要使用`索引条件下推`这个特性，在`Extra`列中将会显示`Using index condition`

  **什么是索引条件下推？**

  ```sql
  SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a';
  ```

  对于上面这个查询，`key1 > 'z'` 这个条件是可以使用索引的，但是`key1 LIKE '%a'`这个条件由于是左侧模糊，所以不能使用索引

  先看看索引条件下推前的查询步骤：

  1. 先根据`key1 > 'z'` 这个条件从二级索引`idx_key1`中获取到对应的二级索引记录
  2. 然后根据上一步骤得到的二级索引记录中的主键值进行回表，找到完整的用户记录后再判断这条记录是否符合`key1 LIKE '%a'`这个条件
  3. 如果符合就把该条记录加入结果集

  显而易见，有很多明明不符合`key1 LIKE '%a'`，却仍然需要回表，造成了浪费

  因此提出了索引条件下推，即把回表的操作延后：

  1. 先根据`key1 > 'z'` 这个条件从二级索引`idx_key1`中获取到对应的二级索引记录
  2. 再判断这些记录是否符合`key1 LIKE '%a’`
  3. 如果符合再进行回表

- `Using where`

  当我们使用全表扫描来执行对某个表的查询，并且该语句的`WHERE`子句中有针对该表的搜索条件时，在`Extra`列中会提示上述额外信息

- `using join buffer(Block Nested Loop)`

  在连接查询执行过程中，当被驱动表不能有效的利用索引加快访问速度，`MySQL`一般会为其分配一块名叫`join buffer`的内存块来加快查询速度，也就是我们所讲的`基于块的嵌套循环算法`

- `not exists`

  当我们使用左（外）连接时，如果`WHERE`子句中包含要求被驱动表的某个列等于`NULL`值的搜索条件，而且那个列又是不允许存储`NULL`值的，那么在该表的执行计划的`Extra`列就会提示`Not exists`额外信息

- `Using intersect(...)`、`Using union(...)`和`Using sort_union(...)`

  如果执行计划的`Extra`列出现了`Using intersect(...)`提示，说明准备使用`Intersect`索引合并的方式执行查询，括号中的`...`表示需要进行索引合并的索引名称；如果出现了`Using union(...)`提示，说明准备使用`Union`索引合并的方式执行查询；出现了`Using sort_union(...)`提示，说明准备使用`Sort-Union`索引合并的方式执行查询。

- `Zero limit`

  当我们的`LIMIT`子句的参数为`0`时，表示压根儿不打算从表中读出任何记录，将会提示该额外信息

- `Using filesort`

  在很多情况下排序操作是无法使用索引的，只能在内存中（记录较少时）或者磁盘中（记录较多时）进行排序，这种在内存或者磁盘上进行排序的方式统称为**文件排序**，如果某个查询需要使用文件排序的方式执行查询，就会在执行计划的`Extra`列中显示`Using filesort`提示

- `Using temporary`

  如果查询中使用到了内部的临时表，在执行计划的`Extra`列将会显示`Using temporary`提示

  特别的，会发现下面的查询语句即使没有使用`ORDER BY`子句排序，执行计划中的`extra`信息中仍然有`Using filesort`

  ![image-20220104145901156](https://tva1.sinaimg.cn/large/008i3skNgy1gy1neacgeej31l4068wg5.jpg)

  这是由于**`MySQL`会在包含`GROUP BY`子句的查询中默认添加上`ORDER BY`子句**，也就是说上述查询语句实际上与下面这个语句等价

  ```sql
  SELECT common_field, COUNT(*) AS amount FROM s1 GROUP BY common_field ORDER BY common_field;
  ```

  如果不想为包含`GROUP BY`子句的查询进行排序，需要显式地写上`ORDER BY NULL`，这样就不会有`Using filesort`了

  ![image-20220104150052252](https://tva1.sinaimg.cn/large/008i3skNgy1gy1ng7m5iaj31fs06omz7.jpg)

  > 执行计划中出现`Using temporary`并不是一个好的征兆，因为建立与维护临时表要付出很大成本的，所以我们最好能使用索引来替代掉使用临时表

- `Start temporary, End temporary`

  查询优化器会优先尝试将`IN`子查询转换成`semi-join`，而`semi-join`又有好多种执行策略，当执行策略为`DuplicateWeedout`时，也就是通过建立临时表来实现为外层查询中的记录进行去重操作时，驱动表查询执行计划的`Extra`列将显示`Start temporary`提示，被驱动表查询执行计划的`Extra`列将显示`End temporary`提示

- `LooseScan`

  在将`In`子查询转为`semi-join`时，如果采用的是`LooseScan`执行策略，则在驱动表执行计划的`Extra`列就是显示`LooseScan`提示

- `FirstMatch(tbl_name)`

  在将`In`子查询转为`semi-join`时，如果采用的是`FirstMatch`执行策略，则在被驱动表执行计划的`Extra`列就是显示`FirstMatch(tbl_name)`提示



### Json格式的执行计划

在`EXPLAIN`单词和真正的查询语句中间加上`FORMAT=JSON`即可查看某个执行计划花费的成本的方式

对于语句

```sql
EXPLAIN FORMAT=JSON SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s1.common_field = 'a'\G
```

![image-20220104150948543](https://tva1.sinaimg.cn/large/008i3skNgy1gy1npifx0rj30ce04qwep.jpg)

- `read_cost`

  `read_cost`由两部分组成：

  - IO成本
  - 检测`rows ✕（1-filter）`条记录的CPU成本

  >  `rows`和`filter`都是我们前边介绍执行计划的输出列，在JSON格式的执行计划中，`rows`相当于`rows_examined_per_scan`，filtered名称不变。

- `eval_cost`

  检测 `rows × filter`条记录的成本。

- `prefix_cost`

  即单独查询当前表的成本，也就是`read_cost + eval_cost`

- `data_read_per_join`

  表示在此次查询中需要读取的数据量

> 如果当前表是被驱动表，可能会被读取多次，那么其`read_cost`和`eval_cost`是访问多次表后累加起来的值，`prefix_cost`的值代表的是整个连接查询预计的成本，也就是单次查询驱动表和多次查询被驱动表后成本的和



## InnoDB-Buffer Pool

在MySQL服务器启动时就向操作系统申请了一片连续的内存，叫做Buffer Pool（缓冲池）



### 内部组成

Buffer Pool中默认的缓存页大小和在磁盘上默认的页大小是一样的，都是16KB。InnoDB为每一个缓存也都创建了一些所谓的控制信息，这些控制信息包括该页所属的表空间编号、页号、缓存页在Buffer Pool中的地址、链表节点信息、一些锁信息以及LSN信息。

每个缓存页对应的控制信息占用的内存大小是相同的，每个页对应的控制信息占用的一块内存称为控制块，控制块和缓存页是一一对应的，都被存放到Buffer Pool中，其中控制块在Buffer Pool前面，缓存页在后面

![image-20220104162136741](https://tva1.sinaimg.cn/large/008i3skNgy1gy1ps81rhij30q607xgm6.jpg)

> 碎片即Buffer Pool中剩余的因为不够分配一对控制块和缓存页而空闲的内存空间



### free链表

申请完Buffer Pool所需内存后，就要进行初始化工作，就是把其划分为若干对控制块和缓存页，这就需要一个free链表来标志Buffer Pool中哪些缓存页是空闲的

![image-20220104163443748](https://tva1.sinaimg.cn/large/008i3skNgy1gy1q5v91axj30rj0gadh9.jpg)

为了方便管理free链表，还需要申请一块额外的内存空间（并不包含在Buffer Pool中）作为free链表的基节点，记录着链表的头尾节点地址和节点数量等信息



### 缓存页的hash处理

当需要访问某个页中的数据时，如果该页在Buffer Pool中，就直接使用即可，如果在磁盘中，就需要先把其加载到Buffer Pool中缓存后使用

**至于如何定位一个页呢？**

InnoDB会以表空间号+页号作为key，缓存页作为value来创建一个哈希表，因此需要访问一个页面时，只要先根据其表空间号+页号到哈希表中查看是否有哦对应缓存页，如果没有的话就从`free链表`中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。



### flush链表

如果我们修改了`Buffer Pool`中某个缓存页的数据，那它就和磁盘上的页不一致了，这样的缓存页也被称为`脏页`。当然，最简单的做法就是每发生一次修改就立即同步到磁盘上对应的页上，但是频繁的往磁盘中写数据会严重的影响程序的性能（毕竟磁盘慢的像乌龟一样）。所以每次修改缓存页后，我们并不着急立即把修改同步到磁盘上，而是在未来的某个时间点进行同步。脏页连接起来形成的链表就是flush链表

![image_1d1589dpqmt5v1849s7614nu23.png-133.5kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/2/1693e86e2ec4572a~tplv-t2oaga2asx-watermark.awebp)



### LRU链表

Buffer Pool对应的内存大小是有限的，因此当其没有多余的空闲缓存页时就需要把一些缓存页调出Buffer Pool，InnoDB采用LRU（最近最久未使用）页面置换算法。

因此需要维护一个LRU链表，需要调出的页面就在LRU链表中



#### 简单的LRU链表

当访问一个页时：

- 如果该页不在`Buffer Pool`中，在把该页从磁盘加载到`Buffer Pool`中的缓存页时，就把该缓存页对应的`控制块`作为节点塞到`LRU链表`的头部。
- 如果该页已经缓存在`Buffer Pool`中，则直接把该页对应的`控制块`移动到`LRU链表`的头部。

> 也就是说，每当使用到一个缓存也时，就把其调整到LRU链表头部，这样LRU链表尾部就是最近最久未使用的缓存页



#### 划分区域的LRU链表

简单的LRU链表存在两个问题：

1. 不适用预读：加载到`Buffer Pool`中的页不一定被用到。
2. 全表扫描引起的大量缓存页换出：如果非常多的使用频率偏低的页被同时加载到`Buffer Pool`时，可能会把那些使用频率非常高的页从`Buffer Pool`中淘汰掉。



**先说说预读是什么：**

InnoDB提供了预读服务，即InnoDB认为执行当前的请求之后可能会读取到哪些页面，就把它们预先加载到Buffer Pool中。根据触发方式不同，预读可以分为以下两种：

1. 线性预读

   InnoDB中提供了一个系统变量`innodb_read_ahead_threshold`（默认为56），如果顺序访问了某个区的页面超过了这个系统变量的值，就会触发一次异步读取下一区中全部的页面到Buffer Pool中的请求

   > 注意`异步`读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行

2. 随机预读

   InnoDB中提供了一个系统变量`innodb_random_read_ahead`（默认为13），如果Buffer Pool中已经缓存了某个区的该系统变量的值个连续的页面，无论这些页面是不是顺序读取的，都会触发一次异步读取本区中所有的页面到Buffer Pool中的请求

   随机预读的功能默认关闭

`预读`本来是个好事儿，如果预读到`Buffer Pool`中的页成功的被使用到，那就可以极大的提高语句执行的效率。可是如果用不到呢？这些预读的页都会放到`LRU`链表的头部，但是如果此时`Buffer Pool`的容量不太大而且很多预读的页面都没有用到的话，这就会导致处在`LRU链表`尾部的一些缓存页会很快的被淘汰掉，也就是所谓的`劣币驱逐良币`，会大大降低缓存命中率。



**再分析一下全表扫描：**

全表扫描意味着要访问该表所在的所有页，该表中的记录越多，占用的页也越多。这样就可能会出现全表扫描时一次加载大量的页到Buffer Pool中，导致之前缓存的页被全部置换出去，之后的查询语句在执行时需要重新加载页面，从而大大降低了缓存命中率



为了解决简单LRU链表存在的问题，InnoDB把LRU链表按照一定比例分为了两个区：

- 一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做`热数据`，或者称`young区域`，靠近链表头部。
- 另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做`冷数据`，或者称`old区域`，靠近链表尾部。

![image_1d15fb53d2lf13ovglg1rnv1h2n2g.png-116.5kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/2/1693e86e2a3fffa3~tplv-t2oaga2asx-watermark.awebp)

- 针对预读的页面可能不进行后续访问情况的优化

  当磁盘上的某个页面在初次加载到`Buffer Pool`中的某个缓存页时，该缓存页对应的控制块会被放到`old`区域的头部。这样针对预读到`Buffer Pool`却不进行后续访问的页面就会被逐渐从`old`区域逐出，而不会影响`young`区中被使用比较频繁的缓存页

- 针对全表扫描，短时间内访问大量使用频率非常低的页面情况的优化

  在对某个处在`old`区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该页面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。这个时间间隔是由系统变量`innodb_old_blocks_time`控制的，默认为`1000ms`



#### 更进一步优化LRU链表

对于young区域的缓存页来说，每次访问一个缓存页都要把它移动到LRU链表的头部，并且由于在young区的缓存页大部分是热点数据，是可能被经常访问的，频繁的对LRU链表进行节点移动操作是一个额外的开销。

为了解决这个问题其实我们还可以提出一些优化策略，比如只有被访问的缓存页位于`young`区域的`1/4`的后边，才会被移动到`LRU链表`头部，这样就可以降低调整`LRU链表`的频率，从而提升性能（也就是说如果某个缓存页对应的节点在`young`区域的`1/4`中，再次访问该缓存页时也不会将其移动到`LRU`链表头部）。



### 刷新脏页到磁盘

后台有专门的线程每隔一段时间负责把脏页刷新到磁盘，这样可以不影响用户线程处理正常的请求。主要有两种刷新路径：

- 从`LRU链表`的冷数据中刷新一部分页面到磁盘。

  后台线程会定时从`LRU链表`尾部开始扫描一些页面，扫描的页面数量可以通过系统变量`innodb_lru_scan_depth`来指定，如果从里边儿发现脏页，会把它们刷新到磁盘。这种刷新页面的方式被称之为`BUF_FLUSH_LRU`。

- 从`flush链表`中刷新一部分页面到磁盘。

  后台线程也会定时从`flush链表`中刷新一部分页面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新页面的方式被称之为`BUF_FLUSH_LIST`。

有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到`Buffer Pool`时没有可用的缓存页，这时就会尝试看看`LRU链表`尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将`LRU链表`尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为`BUF_FLUSH_SINGLE_PAGE`。

当然，有时候系统特别繁忙时，也可能出现用户线程批量的从`flush链表`中刷新脏页的情况，很显然在处理用户请求过程中去刷新脏页是一种严重降低处理速度的行为（毕竟磁盘的速度慢的要死），这属于一种迫不得已的情况



### innodb_buffer_pool_chunk_size

在`MySQL 5.7.5`之前，`Buffer Pool`的大小只能在服务器启动时通过配置`innodb_buffer_pool_size`启动参数来调整大小，在服务器运行过程中是不允许调整该值的。

不过在`MySQL 5.7.5`之后，支持了在服务器运行过程中调整`Buffer Pool`大小的功能。但是这样的话就存在一个问题：每次重新调整`Buffer Pool`大小时，都需要重新向操作系统申请一块连续的内存空间，然后将旧的`Buffer Pool`中的内容复制到这一块新的内存空间中，这是一个极为耗时的操作。

为了解决这个问题，不再一次性为Buffer Pool向操作系统申请一大片连续的内存空间，而是以一个所谓的chunk为单位向操作系统申请空间。也就是说一个Buffer Pool实例实际上是由若干个chunk组成的，一个chunk就代表一片连续的内存空间

![image_1d15r7te41q58egj1b4plh615ug7r.png-125.5kB](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/3/2/1693e86e2a5de8f2~tplv-t2oaga2asx-watermark.awebp)

> 在多线程环境下，访问`Buffer Pool`中的各种链表都需要加锁处理啥的，在`Buffer Pool`特别大而且多线程并发访问特别高的情况下，单一的`Buffer Pool`可能会影响请求的处理速度。所以在`Buffer Pool`特别大的时候，我们可以把它们拆分成若干个小的`Buffer Pool`，每个`Buffer Pool`都称为一个`实例`，它们都是独立的，独立的去申请内存空间，独立的管理各种链表等，所以在多线程并发访问时并不会相互影响，从而提高并发处理能力。
>
> 通过修改`innodb_buffer_pool_instances`的值来改变`Buffer Pool`实例的值

正是因为发明了这个`chunk`的概念，我们在服务器运行期间调整`Buffer Pool`的大小时就是以`chunk`为单位增加或者删除内存空间，而不需要重新向操作系统申请一片大的内存，然后进行缓存页的复制。这个所谓的`chunk`的大小是我们在启动操作`MySQL`服务器时通过`innodb_buffer_pool_chunk_size`启动参数指定的，它的默认值是`134217728`，也就是`128M`。不过需要注意的是，`innodb_buffer_pool_chunk_size`的值只能在服务器启动时指定，在服务器运行过程中是不可以修改的。

> **为什么不允许在服务器运行过程中修改`innodb_buffer_pool_chunk_size`的值？**
>
> 还不是因为`innodb_buffer_pool_chunk_size`的值代表`InnoDB`向操作系统申请的一片连续的内存空间的大小，如果你在服务器运行过程中修改了该值，就意味着要重新向操作系统申请连续的内存空间并且将原先的缓存页和它们对应的控制块复制到这个新的内存空间中，这是十分耗时的操作！ 另外，这个`innodb_buffer_pool_chunk_size`的值并不包含缓存页对应的控制块的内存空间大小，所以实际上`InnoDB`向操作系统申请连续内存空间时，每个`chunk`的大小要比`innodb_buffer_pool_chunk_size`的值大一些，约5%。





