# 计算机网络

![image-20210914165743406](https://tva1.sinaimg.cn/large/008i3skNgy1gug9f9n4kdj60kj0a575d02.jpg)







## 应用层

应用层是网络应用程序及它们的应用层协议存留的地方。



### HTTP

#### 特点

- 支持C/S模式

- 简单快速

  客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。

- 灵活

  HTTP允许传输任意类型的数据对象。正在传输的类型由`Content-Type`（HTTP包中用来表示内容类型的标识）加以标记。

- 无连接

  无连接的含义是限制每次连接只处理一个请求：服务器处理完客户的请求，并收到客户的应答后，就断开连接。

- 无状态

  无状态是指协议对于事务处理没有记忆能力，即每个请求都是独立的，即使是开启了`Keep-Alive`也不会对此造成影响。

  - 优点：解放了服务器，每一次请求“点到为止”。不会造成不必要的连接占用。并且在服务器不需要先前信息时应答较快
  - 缺点：在服务器需要先前信息时需要进行重传，导致传输大量重复的内容信息



#### 报文格式

```c
// 请求报文
<method> <request-URL> <version>
<headers>
// HTTP报文的请求头和主体分隔符是CRLF
CRLF
<entity-body>

// 响应报文
<version> <status> <reason-phrass>
<headers>
CRLF
<entity-body>
```

- <method> 方法

  客户端希望服务器对资源执行的动作，是一个单独的词，常用的HTTP方法如下：

  |  方法   |                        描述                        | 是否包含主体 |
  | :-----: | :------------------------------------------------: | :----------: |
  |   GET   |                从服务器获取一份文档                |      ×       |
  |  HEAD   |              只从服务器获取文档的首部              |      ×       |
  |  POST   |             向服务器发送需要处理的数据             |      √       |
  |   PUT   |           将请求的主体部分存储在服务器上           |      √       |
  |  TRACE  | 对可能经过代理服务器传送到服务器上去的报文进行追踪 |      ×       |
  | OPTIONS |           决定可以在服务器上执行哪些方法           |      ×       |
  | DELETE  |               从服务器上删除一份文档               |      ×       |

- <request-URL> 请求URL

  命名了所请求资源，或者URL路径组件的完整URL。如果直接与服务器进行对话，只要URL的路径组件是资源的绝对路径，通常就不会有什么问题

- <version> 版本

  报文使用的HTTP版本

  ```c
  HTTP/<主要版本号>.<次要版本号>
  ```

- <status> 状态码

  描述了请求过程中所发生的情况

  | 整体范围 | 已定义范围 |    分类    |
  | :------: | :--------: | :--------: |
  | 100~199  |  100~101   |  信息提示  |
  | 200~299  |  200~206   |    成功    |
  | 300~399  |  300~305   |   重定向   |
  | 400~499  |  400~415   | 客户端错误 |
  | 500~599  |  500~505   | 服务端错误 |

  | 状态码 |          原因短语          |                           中文描述                           |
  | :----: | :------------------------: | :----------------------------------------------------------: |
  |  100   |          Continue          |                   继续。客户端应继续其请求                   |
  |  101   |    Switching Protocols     | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
  |  200   |             OK             |               请求成功。一般用于GET与POST请求                |
  |  201   |          Created           |               已创建。成功请求并创建了新的资源               |
  |  202   |          Accepted          |              已接受。已经接受请求，但未处理完成              |
  |  400   |        Bad Request         |             客户端请求的语法错误，服务器无法理解             |
  |  401   |        Unauthorized        |                    请求要求用户的身份认证                    |
  |  403   |         Forbidden          |        服务器理解请求客户端的请求，但是拒绝执行此请求        |
  |  404   |         Not Found          | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
  |  408   |      Request Time-out      |           服务器等待客户端发送的请求时间过长，超时           |
  |  500   |   Internal Server Error    |                 服务器内部错误，无法完成请求                 |
  |  501   |      Not Implemented       |             服务器不支持请求的功能，无法完成请求             |
  |  505   | HTTP Version not supported |        服务器不支持请求的HTTP协议的版本，无法完成处理        |

- <reason-phrass> 原因短语

  原因短语和状态码总是成对出现的，是数字状态码的可读版本，包含行终止序列之前的所有文本，只对人类有意义。

  > 即如果状态码为200，即使原因短语表示不成功，该报文都会被当做成功指示处理

- <headers> 首部

  可以有零个或多个首部，每个首部都包含一个名字，后面跟着一个冒号（：），然后是一个可选的空格，然后是一个值，最后是一个CRLF。首部是由一个空行（CRLF）结束的，表示了首部列表的结束和实体主体部分的开始。

  |     通用首部      |                             描述                             |
  | :---------------: | :----------------------------------------------------------: |
  |    Connection     |       允许客户端和服务器指定与请求/响应连接有关的选项        |
  |       Date        |         提供日期和时间标志，说明报文是什么时间创建的         |
  |   MIME-Versiion   |                  给出了发送端使用的MIME版本                  |
  |      Trailer      | 如果报文采用了分块传输编码方式，就可以用这个首部列出位于报文拖挂（trailer）部分的首部集合 |
  | Transfer-Encoding |  告知接收端为了保证报文的可靠传输，对报文采用了什么编码方式  |
  |      Update       |         给出了发送端可能想要升级使用的额新版本或协议         |
  |        Via        |            显示了报文经过的中间结点（代理、网关）            |

- <entity-body> 实体的主体部分

  包含一个由任意数据组成的数据块，并不是所有的报文都包含实体的主体部分，有时报文只是以一个CRLF结束



#### 连接过程

1. 域名解析（DNS）
2. 建立TCP连接（HTTP是基于TCP的）
3. 浏览器向Web服务器发送HTTP请求
4. Web服务器响应HTTP请求
5. Web服务器关闭TCP连接



#### 保持HTTP状态

客户端与服务器进行动态交互的 Web 应用程序出现之后，HTTP 无状态的特性严重阻碍了这些应用程序的实现，毕竟交互是需要承前启后的，简单的购物车程序也要知道用户到底在之前选择了什么商品。于是，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 `Cookie`，而另一个则是 `Session`。



##### Cookie

`Cookie`实际上是一小段的文本信息（k-v格式）。客户端向服务器发起请求，如果服务器需要记录该用户的状态，就使用`response`向客户端浏览器颁发一个`Cookie`，**客户端浏览器会把这个`Cookie`保存起来**，再次请求时把`Cookie`一同提交给服务器，服务器检查该`Cookie`以此来辨认用户状态。

![img](https://upload-images.jianshu.io/upload_images/13949989-dcf024be2733e725.png?imageMogr2/auto-orient/strip|imageView2/2/w/400/format/webp)



###### Cookie属性项

|   属性项   |                             介绍                             |
| :--------: | :----------------------------------------------------------: |
| NAME=VALUE | 键值对，可以设置要保存的 Key/Value，注意这里的 NAME 不能和其他属性项的名字一样 |
|  Expires   |       过期时间，在设置的某个时间点后该 Cookie 就会失效       |
|   Domain   |                     生成该 Cookie 的域名                     |
|    Path    |   该 Cookie 是在当前的哪个路径下生成的，如 path=/wp-admin/   |
|   Secure   |  如果设置了这个属性，那么只会在 SSH 连接时才会回传该 Cookie  |

- Expires

  该属性用来设置`Cookie`的有效期。`Cookie`中的`maxAge`用来表示该属性，单位为秒。`Cookie`中通过`getMaxAge()`和`setMaxAge(int maxAge)`来读写该属性。`maxAge`有3种值，分别为正数，负数和0。

  ```java
  Cookie cookie = new Cookie("coookie",System.currentTimeMillis()+"");
  // 设置生命周期为MAX_VALUE，永久有效
  cookie.setMaxAge(Integer.MAX_VALUE);
  resp.addCookie(cookie);
  ```

  - `maxAge`为正数：`Cookie`将在`maxAge`秒后失效，浏览器会将该`Cookie`持久化，即写入到对应的`Cookie`文件中（每个浏览器存储的位置不一样）。无论客户关闭了浏览器还是电脑，只要还在`maxAge`秒之内，登录网站时该`Cookie`仍然有效
  - `maxAge`为负数：表示该`Cookie`只是一个临时`Cookie`，不会被持久化。仅在本浏览器窗口或者本窗口打开的子窗口中有效，关闭浏览器后该`Cookie`立即失效
  - `maxAge`为0：表示立即删除该`Cookie`

- 修改或删除Cookie

  `HttpServletResponse`只提供了`addCookie()`方法，没有提供删除方法。只需要新建一个除了`value`、`maxAge`之外的属性都相同的`Cookie`即可达到覆盖原来的`Cookie`的效果。

  从客户端读取`Cookie`时，包括`maxAge`在内的其他属性都是不可读的，也不会被提交。浏览器提交`Cookie`时只会提交`name`和`value`属性，**`maxAge`属性只被浏览器用来判断`Cookie`是否过期，而不能用服务端来判断。**

  > 我们无法在服务端通过`cookie.getMaxAge()`来判断该`cookie`是否过期，`maxAge`只是一个只读属性，值永远为-1。当`cookie`过期时，浏览器在与后台交互时会自动筛选过期`cookie`，过期了的cookie就不会被携带了。

- Cookie的域名

  `Cookie`是不可以跨域名的，隐私安全机制禁止网站非法获取其它网站的`Cookie`。正常情况下，同一个一级域名下的两个二级域名也不能交互使用`Cookie`（除非把两个`Cookie`的`domain`参数设置为一级域名）

  

##### Session

当客户端第一次访问服务器的时候，此时客户端的请求中不携带任何标识给服务器，所以此时服务器无法找到与之对应的session，所以会新建`session`对象，当服务器进行响应的时候，会把`sessionID`返回给客户端，并开辟一部分内存把`session`对象存储起来。下一次客户端请求时带上这个`sessionID`，服务器就会根据此ID寻找对应的`session`对象了。

![img](https://img2018.cnblogs.com/blog/885859/201909/885859-20190925225956556-1941547544.png)

- Cookie实现

  服务器把`sessionID`放到响应头的`Set-Cookie`中，以`K-V`形式（JSESSIONID=xxx）返回给客户端。如果`Cookie`被禁用了，用该方法实现的`Session`也无法使用

  注意：`Cookie`消失了并不代表`Session`消失了，`Cookie`消失了仅仅只是对应的`session`对象标识消失，而对应的`session`仍然保存在服务器，但已经成为了报废数据等待`GC`回收

- URL重写实现

  就是把`sessionID`附加在URL路径后：

  - 作为URL路径的附加信息
  - 作为查询字符串附加在URL后



|                  |                            Cookie                            |                           Session                            |
| :--------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|     存储位置     |                            客户端                            |                            服务器                            |
|     数据类型     |                     只能存储ASCII字符串                      |            采用哈希表方式，可以保存任意类型的数据            |
| 隐私政策和安全性 | 存储在客户端，对客户端可见，因此可能会产生伪装等安全问题。所以尽量不要用Cookie来存储敏感信息，或者对Cookie进行加密 |     存储在服务器，对客户端透明，不存在敏感信息泄露的风险     |
|      有效期      |                        根据maxAge而变                        |                         依赖于Cookie                         |
|    服务器压力    |       保存在客户端，不消耗服务器资源，适用于高并发场景       | 保存在服务器，每个用户都将产生一个会话，高并发场景下会消耗大量内存 |



#### HTTP1.0

- HTTP1.0默认创建短连接，规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。

  > HTTP的长连接和短连接，实际上就是TCP的长连接和短连接

- `Host`字段可以为空，因此WEB浏览器无法使用主机头名来明确表示要访问服务器上的哪个WEB站点，这样就无法使用WEB服务器在同一个IP地址和端口号上配置多个虚拟WEB站点。

  > 当时没有想到会有多个机器使用同一个IP的情况，认为一个IP地址上只会有一个`Host`主机

- 不支持断点续传，即发生断连后只能重新下载完整的包



##### 存在问题

###### 连接无法复用

HTTP1.0只支持短连接，每次请求和响应都要重新建立连接。TCP的三次握手和四次挥手是一个非常耗费时间的过程，并且会严重影响客户机和服务器的性能



###### HOLB（Head of Line Blocking，队头阻塞）

简单来说，就是单个慢对象阻止了后续的其他对象前进

![img](https://pic1.zhimg.com/80/v2-55b205a99a18fe414cf5f93860f36bb0_720w.jpg)

如上图，js文件和css文件分成了三个TCP包传输。在这种情况下，当js文件的传输响应后，css文件的头部（红色部分）和内容（紫色部分）只是附加在js文件之后，接受者使用HTTP首部的`Content-Length`来知道每个响应的结束为止和开始位置，从而区分两个不同的响应。

假设js文件比css文件大得多，在下载整个js文件之前，css必须等待，尽管它要小得多，其实可以更早的被接受以使用。但由于此时js文件排在队头，css文件只能等待js被下载完毕后才能被下载从而使用。这就是队头阻塞问题。

> 这个问题在HTTP1.0和HTTP1.1中都有出现，直到HTTP2.0才得以解决



**是否可以利用多路复用来解决这个问题？**

多路复用即把两个文件划分为小块，交错的进行传输，如下图所示

<img src="https://pic4.zhimg.com/80/v2-ab3d635cd31de6073cb5981c6a069b6f_720w.jpg" alt="img" style="zoom:67%;" />

答案是**不可以**的。HTTP是一个纯文本协议，这意味着它只在有效荷载（payload）的前面附加头部，并通过头部来区分不同的报文，它不会进一步区分单个资源与其他资源。

像上图的情况，客户端分析到第一个首部，得知期望后面有1000个字节的有效荷载（第一个红色块），因此它把后面的1000个字节都解释为js的一部分，即使中间存在着css文件首部（第二个红色块）和css内容（第一个紫色块），因为这两个文件的有效荷载和首部都是纯文本。更为糟糕的是，它在读取1000个字节后会停止（假设此时已经读取到第二个绿色块部分）。此时，它看不到有效的新报头，因此会删除TCP数据包3的其余部分，然后把浏览器把它所认为的js内容传递给js解析器，这注定是失败的。



这是 HTTP协议设计方式的一个基础限制。如果只有一个TCP 连接，那么在切换到发送新资源之前，必须**完整地**传输资源响应。如果前面的资源创建缓慢（例如，从数据库查询动态生成的`index.html`）或者，如上所述，如果前面的资源很大。这些问题可能会引起队头阻塞问题。浏览器为每个页面打开多个并行的TCP连接就是尝试解决这个队头阻塞问题，但建立TCP连接是十分昂贵的，并且不能随着时间的推移扩展的太好。



##### 请求方法

HTTP1.0中定义了三种请求方法。以下三个方法都是简单方法

###### GET

- GET方法通常用于请求服务器发送某个资源，是安全和幂等的

  > - 安全：该操作用于获取信息而非修改信息，不会影响到资源的状态
  > - 幂等：对同一个URL的多次请求应该返回同样的结果

- 在URL后面拼接参数，只能以文本的形式传递参数

  - `RFC2616`要求长度不超过2048
  - `RFC7230`建议小于8000
  - 建议不超过250，超过2000会有部分基础设施（浏览器、CDN等）不兼容
  - 超过长度返回414

- 传递数据量小

- 安全性低，会将信息显示在地址栏

- 速度快，通常用于对安全性要求不高的要求

- 会被浏览器主动`cache`

- ==产生了一个TCP数据包==：浏览器会把`http header`和`data`一并发送出去，服务器响应`200`（返回数据）



###### POST

- 向服务器提交数据，比如完成表单数据的提交，将数据提交给服务器处理

- 非幂等

- 相对于GET安全性高一些（抓包也会抓到POST的内容）

- 传递数据量大，对数据长度没有要求

- 请求不会被缓存，也不会保留在浏览器的历史记录中

- 报文长度通过`content-length`指明

- 可以基于1.1以后版本实现分块传输

- ==产生了两个TCP数据包==：浏览器先发送`header`，服务器响应`100 continue`，浏览器再发送`data`，服务器响应`200 OK`（返回数据）

  > 在网络环境好的情况下，发一次数据包和发两次数据包的时间差异几乎可以忽略不计；而在网络环境差的情况下，两次发送在验证数据包完整性上有非常大的优点。（但不是所有浏览器POST请求都发送两次数据包，火狐就只发送一次）



###### HEAD

- 它与`GET`方法几乎是一样的，对于`HEAD`请求的回应部分来说，它的`HTTP`头部中包含的信息与通过`GET`请求所得到的信息是相同的。利用这个方法，不必传输整个资源内容，就可以得到`Request-URI`所标识的资源的信息。
- 只请求资源的首部
- 用于测试超链接的有效性，是否可以访问，最近是否更新；下载文件之前判断文件大小和文件信息



#### HTTP1.1

- 为了克服HTTP1.0连接不可复用的缺陷，HTTP1.1支持持久连接（默认使用带流水线的持久连接），**增加了`Connection`字段**，通过设置`Keep-Alive`保持HTTP连接不断开，避免每次客户端与服务器请求都要重复建立新的TCP连接，提高了网络的利用率。客户端可以通过设置`Connection:false`来告知服务器关闭连接

  > 但，HTTP/1.0的`Proxy`不支持`Connection`头域，为了不让它们转发可能误导接收者的头域，协议规定所有出现在`Connection`头域中的头域名都将被忽略（这个其实就是前面保持`HTTP`状态中提及的`Keep-Alive`的局限性）

- 如果Host字段为空，服务器会认为是`400 Bad Request`

  > WEB浏览器可以使用主机头名来明确表示要访问服务器上的哪个WEB站点，这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点。

- 支持断点续传：在请求消息中引入了`range`头域，它允许只请求资源的某个部分。在响应信息中的`Content-Range`头域声明了返回的这部分对象的偏移值和长度。**响应码为206，防止`Cache`将响应认为是完整的一个对象**

- 增加流水线操作以降低通信延迟

- 引入额外的缓存控制机制

- 支持响应分块



##### 请求方法

HTTP1.1新增了六种请求方法

###### OPTIONS

- 用于检测服务器支持哪些HTTP方法

- 用来检查服务器的性能。例如：AJAX进行跨域请求时的预检，需要向另外一个域名的资源发送一个`HTTP OPTIONS`请求头，用以判断实际发送的请求是否安全

- 在CORS（跨源资源共享）中，可以使用`OPTIONS`方法发起一个预检请求，以检测实际请求是否可以被服务器所接受。
  - `Access-Control-Allow-Origin`：在响应头中指定响应的资源允许被这些`origin`共享

  - `Access-Control-Allow-Methods`：在对`OPTIONS`预检请求的应答中明确了客户端所要访问的资源允许使用的方法列表

  - `Access-Control-Allow-Headers`：指明了实际请求中允许携带的首部字段

  - `Access-Control-Allow-Credentials`：表示是否可以将对请求的响应暴露给页面

    > 当作为对预检请求的响应的一部分时，这能表示是否真正的请求可以使用`credentials`（凭证，即`cookie`或者TLS客户端证书等）。注意简单的GET请求没有预检，所以若一个对资源的请求带了`credentials`，如果这个响应头没有随资源返回，响应就会被浏览器忽视，不会返回到web内容

  - `Access-Control-Expose-Headers`：指示哪些报头可以公开为通过列出他们的名字的响应的一部分

    > CORS请求时，`XMLHttpRequest`对象的`getResponseHeader()`方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。 如果想拿到其他字段，就必须在`Access-Control-Expose-Headers`里面指定

  - `Access-Control-Max-Age`：指定了预检请求的结果能被缓存多久



###### PUT

- 用于替换目标资源，要求提供的一定是一个完整的资源对象（如果没有提供则缺少的字段会被置空）
- 幂等性



###### PATCH

- 用于局部更新资源



###### DELETE

- 用于删除资源
- 幂等
- 客户端无法保证删除操作一定会被执行，因为HTTP规范允许服务器在不通知客户端的情况下撤销请求



###### TRACE

- 使服务器原样返回任意客户端请求的任何内容

  > TRACE请求会在目的服务器端发起一个“环回”诊断。行程最后一站的服务器会弹回一条TRACE响应，并在响应主体中携带它收到的原始请求报文

- 客户端可以查看在所有中间HTTP应用程序组成的请求/响应链上原始报文是否被修改过



###### CONNECT

- 将服务器作为代理，让服务器代替用户去访问其他网页（翻墙），之后将数据返回给用户



##### 管道化（pipeline）——假并行传输

![image-20211028221535993](https://tva1.sinaimg.cn/large/008i3skNgy1gvvdvm4jp6j30da07i3yq.jpg)

在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，**但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容**，这样也显著地减少了整个下载过程所需要的时间。

也就是说，HTTP管道化可以让我们把FIFO队列从客户端（请求队列）迁移到服务端（响应队列）

但是，HTTP1.1仍然无法解决HOLB问题，同时管道化技术很多浏览器基本不支持



##### 浏览器优化策略——真并行传输

浏览器允许打开多个TCP连接，在不同的TCP连接上同时发送请求，以达到真正的并行传输



##### 缓存处理

###### 强缓存

强缓存，是浏览器优先命中的缓存，**速度最快**。当我们在状态码后面看到 (from memory disk) 时，就表示浏览器从内存中读取了缓存，当进程结束后，也就是 tab 关闭以后，内存里的数据也将不复存在。**只有当强缓存不被命中的时候，才会进行协商缓存的查找。**

- **Pargma**

  在 HTTP 1.0 时代，使用的是 `Pragma: no-cache` 字段来进行缓存的判断，由于现在已经步入 1.1 时代，更多的由 `Cache-Control` 控制，所以建议只在需要兼容 HTTP/1.0 客户端的场合下应用 Pragma 首部。

- **Expires**

  该字段表示的是，设定的时间为缓存的有效时间，当发生请求时，浏览器将会把 `Expires` 的值与本地时间进行对比，如果本地时间**小于**设置的时间，则读取缓存。

  因为对比的是本地时间，所以也存在着弊端：当本地时间与服务端时间不一致时，无法达到预期的资源读取结果。

  > - 当 `Expires` 的字段设置为 **0** 时，代表该资源已经过期
  > - 如果在 `Cache-Control` 响应头设置了 "max-age" 或者 "s-max-age" 指令，那么 `Expires` 头会被忽略。

- **Cache-Control**

  由于 `Expires` 的局限性， `Cache-Control` 登场了，下面说明几个常用的字段

  - no-mmstore：缓存不应存储有关客户端请求或服务器响应的任何内容。
  - no-cache：在发布缓存副本之前，强制要求缓存把请求提交给原始服务器进行验证。
  - max-age：相对过期时间，单位为秒(s)，告知服务器资源在多少以内是有效的，无需向服务器请求（指的是从当前时间开始计算的秒数）

  > 如果将 `Cache-Control` 设置为 `no-cache` 后，那么服务器将去验证 `Last-Modeified` 、 `ETag` 等字段，而 `no-store` 的作用则是不进行资源的缓存



###### 协商缓存

当浏览器没有命中强缓存后，便会命中协商缓存，协商缓存由以下几个 HTTP 字段控制：

- **Last-Modified——比较修改时间**

  ==服务端将资源传送给客户端的时候，会将资源最后的修改时间以 `Last-Modified: GMT` 的形式加在实体首部上返回。客户端接收到后会为此资源信息做上标记，等下次重新请求该资源的时候将会带上时间信息给服务器做检查，==若传递的值与服务器上的值一致，则返回 `304` ，表示文件没有被修改过，若时间不一致，则重新进行资源请求并返回 `200` 。

  - If-Modified-Since

    在客户端重新请求资源的时候，将会在请求头添加 `If-Modifed-Since: GMT` 字段传递给服务端，服务端接收后会与当前该文件的最后修改时间对比，如果时间一致则返回 `304` ，如果不一致则传递最新的资源并返回 `200` 状态码。

  - If-Unmodified-Since

    该值告诉服务器，若`Last-Modified`没有匹配上（资源在服务端的最后更新时间改变了），则应当返回`412(Precondition Failed) `状态码给客户端。 `Last-Modified` 存在一定问题，**如果在服务器上，一个资源被修改了，但其实际内容根本没发生改变，会因为`Last-Modified`时间匹配不上而返回了整个实体给客户端（即使客户端缓存里有个一模一样的资源）**。
    这个字段的一个典型应用场景就是断点续传：当下载的资源内容被改变时，不应该继续返回之前的资源内容。

- **ETag——比较文件内容是否修改**

  为了解决上面资源修改但是内容却没被修改，却依旧返回最新的资源的问题，ETag是一种比较好的解决方案, ==服务端通过某种算法（比如 MD5）计算出该**资源的唯一标致符**，在响应资源的时候，将会添加在实体首部字段连同资源一并返回给客户端。客户端接收到后将会保存该信息，并且在下一次请求中附上该信息给服务端，服务器只需要比较客户端传来的ETag跟自己服务器上该资源的ETag是否一致，就能很好地判断资源相对客户端而言是否被修改过了。==
  如果服务端检测到传递过来的值与服务器端的不一致，则返回最新的资源和 `200` 状态码，否则返回 `304` 告知客户端使用缓存文件

  - If-None-Match

    示例为 `If-None-Match: "5d8c72a5edda8d6a:3239"` 该字段告知服务端如果 ETag 没匹配上，需要重发资源数据，否则直接回送`304` 和响应报头即可。 当前各浏览器均是使用的该请求首部来向服务器传递保存的 ETag 值。

  - If-Match

    告诉服务器如果没有匹配到ETag，或者收到了 "*" 值而当前并没有该资源实体，则应当返回`412(Precondition Failed) `状态码给客户端。否则服务器直接忽略该字段。
    需要注意的是，如果资源是走分布式服务器（比如CDN）存储的情况，需要这些服务器上计算ETag唯一值的算法保持一致，才不会导致明明同一个文件，在服务器A和服务器B上生成的ETag却不一样。

  > 注：`If-None-Math` 的 优先级比 `If-Modified-Since` 的优先级更高，有了 `If-None-Match` 字段后 `If-Modified-Since` 字段将会被忽略



##### 跨源资源共享（CORS）

**跨源资源共享**（CORS）（或通俗地译为跨域资源共享）是一种基于HTTP头的机制，该机制通过允许服务器标示除了它自己以外的其它`origin`（域，协议和端口），这样浏览器可以访问加载这些资源。跨源资源共享还通过一种机制来检查服务器是否会允许要发送的真实请求，该机制通过浏览器发起一个到服务器托管的跨源资源的"预检"请求。在预检中，浏览器发送的头中标示有HTTP方法和真实请求中会用到的头。

CORS需要浏览器和服务器同时支持。整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。



浏览器将CORS请求分成两类：简单请求（`simple request`）和非简单请求（`not-so-simple request`）

###### 简单请求

1. 请求方法是以下三种方法之一：
   - HEAD
   - GET
   - POST

2. HTTP的头信息不超出以下几种字段：
   - Accept
   - Accept-Language
   - Content-Language
   - Last-Event-ID
   - Content-Type：只限于三个值`application/x-www-form-urlencoded`、`multipart/form-data`、`text/plain`

对于简单请求，浏览器直接发出CORS请求。即在头信息中增加一个`origin`字段，用来说明本次请求来自哪个源（协议+域名+端口），服务器根据这个值，决定是否同意这次请求：

- 如果服务器不同意，即origin指定的源不在许可范围内，服务器会返回一个正常的HTTP响应。如果浏览器发现，响应的头信息没有包含`Access-Control-Allow-Origin`字段，就知道出错了。（但是响应状态码可能是200，因此这种错误无法通过状态码识别）

- 如果`origin`指定的源在许可范围内。服务器返回的响应会多出几个头字段

  ```http
  // 必须字段
  Access-Control-Allow-Origin: 请求中指定的origin
  // 以下两个都是可选字段  
  Access-Control-Allow-Credentials: true
  Access-Control-Expose-Headers: xxx
  Content-Type: text/html; charset=utf-8
  ```



###### 非简单请求

非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为"预检"请求（`preflight`）。

浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的`XMLHttpRequest`请求，否则就报错。

```http
// 预检使用的请求方法是OPTIONS
OPTIONS /cors HTTP/1.1
Origin: 表示请求来自的源
// 用来列出浏览器的CORS请求会用到哪些HTTP方法
Access-Control-Request-Method: PUT
// 指定浏览器CORS请求会额外发送的头信息字段，用逗号分割
Access-Control-Request-Headers: X-Custom-Header
Host: api.alice.com
Accept-Language: en-US
Connection: keep-alive
User-Agent: Mozilla/5.0...
```

如果服务器允许跨域请求，就会做出如下响应

```http
HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:15:39 GMT
Server: Apache/2.0.61 (Unix)
// 表示该源可以请求数据，如果设置为*，则表示同意任意跨域请求
Access-Control-Allow-Origin: http://api.bob.com
// 访问该资源可使用的HTTP方法
Access-Control-Allow-Methods: GET, POST, PUT
// 实际请求中允许携带的头部字段
Access-Control-Allow-Headers: X-Custom-Header
Content-Type: text/html; charset=utf-8
Content-Encoding: gzip
Content-Length: 0
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: text/plain
```



##### 响应分块

在长连接请求中，无法继续使用之前的方法来判断数据是否完全发送完毕，但是我们**可以根据 `Content-Length` 的长度是否为 0 来判断数据是否传输完毕**，请求传输的内容与长度必须保持一致，否则内容将会被截断。并且这种方法有一个弊端，那就是当发送的内容足够大时，服务器都需要去计算 `content` 的长度，导致性能降低和速度变慢。另外，如果Content-Length长度与实际内容长度不一致会导致内容被截断

由于 `Content-Length` 存在的弊端，我们可以使用 `Transfer-Encoding` 配合 `Content-Encoding` 来告诉浏览器传输的结果， `Transfer-Encoding` 的常用值为 `chunked` ，而 `Content-Encoding` 的作用是告知浏览器采用何种编码（压缩），通常使用的是 `gzip` 。**对资源进行压缩后，再对内容进行分块传输**。当最后一个分块长度为0时，则代表数据传输完成。



##### 断点续传（分块传输）

断点续传：指的是在上传/下载时，将任务（一个文件或压缩包）人为的划分为几个部分，每一个部分采用一个线程进行上传/下载，如果碰到网络故障，可以从已经上传/下载的部分开始继续上传/下载未完成的部分，而没有必要从头开始上传/下载。可以节省时间，提高速度。

在请求头上增加`Range`头域，指定第一个字节和最后一个字节的位置，如：`Range:bytes=0-499`。收到带`Range`的请求后，服务器会在`Content-Range`头部返回当前接受的范围和文件总大小，如：`Content-Range:bytes 0-499/22400`

如果响应码为`HTTP/1.1 206 Partial Content`，说明这个响应不是完整对象，正在使用断点续传方式。如果响应码为`HTTP/1.1 200 OK`，说明已经传输完毕，不使用断点续传方式



#### HTTP2.0





#### HTTP3.0



### SMTP

SMTP提供了电子邮件报文的传输



### FTP

FTP提供了两个端系统之间的文件传送



### DNS



## 运输层



### TCP

#### 特点

- TCP是**面向连接**的运输层协议。应用程序在使用TCP协议之前必须先建立TCP连接，在传送数据完毕后必须释放已经建立的TCP连接

- 每一条TCP连接只能是**点对点**的

- TCP提供**可靠交付**的服务，通过TCP连接传送的数据，保证无差错、不丢失、不重复、按序到达

- TCP提供**全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据，TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据

- **面向字节流**（这个流指的是流入到进程或从进程流出的字节序列）

  > “面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块(大小不等)，但 TCP 把应用程序交下来的数据仅仅看成是一连串的`无结构的字节流`。TCP 并不知道所传送的字节流的含义
  >
  > TCP 不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系。例如，发送方应用程序交给发送方的 TCP 共10个数据块，但接收方的 TCP 可能只用了4个数据块就把收到的字节流交付上层的应用程序



#### TCP连接

TCP连接的端点叫做套接字（`socket`）或插口，根据RFC793的定义：端口号拼接到IP地址即构成了套接字

> 套接字socket = IP地址:端口号

每一条TCP连接唯一的被通信两端的两个端点（即两个套接字）所确定

> TCP连接::={socket1,socket2}{(IP1:port1),(IP2:port2)}



#### 报文结构

![img](http://image.honeypps.com/images/papers/2018/148.png)

##### 序列号

即seq，是本报文段发送的数据组的第一个字节的序号，比如本报文的序列号为x，数据部分有100字节，则下一个报文的序列号就是x+100，序列号确保了TCP传输的有序性。

##### 确认号

即ack，指明下一个期待收到的字节序号，表明该序号之前的所有数据已经正确无误的收到。确认号只有当ACK标志为1时才有效。比如建立连接时，SYN报文的ACK标志位为0，此时确认号无效

##### 首部长度

由于TCP首部包含一个长度可变的选项和填充部分，因此需要这个值来指定这个TCP报文的首部长度（字段大小为4bit，**长度单位为4字节**，因此首部最大长度为（2^4-1） * 4=60字节）

##### 标志位

- `URG`：指示报文中有紧急数据，应尽快传送
- `PSH`：为1表示是带有push标志的数据，只是接收方在接受到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队
- `RST`：TCP连接中出现严重差错，必须释放连接再重新建立连接
- `FIN`：发送端已完成数据传输，请求释放连接
- `SYN`：*Synchronize Sequence Number*，处于TCP连接建立过程
- `ACK`：确认序号标志，为1时表示确认号有效；为0表示报文中不含确认信息，忽略确认号字段

##### 滑动窗口大小

接收端用来告知发送端自己还有多少缓冲区可以接收数据，发送端根据这个值来发送数据，从而避免发送的数据过多接收端处理不过来，以此控制发送端发送数据的速率，从而达到流量控制（字段大小为16bit，因此窗口大小最大为2^16-1=65535）

##### 选项和填充部分

**TCP首部的固定长度为：(16+16+32+32+4+6+6*1+16+16+16)/8 = 20字节**。

因此选项和填充部分的最大长度为：60-20=40字节



#### 三次握手

![img](http://image.honeypps.com/images/papers/2018/149.png)

最开始双方都处于`CLOSED`状态，主动打开连接的为客户端，被动打开连接的为服务器。

1. 服务器进程创建传输控制块TCB，时刻准备接受客户进程的连接请求，进入`LISTEN`（监听）状态

2. 客户端进程也先创建传输控制块TCB。然后向服务器发送连接请求报文，进入`SYN-SENT`（同步已发送）状态

   > 连接请求报文：同步标志位`SYN=1`，选择一个初始序列号`seq=x`
   >
   > TCP规定，SYN报文段（即`SYN=1`的报文段）不能携带数据，但是需要消耗掉一个序号

3. 服务器收到连接请求报文后，如果同意连接，则发出确认报文，并进入`SYN-RCVD`（同步收到）状态

   > 连接确认报文：`SYN=1`，`ACK=1`，选择一个初始序列号`seq=y`，确认号`ack=x+1`
   >
   > TCP规定，ACK报文段（即`ACK=1`的报文段）也不能携带数据，但是也需要消耗一个序号

4. 客户端收到连接确认报文后，还要向服务器发出确认报文，并进入`ESTABLISGHED`（已建立连接）状态

   > 确认报文：`ACK=1`，序号`seq=x+1`，确认号`ack=y+1`

5. 服务端收到ACK报文后就进入`ESTABLISHED`状态，此后双方就可以开始通信了



##### 目的

**信息对等和防止超时**。防止超时导致脏连接。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，**两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。**如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。



#### 四次挥手

![img](http://image.honeypps.com/images/papers/2018/150.png)

最开始双方都处于`ESTABLISHED`（已建立连接）状态。由于 TCP 连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN报文来终止这个方向的连接。收到一个FIN报文只意味着这一方向上没有数据流动，一个 TCP 连接在收到一个FIN报文后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭
1. 客户端主动关闭，向服务器发送连接释放报文，并且**停止发送数据**，并进入`FIN-WAIT-1`（终止等待1）状态

   > 连接释放报文：`FIN=1`，序列号`seq=u`（等于前面已经传送过来的数据的最后一个字节的序号+1）
   >
   > TCP规定，FIN报文段（即`FIN=1`的报文段）即使不携带数据也要消耗一个序号

2. 服务器收到连接释放报文，就发出确认报文，并进入`CLOSE-WAIT`（关闭等待）状态。此时TCP服务器会通知高层的应用进程，**客户端向服务器方向的连接已经释放了，这时候处于半关闭状态**，即客户端已经没有数据要发送了，但是如果服务器发送数据，客户端仍然要接受（因为服务器向客户端方向的连接还没有释放）

   > 连接释放确认报文：`ACK=1`，确认号`ack=u+1`，序列号`seq=v`（同样也是前面已经传送过来的数据的最后一个字节的序号+1）

3. 客户端收到服务器的确认报文后，就进入`FIN-WAIT-2`（终止等待2）状态，等待服务器发送连接释放报文。在等待期间还需要接受服务器发送的最后的数据

4. 服务器发送完最后的数据后，就像客户端发送连接释放报文，并进入`LAST-ACK`（最后确认）状态

   > `FIN=1`，`ack=u+1`，因为与上次发送连接确认报文期间可能还发送了一些数据，因此假定序列号为`seq=w`

5. 客户端收到服务器的连接释放报文后就发出确认报文，并进入`TIME-WAIT`（时间等待）状态

   > `ACK=1`，`ack=w+1`，`seq=u+1`

6. 服务器只要收到了客户端发出的确认，立即进入`CLOSED`状态，**撤销TCB后就释放了TCP连接**。因此==服务器结束TCP连接的时间要比客户端早一些==

7. 等待*2MSL*（最长报文段寿命）时间后，当客户端撤销相应的TCB后才进入`CLOSED`（连接关闭）状态



##### 为什么客户端最后还要等待2MSL？

`MSL`（*Maximum Segment Lifetime*），TCP允许不同的实现可以设置不同的MSL值。

1. **保证客户端发送的最后一个ACK报文能够到达服务器**，因为这个ACK报文可能丢失。站在服务器的角度看来，我已经发送了`FIN+ACK`报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个`2MSL`时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。如果客户端收到服务端的`FIN+ACK`报文后，发送一个ACK给服务端之后就“自私”地立马进入`CLOSED`状态，可能会导致服务端无法确认收到最后的ACK指令，也就无法进入`CLOSED`状态，这是客户端不负责任的表现。
2. **防止失效请求**。防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个*2MSL*时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。



##### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？

建立连接的时候， 服务器在`LISTEN`状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，**己方ACK和FIN一般都会分开发送，从而导致多了一次**。



#### 保证可靠传输

|       三次握手       |              保证连接              |
| :------------------: | :--------------------------------: |
|        检验和        | 检测数据是否有差错和异常（无差错） |
|        序列号        |              有序送达              |
| 流量控制（滑动窗口） |   防止发送数据过多接收端无法处理   |
|       拥塞控制       |    避免网络中间堵塞，降低丢包率    |
|       ARQ协议        |             保证不丢失             |



#### 滑动窗口

TCP通过滑动窗口来实现流量控制，如果发送端和接收端对数据包处理速度不同，可以通过滑动窗口来控制发送端发送数据的速度来避免接收端接收缓存溢出。

 ![image-20211023131137625](https://tva1.sinaimg.cn/large/008i3skNgy1gvp622ud0bj60io06oaas02.jpg)

发送缓存内数据的状态有以下四种（假设发送窗口向右滑动）：

- 已发送并收到确认：对应滑动窗口左端数据
- 已发送未收到确认：对应滑动窗口中的数据（靠左边）
- 未发送但可发送：也是滑动窗口中的数据（靠右边）
- 未发送且不允许发送：对应滑动窗口右端数据

发送窗口后沿不可能后移，因为不可能撤销已经收到的确认；

发送窗口前沿一般是向前移动的，也可能会原地不动：

- 没有收到新的确认，对应通知的窗口大小也不变
- 收到了新的确认，但对应通知的窗口大小减小了

发送窗口前沿也可能会后移，但TCP强烈不赞成这样的做法，因为窗口中的数据可能已经发送了，但窗口前沿后移后该数据应该是不允许发送的状态，这样就可能会产生一些错误



##### 机制详解

<img src="https://pic1.zhimg.com/80/v2-78114aac276563cace34a2d792445478_720w.jpg" alt="img" style="zoom:67%;" />

发送端发送ABCD四个字节的数据，但只有CD两个数据到达了接收端

<img src="https://pic2.zhimg.com/80/v2-970b6c73c847a1c7dec9163928bc6ee1_720w.jpg" alt="img" style="zoom:67%;" />

由于接收端只收到了CD，没有收到AB，因此不会发出确认。一段时间后发送端由于没有收到确认，所以重传ABCD，这次所有数据都到达了接收端

<img src="https://pic1.zhimg.com/80/v2-f8f6eb45d641a944c047a411783a3f5c_720w.jpg" alt="img" style="zoom:67%;" />



数据A先到达接收端，因此接收端发出对A的确认，但中途丢失了。之后数据B也到达了接收端，至此接收端的ABCD数据都接收到了，根据**累计确认的原则（即如果这个字节前面的数据都完整的收到了，就只发出对这个字节的确认）**，发出对D的确认。

接收端收到重传的数据C、D，再次发出对D的ACK包

<img src="https://pic1.zhimg.com/80/v2-29f318791e084f23089da0e7ca565774_720w.jpg" alt="img" style="zoom:67%;" />

发送端收到了对D的确认，得知ABCD的数据都发送成功，因此窗口向前滑动（如果先收到了对A的ACK包，则只向前滑动一个，即滑动窗口中的数据为BCDE），发送EFGH数据

> ABCD为已发送并收到确认数据，I之后的为不可发送的数据



##### 缓存和窗口

![img](https://pic3.zhimg.com/80/v2-5e45f417d81c7a21d39325c593389eba_720w.jpg)

发送缓存用来暂时存放：

- 发送应用程序传送给对方TCP准备发送的数据
- TCP已发送但还未收到确认的数据（已经收到确认的数据应该从缓存中删除）

因此发送缓存和发送窗口的后沿是重合的，发送缓存的前沿比发送窗口的前沿要前。

> 发送应用程序必须控制写入缓存的速率，否则发送缓存会没有存放数据的空间

接收缓存用来暂时存放：

- 按序到达的、但尚未被接收应用程序读取的数据
- 未按序到达的数据

因此接收缓存和接收窗口的前沿是重合的，接收缓存的后沿比接收窗口的后沿要后。

收到的分组被检测出有差错（检验和）就直接丢弃。如果接收应用程序一直来不及读取收到的数据，接收缓存最终就会被填满，使得接收窗口减小到0，这样发送端就不会继续发送数据，直到接收端通知发送端其接收窗口恢复。

> 对于不按序到达的数据，TCP通常是先存放在接收窗口，等字节流中缺少的字节都收到后，再按序交付上层的应用进程



由于接收窗口可能变为0，这样就会造成接收端通知发送端窗口值为0，发送端停止发送数据，但之后接收端窗口值又恢复了，可以接收数据，但发送端不知道窗口值已经恢复了，一直不发送，接收端又一直等待发送数据的死锁现象。

为了避免这个情况，TCP 为每一个连接设有一个**持续计时器**(`persistence timer`)。只要 TCP 连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个**零窗口探测报文段**(仅携带1字节的数据)，而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了



##### 总结

1. 累计确认：如果当前字节前面的所有数据都收到了，则不会对前面的逐个数据都发送确认，只会发送对当前字节的ACK包。这样大大减小了传输开销
2. 滑动原则：只有收到了某个字节的ACK，窗口才会向前移动到这个字节的下一个字节
3. 滑动窗口提高了信道利用率：因为如果每发送一个字节的数据都要等待确认才能发送下一个字节的数据，信道利用率太低了。而采用滑动窗口机制则可以一次性发送多个数据，即使部分数据发送失败了，滑动窗口也有机会前移继续发送新的数据
4. 由于发送缓存和接收缓存都是有限的，滑动窗口能控制发送速率，避免发送数据过多接收端处理不过来导致接收缓存溢出的情况



#### ARQ协议

自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。



##### 停止等待ARQ

停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；

1. 无差错情况：

   发送方发送分组,接收方在规定时间内收到,并且回复确认。发送方收到确认后继续发送下一个分组

2. 超时重传：

   停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更快一些。这种自动重传方式常称为**自动重传请求 ARQ** 。

   另外在停止等待协议中**若收到重复分组，就丢弃该分组，但同时还要发送确认**。连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

3. 确认丢失：

   确认消息在传输过程丢失，发送方重传消息

   （1）接收方丢弃这个重复的M1消息，不向上层交付。

   （2）接收方再次向发送方发送确认消息。（不会认为已经发送过了，就不再发送）

4. 确认迟到：

   确认消息在传输过程中迟到，发送方在没有接受到确认消息时重传数据

   （1）发送方收到重复的确认后，直接丢弃。

   （2）接收方收到重复的数据后，也直接丢弃重复的数据。



##### 回退N帧ARQ（Go Back N,GBN）

GBN协议中，发送方在发完一个数据帧后，连续发送若干个数据帧，即使在连续发送过程中收到了接收方发来的应答帧，也可以继续发送。且发送方在每发送完一个数据帧时都要设置超时定时器。只要在所设置的超时时间内仍收到确认帧，就要重发相应的数据帧。如：当发送方发送了N个帧后，若发现该N帧的前一个帧在计时器超时后仍未返回其确认信息，则该帧被判为出错或丢失，此时发送方就不得不重新发送出错帧及其后的N帧。

1. 接收端丢弃从第一个没有收到的数据包开始的所有数据包
2. 累积确认，不会管中间的数据包
3. 接收窗口为1，从而保证了按序接收数据帧
4. 若采用n个比特对帧编号，则其发送窗口的尺寸应满足：1~2^n^-1。若发送窗口的尺寸大于2^n^-1，则会造成接受方无法分辨新帧和旧帧。（没有足够的编号给帧）
5. GBN协议的缺陷：累积确认机制导致要回退到前N帧进行重传，部分已经接受成功的数据帧也要进行重传，造成了浪费



##### 选择性重传ARQ(Selective Repeat,SR)

 SR协议是当接收方发现某帧出错后，其后继续送来的正确的帧虽然不能立即递交给接收方的高层，但接收方可收下来，存放在一个缓冲区中，同时要求发送方重新传送出错的那一帧。一旦收到重新传来的帧后，就可以原已存于缓冲区中的其余帧一并按正确的顺序递交高层。显然，**SR减少了浪费，但要求接收方有足够大的缓冲区空间**。

1. 发送端连续发送数据包，并且对每个数据包都设有一个计时器
2. 当在一定时间内没有收到某个数据包的ACK时，发送端只重新发送那个没有ACK的数据包
3. 假设序列号位数为k位，则接收窗口大小+发送窗口大小≤2^k^，即发送窗口和接收窗口大小范围为1~2^(k-1)^。防止因为接收方ACK丢失导致发送重发k号分组，而此时接收方滑到了新窗口，新窗口有新的k号分组（不是原来的，共用序号产生的），导致出错



##### 总结

如果从滑动窗口的观点来统一看待停等、后退N、选择重传三种协议，它们的差别仅仅在于各自窗口大小不同而已：

- 停等协议：发送窗口=1，接收窗口=1
- 后退N协议：发送窗口>1，接收窗口=1
- 选择重传协议：发送窗口>1，接收窗口>1



#### 拥塞控制

![image-20211023161659594](https://tva1.sinaimg.cn/large/008i3skNgy1gvpbex0l1yj60j507raau02.jpg)

- TCP采用基于窗口的方法进行拥塞控制，该方法属于闭环控制方法。发送方维持一个拥塞窗口`cwnd`（*congestion window*），其值取决于网络的拥塞程度，并且动态变化。

  > - `cwnd`的维护原则：只要网络没有出现拥塞拥塞窗口就再增大一些
  > - 没有按时收到应当到达的确认报文，即发生重传，就说明出现了网络拥塞

- 还有一个慢开始门限`ssthresh`



##### 重要阶段

###### 慢开始（slow-start）

目的：用来决定网络的负载能力或拥塞程度

主机开发发送数据报时，如果立即将大量的数据注入到网络中，可能会出现网络的拥塞。慢启动算法就是在主机刚开始发送数据报的时候先探测一下网络的状况，如果网络状况良好，发送方每发送一次文段都能正确的接受确认报文段。那么就从小到大的增加拥塞窗口的大小，即增加发送窗口的大小。

```c++
// 指数增长
cwnd = cwnd * 2
```



###### 拥塞避免（congestion avoidance）

目的：防止`cwnd`增加过快而导致网络拥塞（慢开始算法中`cwnd`是指数级增长），所以需要设置一个慢开始门限`ssthresh`状态变量：

- `cwnd < ssthresh`，使用慢开始算法
- `cwnd > ssthresh`，停止使用慢开始算法而改用拥塞避免算法
- `cwnd = ssthresh`，两个算法都可以使用

```c++
// 线性增长
cwnd = cwnd + 1
```



###### 快重传（fast retransmit）

###### ![image-20211023165830758](https://tva1.sinaimg.cn/large/008i3skNgy1gvpcm482uwj60g006amxl02.jpg)

快重传，就是使发送方尽快进行重传，而不是等到超时重传计时器到时才重传：

- 要求接收方不要等到自己发送数据时才进行捎带确认，而是要**立即发送确认**
- 即使收到了失序的报文段也要立即发出对已收到的报文段的**重复确认**
- 发送方一旦受到3个连续的重复确认（*3-ACK*），就将相应的报文段**立即重传**
- 对于个别丢失的报文段，发送方不会出现超时重传，也就不会误以为出现了拥塞（从而把`cwnd`置为1），使用快重传可以使整个网络的吞吐量提高约20%



###### 快恢复（fast recovery）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

发送方一旦收到了*3-ACK*，就知道现在只是丢失了个别报文段，而不是发生了网络拥塞，于是不启动慢开始算法，而是执行快恢复算法：

- 发送方将慢开始门限`ssthresh`值和拥塞窗口`cwnd`值调整为当前窗口的一半，并开始执行拥塞避免算法
- 也有的快恢复实现是把快恢复开始时的cwnd值再增大一些，为新的`ssthresh+3`
  - 既然发送方收到了3个重复的确认，就表明有3个数据已经离开了网络
  - 这3个报文段不再消耗网络资源而是停留在接收方的接收缓存中
  - 因此在网络中不是堆积了报文段，反而是减少了3个报文段，因此可以适当把`cwnd`扩大些



##### 算法

###### AIMD（加法增大乘法减小）

![image-20211023170202584](https://tva1.sinaimg.cn/large/008i3skNgy1gvpcpsc2jhj60ib08taaj02.jpg)

1. 乘法减小：无论在慢启动阶段还是在拥塞控制阶段，只要网络出现超时，就是将`ssthresh`置为`cwnd`的一半，cwnd置为1，然后开始执行慢启动算法（`cwnd<ssthresh`）。
2. 加法增大：当网络频发出现超时情况时，`ssthresh`就下降的很快，为了减少注入到网络中的分组数，而加法增大是指执行拥塞避免算法后，是拥塞窗口缓慢的增大，以防止网络过早出现拥塞。

==慢开始和拥塞避免结合起来就是`AIMD`算法==，是使用最广泛的算法。拥塞避免算法不能够完全的避免网络拥塞，通过控制拥塞窗口的大小只能使网络不易出现拥塞。这样做的目的能迅速的减少主机向网络中传输数据，使发生拥塞的路由器能够把队列中堆积的分组处理完毕。



###### TCP Tahoe协议

TCP Tahoe协议是TCP最早的TCP拥塞控制版本，==由慢开始、拥塞避免、快重传三者结合==



###### TCP Reno协议

Reno是应用最广泛且较为成熟的算法，基于Tahoe，==慢开始、拥塞避免、快重传、快恢复四者结合起来就是Reno==



###### TCP Vegas

经典的Vegas算法的基本思路：RTT增加，拥塞窗口减小；RTT减小，拥塞窗口变大

1. 重传机制：Vegas采用更精确的RTT估计值在以下两种情形下决定是否重发：

   - 当接受到重复ACK时，Vegas检查目前时间和记录的时间标签之差是否比超时值大，如果是，则立刻重发数据包，不必等第三个重复ACK。当接受重传数据包应答后，Vegas以3/4而不是1/2因子降低拥塞窗口。
   - 当接受到非重复的ACK时，如果它是重发之后的第一或是第二个确认，Vegas将再次检测数据发送时间间隔是否查过超时值。如果是，则重发。

2. 拥塞避免机制：Vegas通过比较实际吞吐量和期望吞吐量来调节用三个窗口的大小

   - 期望吞吐量：`Expected=cwmd/BaseRTT`

     > BaseRTT是所有观测来回响应时间的最小值，一般是建立连接后所发的第一个数据包的RTT

   - 实际吞吐量：`Actual=cwnd/RTT`

   - 计算差值：`diff=（Expected-Actual）*BaseRTT`

> 定义阈值a、b，当diff拥塞窗口增大，+1；当`diff>b`，拥塞窗口缩小，-1；当`a<=diff<=b`,拥塞窗口不变。通常`a=1，b=3`，意味着该连接至少保留一个包在队列中。



###### TCP BIC

BIC将拥塞控制视为一个**搜索问题**，具有良好的拓展性、友好性和公平性。但是丢失率<1e-8其发送速率的增长不如`HSTCP`、`STCP`快。

BIC包括两部分：二分搜索增加（*Binary Search increase*）+  加性增加（*additive increase*）

- **二分搜索**： TCP主动而非被动搜索一个处于丢包触发阈值的分组发送速率。

  > - `Wmin` 快速恢复借宿后的拥塞窗口大小值
  > - `Wmax` 快速恢复结束前的拥塞窗口大小值
  >
  > 首先设置目标窗口的大小为`Wmin`和`Wmax`的中间值。如果没有丢包，则当前窗口的值设为`Wmin`，拥塞窗口增加现在与`Wmin`差值的一半；如果丢包，当前窗口值为`Wmax`。

- **加性增长**：如果目前值与目标值差值太大，将拥塞窗口直接设置为目标值带来很大压力。此时设置一个`Smax`，按照`Smax`步长增长。



###### TCP CUBIC

对BIC算法的简化，用三次项支配窗口扩充算法，新窗口的尺寸w为：

 ![TCP协议拥塞控制算法（Reno、HSTCP、BIC、Vegas、Westwood）](https://img-blog.csdnimg.cn/img_convert/d8a4acaf42fc3a3585912fb370c0c15f.png)



#### 长连接与短连接

|          |                            短连接                            |                            长连接                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 操作过程 |   建立连接→数据传输→关闭连接...建立连接→数据传输→关闭连接    |     建立连接→数据传输...（保持连接）...数据传输→关闭连接     |
|   优点   |   管理简单，存在的连接都是有用的连接，不需要额外的控制手段   |          省去较多的TCP连接建立和销毁过程，减少浪费           |
|   缺点   | 如果客户请求频繁，则会在TCP建立和关闭操作上浪费大量时间和带宽 | KeepAlive探测周期太长，并且只是探测TCP连接的存活；连接数量可能会越来越多，增加服务端的压力 |
| 应用场景 |    如WEB网站的HTTP服务，用户量大，且每个用户无需频繁操作     | 操作频繁，点对点通讯，并且连接数较少的情况（比如数据库的连接，如果使用短连接频繁的通信会造成socket错误） |



#### 连接保活——KeepAlive

##### 为什么要有KeepAlive？

在长连接应用场景下，服务器端一般不会主动关闭连接，如果客户端与服务器之间的连接一直不关闭，会存在一个问题：随着客户端连接越来越多，服务器早晚有一天会承受不住。此时服务端需要采取一些措施，比如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致服务端服务受损；如果条件允许可以以客户端机器为颗粒度，限制每个客户端的最大、最长连接数。

为了解决这个问题，TCP通过`KeepAlive`机制（保活功能）来检测死连接。保活功能**主要为服务器应用提供**，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务器端检测到这种半开放的连接。

如果一个给定的连接在**2小时**内没有任何数据传输，服务器就向客户端发送一个探测报文段（心跳包）：

1. 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常*（ACK响应）*，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
2. 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在**75秒**后超时。服务器总共发送**10个**这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并**终止连接**。
3. 客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位*（RST响应）*，使得服务器**终止这个连接**。
4. 客户主机正常运行，但从服务器不可达。这种情况与2类似，TCP能发现的就是没有收到探查的响应。



##### 与HTTP的Keep-Alive的区别

- HTTP的`Keep-Alive`意图在于短时间内连接复用，希望短时间内可以在同一个连接上进行多次请求/响应

  > 客户端发送`connection:keep-alive`头给服务器，并且服务器也接受这个请求头，则可以复用HTTP连接，减少了新建和断开TCP连接的消耗，即避免了进行重复的TCP三次握手和四次挥手的环节

- TCP的`KeepAlive`机制意图在于保活、心跳、检测连接存活。当一个TCP连接两端长时间没有数据传输时（默认配置为2小时），就发送心跳包来探测连接是否存活

  > 即在`ESTABLISHED`状态时双方检测连接的可用性



##### 怎么开启KeepAlive？

`KeepAlive`默认是关闭的，在Linux系统上没有一个全局的选项去开启TCP的`KeepAlive`。需要开启`KeepAlive`的应用必须在TCP的`socket`中单独开启。`Linux Kernel`有三个选项影响到`KeepAlive`的行为：

- `tcp_keepalive_time 7200`：距离上次传送数据多少时间未收到新报文判断为开始检测，单位秒，默认7200s
- `tcp_keepalive_intvl 75`：检测开始每多少时间发送心跳包，单位秒，默认75s
- `tcp_keepalive_probes 9`：发送几次心跳包对方未响应则close连接，默认9次



##### 局限性

- `KeepAlive`只能检测连接是否存活，不能检测连接是否可用。

  > 如果客户端发生死锁，无法在连接上进行任何读写操作，但是操作系统仍然可以响应网络层`KeepAlive`包，就会出现服务器认为该连接仍然存活，不会进行撤销连接，但实际上这个连接已经crash掉了

- 默认的`KeepAlive`心跳时间为2小时，过长

- 依赖于操作系统的实现，灵活性不够，默认为关闭

- 代理（如`socks proxy`）或者负载均衡器会让KeepAlive失效

  > `socks proxy`只管转发TCP层具体的数据包，而不会转发TCP协议内的实现细节的包。
  >
  > 由于`TCP KeepAlive`可能会失效，所以一般会要求**应用要自己有心跳包**



#### 粘包、拆包

由于TCP传输协议面向流的，没有消息保护边界。一方发送的多个报文可能会被合并成一个大的报文进行传输，这就是粘包；也可能发送的一个报文，可能会被拆分成多个小报文，这就是拆包。

可能会出现的情况有以下四种：

![image-20211025151642286](https://tva1.sinaimg.cn/large/008i3skNgy1gvrkwtyxjvj60el08jaai02.jpg)

1. server端分两次读取到了两个独立的完整的数据包D1和D2，没有发生粘包和拆包现象
2. server一次接收到了两个数据包，D1和D2粘合在一起，发生了粘包
3. server分两次读取到了数据包，第一次读取到了完整的D1和一部分D2，第二次读取到了D2剩下的内容
4. server分两次读取到了数据包，第一次读取到了部分D1，第二次读取到了剩下的D1和完整的D2



##### 产生原因

###### socket缓冲区与滑动窗口

每个TCP `socket`在内核中都有一个发送缓冲区(`SO_SNDBUF` )和一个接收缓冲区(`SO_RCVBUF`)，TCP的全双工的工作模式以及TCP的滑动窗口便是依赖于这两个独立的`buffer`的填充状态。

- SO_SNDBUF

  进程发送的数据的时候假设调用了一个`send`方法，最简单情况（也是一般情况），将数据拷贝进入`socket`的内核发送缓冲区之中，然后`send`便会在上层返回。换句话说，`send`返回之时，数据不一定会发送到对端去（和`write`写文件有点类似），**`send`仅仅是把应用层`buffer`的数据拷贝进`socket`的内核发送`buffer`中。**

- SO_RCVBUF：

  把接受到的数据缓存入内核，应用进程一直没有调用`read`进行读取的话，此数据会一直缓存在相应`socket`的接收缓冲区内。再啰嗦一点，不管进程是否读取`socket`，对端发来的数据都会经由内核接收并且缓存到`socket`的内核接收缓冲区之中。**`read`所做的工作，就是把内核缓冲区中的数据拷贝到应用层用户的`buffer`里面，仅此而已。**

- 滑动窗口

  TCP连接在三次握手的时候，会将自己的窗口大小发送给对方，其实就是`SO_RCVBUF`指定的值。之后在发送数据的时，发送方必须要先确认接收方的窗口没有被填充满，如果没有填满，则可以发送。

  

###### MSS/MTU限制

`MTU`  (*Maxitum Transmission Unit*,最大传输单元)是链路层对一次可以发送的最大数据的限制。

> `MTU`是以太网传输数据方面的限制，**每个以太网帧最大不能超过1518bytes**。刨去以太网帧的帧头(DMAC+SMAC+Type域）14Bytes和帧尾(CRC校验)4Bytes，那么剩下承载上层协议的地方也就是Data域最大就只能有==1500Bytes==这个值 我们就把它称之为`MTU`。

`MSS`（*Maxitum Segment Size*,最大分段大小)是TCP报文中**数据部分**的最大长度，是传输层对一次可以发送的最大数据的限制。

> 由于IPV4和IPV6的长度不同，在IPV4中，以太网`MSS`可以达到==1460byte==（1500-20（IPv4首部）-20（TCP首部）= 1460）；在IPV6中，以太网`MSS`可以达到==1440byte==（1500-40（IPv6首部）-20（TCP首部）= 1440）。

**发送方发送数据时，当`SO_SNDBUF`中的数据量大于`MSS`时，操作系统会将数据进行拆分，使得每一部分都不超过`MSS`，也形成了拆包。**

![image-20211025154610343](https://tva1.sinaimg.cn/large/008i3skNgy1gvrlrgscenj60fd08ljrt02.jpg)

![image-20211025161843848](https://tva1.sinaimg.cn/large/008i3skNgy1gvrmpc8ih4j30eo04g3yn.jpg)

数据在传输过程中，每经过一层，都会加上一些额外的信息：

- **应用层：**只关心发送的数据`Data`，`send`方法将数据写入`socket`在内核中的缓冲区`SO_SNDBUF`即返回，操作系统会将`SO_SNDBUF`中的数据取出来进行发送。
- **传输层**：会在`Data`前面加上TCP首部(20字节)，**`Data`最大长度为`MSS`**
- **网络层：**会在TCP报文的基础上再添加一个IP首部，也就是将自己的网络地址加入到报文中。IPv4中首部长度是20字节，IPV6中首部长度是40字节。**整个IP数据报最大长度为`MTU`**
- **链路层：**加上`Datalink Header`和`CRC`。会将`SMAC`(*Source Machine*，数据发送方的`MAC`地址)，`DMAC`(*Destination Machine*，数据接受方的`MAC`地址 )和`Type`域加入。`SMAC+DMAC+Type+CRC`总长度为18字节。
- **物理层：**进行传输



###### Nagle算法

TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头(TCP Header+IP Header)，同时，对方接收到数据，也需要发送ACK表示确认。

> 即使从键盘输入的一个字符，占用一个字节，可能在传输上造成41字节的包，其中包括1字节的有用信息和40字节的首部数据。这种情况转变成了4000%的消耗，这样的情况对于重负载的网络来是无法接受的。称之为**"糊涂窗口综合征"**。

为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据）。==Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。==

`Nagle`算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于`MSS`尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的`ACK`确认该数据已收到。

`Nagle`算法的规则：

1. 如果`SO_SNDBUF`中的数据长度达到`MSS`，则允许发送；
2. 如果该`SO_SNDBUF`中含有`FIN`，表示请求关闭连接，则先将`SO_SNDBUF`中的剩余数据发送，再关闭；
3. 设置了`TCP_NODELAY=true`选项，则允许发送。`TCP_NODELAY`是取消TCP的确认延迟机制，相当于禁用了`Negale` 算法。正常情况下，当`Server`端收到数据之后，它并不会马上向`client`端发送`ACK`，而是会将`ACK`的发送延迟一段时间（一般是**40ms**），它希望在t时间内`server`端会向`client`端发送应答数据，这样`ACK`就能够和应答数据一起发送，就像是应答数据捎带着`ACK`过去。当然，TCP确认延迟40ms并不是一直不变的，TCP连接的延迟确认时间一般初始化为最小值40ms，随后根据连接的重传超时时间（`RTO`）、上次收到数据包与本次接收数据包的时间间隔等参数进行不断调整。另外可以通过设置`TCP_QUICKACK`选项来取消确认延迟。
4. 未设置`TCP_CORK`选项时，若所有发出去的小数据包（包长度小于`MSS`）均被确认，则允许发送;
5. 上述条件都未满足，但发生了超时（一般为200ms），则立即发送。



##### 解决方法

1. 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
2. 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。
3. 设置消息边界（特殊标识符），服务端从网络流中按消息编辑分离出消息内容。



#### 四元组、五元组、七元组

|        | 源IP地址 | 源端口 | 目的IP地址 | 目的端口 | 协议号 | 服务类型 | 接口索引 |
| :----: | :------: | :----: | :--------: | :------: | :----: | :------: | :------: |
| 四元组 |    √     |   √    |     √      |    √     |        |          |          |
| 五元组 |    √     |   √    |     √      |    √     |   √    |          |          |
| 七元组 |    √     |   √    |     √      |    √     |   √    |    √     |    √     |

- 四元组即用四个维度来**确定唯一连接**
- 五元组即用五个字段来**表示一个会话**
- 七元组即用七个字段来**确定网络流量**



#### TCP-fastopen(TFO)

当前`web`和`web-like`应用中一般都是在三次握手后开始数据传输（第三次可以开始传输），相比于UDP，**多了一个RTT的时延**，即使当前很多应用使用长连接来处理这种情况，但是仍然由一定比例的短连接，这额外多出的一个RTT仍然对应用的时延有非常大的影响。TFO就是在这种背景下面提出来的。
 `TFO(TCP fast open)`是TCP协议的`experimental update`，它允许服务器和客户端在连接建立握手阶段交换数据，从而使应用节省了一个RTT的时延。但是TFO会引起一些问题，因此协议要求TCP实现必须**默认禁止TFO**。需要在某个服务端口上启用TFO功能的时候需要应用程序显示启用。



##### TFO过程

![img](https://images2015.cnblogs.com/blog/1032663/201612/1032663-20161224171134307-927842958.png)

1. 在使用TFO之前，`client`首先需要通过一个普通的三次握手连接获取`FOC(Fast Open Cookie)`
   - `client`发送一个带有`Fast Open`选项的`SYN`包，同时携带一个空的`cookie`域来请求一个`cookie`
   - `server`产生一个`cookie`，然后通过`SYN-ACK`包的`Fast Open`选项来返回给`client`
   - `client`缓存这个`cookie`以备将来使用`TFO`连接的时候使用

2. 执行TFO
   - `client`发送一个带有数据的SYN包，同时在`Fast Open`选项中携带之前通过正常连接获取的`cookie`
   - `server`验证这个`cookie`。如果这个`cookie`是有效的，`server`会返回`SYN-ACK`报文，然后这个`server`把接收到的数据传递给应用层。如果这个`cookie`是无效的，`server`会丢掉SYN包中的数据，同时返回一个`SYN-ACK`包来确认SYN包中的系列号
   - 如果`cookie`有效，在连接完成之前`server`可以给`client`发送响应数据，携带的数据量受到TCP拥塞控制的限制
   - `client`发送ACK包来确认`server`的SYN和数据，如果`client`端SYN包中的数据没有被服务器确认，`client`会在这个ACK包中重传对应的数据
   - 剩下的连接处理就类似正常的TCP连接了，`client`一旦获取到FOC，可以重复`Fast Open`直到`cookie`过期。

通过整个过程，我们可以看到**TFO的核心是一个安全`cookie`，服务器使用这个`cookie`来给客户端鉴权**。



##### Fast Open Cookie

- `Fast Open Cookie`是一个加密的数据字符串，由服务端负责生成和验证，客户端或者连接的主动打开放缓存，并且用于后续的初始化连接中
- 服务端加密客户端SYN包里的源IP地址（不包含端口，因为`client`每次的端口都可能不同），生成至多16字节的`cookie`
- 没有服务端生成`cookie`时使用的密钥，客户端是不能生成有效`cookie`的，因此`cookie`不能被第三方伪造
- `cookie`有一定的过期时间，过期后需要有服务端重新生成
- 不提供身份认证，目的不是抵挡中间人
- `cookie`是加密的，在一定程度上增加了TFO的安全性



##### 存在问题

由于带了 `cookie` 有些防火墙认为数据包异常，在这种环境下用起来就会有问题。有报告说某些4G网络就有这种问题。



### UDP

#### 特点

- UDP是基于IP的简单的面向消息的运输层协议
- 无需建立连接
- 不保证数据可靠性
- 简单、轻量化、速度快
- 没有流控制，没有应答确认机制，不能解决丢包、重发、错序问题
- 分组首部开销小，只需8字节，而TCP首部至少需要20字节



#### 报文结构

![image-20211025210902602](https://tva1.sinaimg.cn/large/008i3skNgy1gvrv3egiglj313i0deab7.jpg)



#### 使用场景

UDP协议一般作为流媒体应用、语音交流、视频会议所使用的传输层协议，还有许多基于互联网的电话服务使用的VOIP（基于IP的语音）也是基于UDP运行的，实时视频和音频流协议旨在处理偶尔丢失的数据包，因此，如果重新传输丢失的数据包，则只会发生质量略有下降，而不是出现较大的延迟。

我们大家都知道的DNS 协议底层也使用了UDP 协议，这些应用或协议之所以选择UDP 主要是因为以下这几点：

1. **实时性**，采用 UDP 协议时，只要应用进程将数据传给 UDP，UDP 就会将此数据打包进 UDP 报文段并立刻传递给网络层，然而TCP有拥塞控制的功能，它会在发送前判断互联网的拥堵情况，如果互联网极度阻塞，那么就会抑制 TCP 的发送方。使用 UDP 的目的就是希望实时性。

2. **无须建立连接**，TCP 在数据传输之前需要经过三次握手的操作，而 UDP 则无须任何准备即可进行数据传输。因此 UDP 没有建立连接的时延。

3. **无连接状态**，TCP 需要在端系统中维护连接状态，连接状态包括接收和发送缓存、拥塞控制参数以及序号和确认号的参数，在 UDP 中没有这些参数，也没有发送缓存和接受缓存。因此，某些专门用于某种特定应用的服务器当应用程序运行在 UDP 上，一般**能支持更多的活跃用户**

4. **分组首部开销小**，每个 TCP 报文段都有至少 20 字节的首部开销，而 UDP 仅仅只有 8 字节的开销。



#### UDP洪水

UDP 洪水是一种拒绝服务攻击，攻击者将大量用户数据报协议(UDP) 数据包发送到目标服务器，旨在让该设备的处理和响应能力无力承担。由于UDP 洪水攻击，保护目标服务器的防火墙也可能不堪重负，导致对正常流量拒绝服务。



##### 工作原理

UDP 洪水的工作原理主要是利用服务器响应发送到其端口之一的UDP数据包时所采取的步骤。在正常情况下，服务器在特定端口上收到UDP 数据包时，将通过以下两个步骤进行响应：

1. 服务器首先检查是否有任何当前侦听指定端口请求的程序正在运行。

2. 如果该端口上没有程序正在接收数据包，则服务器将以 ICMP (ping) 数据包作为响应，以告知发送方目标不可达。

UDP洪水就好比酒店接待员转接呼叫的情况。首先，接待员接到电话，呼叫者要求将其连接到特定客房。然后，接待员需要查看所有房间的列表，以确保客人在客房内，并愿意接听电话。如果接待员了解到客人没有接听电话，他们就必须重新接听电话，并告诉呼叫者客人不会接听电话。如果所有电话线路都突然同时发出类似请求，他们很快就会变得不堪重负。

由于目标服务器利用资源来检查并响应每个接收到的UDP 数据包，当收到大量UDP 数据包时，目标资源会很快耗尽，从而导致对正常流量拒绝服务。



##### 如何预防？

大多数操作系统限制ICMP 数据包的响应速率，部分原因是为了中断需要ICMP 响应的DDoS 攻击。这种防护措施的一个缺点是，在攻击期间，合法数据包也可能在此过程中被过滤。如果UDP洪水的大小足以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何防护都将是不够的，因为瓶颈将发生在目标设备的上游。



### KCP

KCP是一个**快速可靠**协议，能==以比 TCP浪费10%-20%的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果==。纯算法实现，并不负责底层协议（如UDP）的收发，需要使用者自己定义下层数据的发送方式，以 `callback`的方式提供给 KCP。连时钟都需要外部传递进来，**内部不会有任何一次系统调用**。

> TCP是为流量设计的（每秒内可以传输多少KB的数据），讲究的是充分利用带宽。而 KCP是为流速设计的（单个数据从一端发送到一端需要多少时间），以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度。 

KCP力求在保证可靠性的情况下提高传输速度；KCP没有规定下层传输协议，但通常使用UDP来实现（使UDP变得可靠）。



#### 报文格式

![img](https://pic1.zhimg.com/80/v2-e3472ecee56ffd50e48175e21001d464_720w.jpg)





#### 特点

1. RTO不翻倍

   RTO（`Retransmission-TimeOut`）即重传超时时间，TCP是基于ARQ协议实现的可靠性，KCP也是基于ARQ协议实现的可靠性，但TCP的超时计算是**2RTO**，而KCP的超时计算是**1.5RTO**，也就是说假如连续丢包3次，TCP是（2^3^=8）RTO，而KCP则是（1.5^3^=3.375）RTO，意味着可以更快地重新传输数据。通过4字节ts（`timestamp`，当前`segment`发送时的时间戳）计算RTT（`Round-Trip-Time`）即往返时延，再通过RTT计算RTO。

2. 选择性重传
   - TCP中实现的是连续ARQ协议，再配合累计确认重传数据，只不过重传时需要将最小序号丢失的以后所有的数据都要重传
   - KCP则只重传真正丢失的数据。

3. 快速重传

   与TCP相同，都是通过累计确认实现的，发送端发送了1，2，3，4，5几个包，然后收到远端的ACK：1，3，4，5，当收到ACK = 3时，KCP知道2被跳过1次，收到ACK = 4时，知道2被跳过了2次，此时可以认为2号丢失，不用等超时，直接重传2号包，大大改善了丢包时的传输速度。

   > 1字节cmd = 81时，sn相当于TCP中的seq，cmd = 82 时，sn相当于TCP中的ack。cmd相当于`WebSocket`协议中的`openCode`，即操作码。

4. 非延迟ACK

   TCP在连续ARQ协议中，不会将一连串的每个数据都响应一次，而是延迟发送ACK，即UNA模式（累计确认），目的是为了充分利用带宽，但是这样会计算出较大的RTT时间，延长了丢包时的判断过程，而KCP的ACK是否延迟发送可以调节。

5. UNA + ACK

   ARQ模型响应有两种，UNA（此编号前所有包已收到，如TCP）和ACK（该编号包已收到），**光用UNA将导致全部重传，光用ACK则丢失成本太高**，以前的协议都是二选其一，而KCP协议中，除去单独的ACK包外，所有包都有UNA信息。

   > 4字节una表示cmd = 81时，当前已经收到了小于una的所有数据。

6. 非退让流控

   KCP正常模式同TCP一样使用公平退让法则，即发送窗口大小由：**发送缓存大小，接收端剩余接收缓存大小，丢包退让以及慢启动**这四个要素决定。但传输及时性要求很高的小数据时，可以通过配置跳过后两步，仅仅依赖滑动窗口来控制发送频率。以牺牲部分公平性及带宽消耗之代价，换取了开着BT能够流畅传输的效果。





## 网络层



## 链路层



## 物理层
